<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mark Fuge">
<meta name="dcterms.date" content="2025-10-26">

<title>Appendix D — Reviewing Mathematical and Computational Foundations for Machine Learning – Machine Learning for Mechanical Engineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../appendices/review_of_singular_value_decomposition.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-0dd2bd5de344125cf763a379ddc3eb04.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../appendices/helpful_tooling.html">Appendices</a></li><li class="breadcrumb-item"><a href="../appendices/review_of_math_and_computing_foundations.html"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Reviewing Mathematical and Computational Foundations for Machine Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning for Mechanical Engineering</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part1/part1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundational Skills</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/reviewing_supervised_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Reviewing Supervised Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/cross_validation_linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Evaluating Machine Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/supervised_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/linear_decompositions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Review of Linear Unsupervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/taking_derivatives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Taking Derivatives with Automatic Differentiation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/distribution_distance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Measuring Distribution Distances</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/introduction_to_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to Inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part2/part2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model-Specific Approaches</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/review_neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Review of Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/intro_to_GANS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Push-Forward Generative Models – Generative Adversarial Networks (GANs)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/GAN_pitfalls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">GAN Training Pitfalls</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/OT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Optimal Transport for Generative Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../problems/problems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../problems/ps1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Problem Set 1</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../notebooks/notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">In-Class Notebooks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/california_housing_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Housing Price Data Visualization In-Class Exercise</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/helpful_tooling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Helpful Tooling for Working with and Debugging Machine Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/course_progression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Course Lecture Progression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/review_of_singular_value_decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Review of Matrices and the Singular Value Decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/review_of_math_and_computing_foundations.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Reviewing Mathematical and Computational Foundations for Machine Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#random-variables-monte-carlo-and-concentration-inequalities" id="toc-random-variables-monte-carlo-and-concentration-inequalities" class="nav-link active" data-scroll-target="#random-variables-monte-carlo-and-concentration-inequalities"><span class="header-section-number">D.1</span> Random Variables, Monte Carlo, and Concentration Inequalities</a>
  <ul class="collapse">
  <li><a href="#concepts" id="toc-concepts" class="nav-link" data-scroll-target="#concepts"><span class="header-section-number">D.1.1</span> Concepts:</a></li>
  <li><a href="#key-equations" id="toc-key-equations" class="nav-link" data-scroll-target="#key-equations"><span class="header-section-number">D.1.2</span> Key Equations:</a></li>
  <li><a href="#monte-carlo-mean-estimation" id="toc-monte-carlo-mean-estimation" class="nav-link" data-scroll-target="#monte-carlo-mean-estimation"><span class="header-section-number">D.1.3</span> Monte Carlo Mean Estimation</a></li>
  <li><a href="#expectation-of-a-nonlinear-function" id="toc-expectation-of-a-nonlinear-function" class="nav-link" data-scroll-target="#expectation-of-a-nonlinear-function"><span class="header-section-number">D.1.4</span> Expectation of a Nonlinear Function</a></li>
  </ul></li>
  <li><a href="#change-of-variables-jacobians" id="toc-change-of-variables-jacobians" class="nav-link" data-scroll-target="#change-of-variables-jacobians"><span class="header-section-number">D.2</span> Change of Variables &amp; Jacobians</a>
  <ul class="collapse">
  <li><a href="#concepts-1" id="toc-concepts-1" class="nav-link" data-scroll-target="#concepts-1"><span class="header-section-number">D.2.1</span> Concepts:</a></li>
  <li><a href="#key-equations-1" id="toc-key-equations-1" class="nav-link" data-scroll-target="#key-equations-1"><span class="header-section-number">D.2.2</span> Key Equations:</a></li>
  <li><a href="#example-linear-transformation-1d" id="toc-example-linear-transformation-1d" class="nav-link" data-scroll-target="#example-linear-transformation-1d"><span class="header-section-number">D.2.3</span> Example: Linear Transformation (1D)</a></li>
  <li><a href="#example-nonlinear-transformation" id="toc-example-nonlinear-transformation" class="nav-link" data-scroll-target="#example-nonlinear-transformation"><span class="header-section-number">D.2.4</span> Example: Nonlinear Transformation</a></li>
  <li><a href="#example-2d-transformation-and-grid-deformation" id="toc-example-2d-transformation-and-grid-deformation" class="nav-link" data-scroll-target="#example-2d-transformation-and-grid-deformation"><span class="header-section-number">D.2.5</span> Example: 2D Transformation and Grid Deformation</a></li>
  <li><a href="#example-computing-jacobians-with-pytorch" id="toc-example-computing-jacobians-with-pytorch" class="nav-link" data-scroll-target="#example-computing-jacobians-with-pytorch"><span class="header-section-number">D.2.6</span> Example: Computing Jacobians with PyTorch</a></li>
  </ul></li>
  <li><a href="#linear-algebra-spectral-norms" id="toc-linear-algebra-spectral-norms" class="nav-link" data-scroll-target="#linear-algebra-spectral-norms"><span class="header-section-number">D.3</span> Linear Algebra &amp; Spectral Norms</a>
  <ul class="collapse">
  <li><a href="#concepts-2" id="toc-concepts-2" class="nav-link" data-scroll-target="#concepts-2"><span class="header-section-number">D.3.1</span> Concepts:</a></li>
  <li><a href="#key-equations-2" id="toc-key-equations-2" class="nav-link" data-scroll-target="#key-equations-2"><span class="header-section-number">D.3.2</span> Key Equations:</a></li>
  <li><a href="#example-2d-linear-transform-visualization" id="toc-example-2d-linear-transform-visualization" class="nav-link" data-scroll-target="#example-2d-linear-transform-visualization"><span class="header-section-number">D.3.3</span> Example: 2D Linear Transform Visualization</a></li>
  <li><a href="#example-spectral-norms-and-condition-numbers-of-different-matrices" id="toc-example-spectral-norms-and-condition-numbers-of-different-matrices" class="nav-link" data-scroll-target="#example-spectral-norms-and-condition-numbers-of-different-matrices"><span class="header-section-number">D.3.4</span> Example: Spectral Norms and Condition Numbers of Different Matrices</a></li>
  <li><a href="#example-neural-network-jacobian-and-local-geometry" id="toc-example-neural-network-jacobian-and-local-geometry" class="nav-link" data-scroll-target="#example-neural-network-jacobian-and-local-geometry"><span class="header-section-number">D.3.5</span> Example: Neural Network Jacobian and Local Geometry</a></li>
  <li><a href="#example-spectral-normalization" id="toc-example-spectral-normalization" class="nav-link" data-scroll-target="#example-spectral-normalization"><span class="header-section-number">D.3.6</span> Example: Spectral Normalization</a></li>
  </ul></li>
  <li><a href="#differentiation-curvature" id="toc-differentiation-curvature" class="nav-link" data-scroll-target="#differentiation-curvature"><span class="header-section-number">D.4</span> Differentiation &amp; Curvature</a>
  <ul class="collapse">
  <li><a href="#concepts-3" id="toc-concepts-3" class="nav-link" data-scroll-target="#concepts-3"><span class="header-section-number">D.4.1</span> Concepts:</a></li>
  <li><a href="#key-equations-3" id="toc-key-equations-3" class="nav-link" data-scroll-target="#key-equations-3"><span class="header-section-number">D.4.2</span> Key Equations:</a></li>
  <li><a href="#example-gradient-and-hessian-visualization" id="toc-example-gradient-and-hessian-visualization" class="nav-link" data-scroll-target="#example-gradient-and-hessian-visualization"><span class="header-section-number">D.4.3</span> Example: Gradient and Hessian Visualization</a></li>
  <li><a href="#example-reducing-computational-cost-using-jvps-and-hvps" id="toc-example-reducing-computational-cost-using-jvps-and-hvps" class="nav-link" data-scroll-target="#example-reducing-computational-cost-using-jvps-and-hvps"><span class="header-section-number">D.4.4</span> Example: Reducing Computational Cost using JVPs and HVPs</a></li>
  </ul></li>
  <li><a href="#marginalization-of-probability-distributions" id="toc-marginalization-of-probability-distributions" class="nav-link" data-scroll-target="#marginalization-of-probability-distributions"><span class="header-section-number">D.5</span> Marginalization of Probability Distributions</a>
  <ul class="collapse">
  <li><a href="#concepts-4" id="toc-concepts-4" class="nav-link" data-scroll-target="#concepts-4"><span class="header-section-number">D.5.1</span> Concepts:</a></li>
  <li><a href="#key-equations-4" id="toc-key-equations-4" class="nav-link" data-scroll-target="#key-equations-4"><span class="header-section-number">D.5.2</span> Key Equations:</a></li>
  <li><a href="#example-2d-gaussian-marginalization" id="toc-example-2d-gaussian-marginalization" class="nav-link" data-scroll-target="#example-2d-gaussian-marginalization"><span class="header-section-number">D.5.3</span> Example: 2D Gaussian Marginalization</a></li>
  <li><a href="#example-conditional-sampling-and-the-joint-distribution" id="toc-example-conditional-sampling-and-the-joint-distribution" class="nav-link" data-scroll-target="#example-conditional-sampling-and-the-joint-distribution"><span class="header-section-number">D.5.4</span> Example: Conditional Sampling and the Joint Distribution</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../appendices/helpful_tooling.html">Appendices</a></li><li class="breadcrumb-item"><a href="../appendices/review_of_math_and_computing_foundations.html"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Reviewing Mathematical and Computational Foundations for Machine Learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Appendix D — Reviewing Mathematical and Computational Foundations for Machine Learning</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Mark Fuge </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 26, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This notebook is designed to help you build (or refresh) the conceptual and computational foundations needed for understanding probabilistic generative modeling methods and other important topics in Machine Learning. You can look at each sub-section independently and in any order to refresh your knowledge of some foundations, though we may build upon certain common examples throughout.</p>
<p><strong>Learning Objectives</strong></p>
<p>By the end of this notebook, you will be able to:</p>
<ol type="1">
<li>Understand random variables and Monte Carlo sampling techniques</li>
<li>Apply change of variables transformations and compute Jacobians</li>
<li>Work with linear algebra concepts relevant to probabilistic models, such as spectral norms of matrices</li>
<li>Compute gradients and understand curvature in optimization landscapes</li>
<li>Perform marginalization operations in probabilistic settings</li>
</ol>
<div id="84949cdb" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard numerical and plotting libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> multivariate_normal</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># PyTorch for automatic differentiation</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting configuration</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.size'</span>] <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'lines.linewidth'</span>] <span class="op">=</span> <span class="dv">2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="random-variables-monte-carlo-and-concentration-inequalities" class="level2" data-number="D.1">
<h2 data-number="D.1" class="anchored" data-anchor-id="random-variables-monte-carlo-and-concentration-inequalities"><span class="header-section-number">D.1</span> Random Variables, Monte Carlo, and Concentration Inequalities</h2>
<section id="concepts" class="level3" data-number="D.1.1">
<h3 data-number="D.1.1" class="anchored" data-anchor-id="concepts"><span class="header-section-number">D.1.1</span> Concepts:</h3>
<ul>
<li>Random variables are functions that map outcomes to numerical values</li>
<li><strong>Expectations</strong> represent the average value of a function over a probability distribution</li>
<li><strong>Monte Carlo methods</strong> use random sampling to approximate expectations and integrals</li>
<li>The <strong>Law of Large Numbers</strong> ensures that sample averages converge to the true expectation as sample size increases</li>
<li>Convergence rate is typically <span class="math inline">\(O(1/\sqrt{N})\)</span>, meaning we need 4x more samples to halve the error</li>
<li>Finite samples introduce uncertainty that decreases with more data and <strong>Concentration Inequalities</strong> (Chebyshev, Hoeffding) bound the probability of large deviations, which can help us understand real-world machine learning behavior</li>
</ul>
</section>
<section id="key-equations" class="level3" data-number="D.1.2">
<h3 data-number="D.1.2" class="anchored" data-anchor-id="key-equations"><span class="header-section-number">D.1.2</span> Key Equations:</h3>
<p><strong>Expectation via Monte Carlo:</strong> <span class="math display">\[\mathbb{E}_{p(x)}[f(X)] = \int f(x) p(x) dx \approx \frac{1}{N} \sum_{i=1}^{N} f(x_i), \quad x_i \sim p(x)\]</span></p>
<p><strong>Intuition:</strong> If we can sample from a distribution, we can approximate any expectation by averaging function values over those samples. The approximation improves as we collect more samples.</p>
<p><strong>Law of Large Numbers:</strong> <span class="math display">\[\bar{X}_N = \frac{1}{N} \sum_{i=1}^{N} X_i \xrightarrow{N \to \infty} \mathbb{E}[X]\]</span></p>
<p><strong>Chebyshev’s Inequality:</strong> <span class="math display">\[P(|\bar{X}_N - \mu| \geq \epsilon) \leq \frac{\sigma^2}{N\epsilon^2}\]</span></p>
<p><strong>Hoeffding’s Inequality (for bounded r.v. in <span class="math inline">\([a,b]\)</span>):</strong> <span class="math display">\[P(|\bar{X}_N - \mu| \geq \epsilon) \leq 2\exp\left(-\frac{2N\epsilon^2}{(b-a)^2}\right)\]</span></p>
<p>Understanding convergence of statistical estimates of various functions will end up being foundational to many aspects of Machine Learning, so it is useful for us to build intuition about it ahead of time.</p>
<p><strong>Intuition:</strong> These inequalities tell us how confident we can be that our sample mean is close to the true mean. They guarantee exponential or polynomial concentration as <span class="math inline">\(N\)</span> grows.</p>
</section>
<section id="monte-carlo-mean-estimation" class="level3" data-number="D.1.3">
<h3 data-number="D.1.3" class="anchored" data-anchor-id="monte-carlo-mean-estimation"><span class="header-section-number">D.1.3</span> Monte Carlo Mean Estimation</h3>
<p>We’ll sample from a standard normal distribution <span class="math inline">\(\mathcal{N}(0, 1)\)</span> and watch how the sample mean converges to the true mean (which is 0) as we increase the number of samples.</p>
<div id="12715535" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># True parameters</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>true_mean <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>true_std <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample sizes to test</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="op">=</span> np.logspace(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">50</span>).astype(<span class="bu">int</span>)  <span class="co"># From 10 to 10,000 samples</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute sample means for increasing sample sizes</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>sample_means <span class="op">=</span> []</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>confidence_intervals <span class="op">=</span> []</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> N <span class="kw">in</span> sample_sizes:</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw N samples from standard normal</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> np.random.normal(true_mean, true_std, N)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute sample mean</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    sample_mean <span class="op">=</span> np.mean(samples)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    sample_means.append(sample_mean)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute 95% confidence interval (±1.96 * standard error)</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    standard_error <span class="op">=</span> np.std(samples) <span class="op">/</span> np.sqrt(N)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    ci <span class="op">=</span> <span class="fl">1.96</span> <span class="op">*</span> standard_error</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    confidence_intervals.append(ci)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>sample_means <span class="op">=</span> np.array(sample_means)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>confidence_intervals <span class="op">=</span> np.array(confidence_intervals)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="851c2ce6" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Left plot: Sample mean convergence with confidence bands</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>ax1.plot(sample_sizes, sample_means, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Sample Mean'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>ax1.fill_between(sample_sizes, </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                  sample_means <span class="op">-</span> confidence_intervals,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>                  sample_means <span class="op">+</span> confidence_intervals,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>                  alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'95% Confidence Interval'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>ax1.axhline(true_mean, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True Mean'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Number of Samples (N)'</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Estimated Mean'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>ax1.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Convergence of Sample Mean'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Right plot: Confidence interval width vs sample size</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>ax2.plot(sample_sizes, confidence_intervals, <span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Number of Samples (N)'</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'95% CI Width (±)'</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>ax2.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>ax2.set_yscale(<span class="st">'log'</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Uncertainty Shrinks as $1/</span><span class="ch">\\</span><span class="st">sqrt</span><span class="sc">{N}</span><span class="st">$'</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Add reference line showing 1/sqrt(N) scaling</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>reference_line <span class="op">=</span> confidence_intervals[<span class="dv">0</span>] <span class="op">*</span> np.sqrt(sample_sizes[<span class="dv">0</span>]) <span class="op">/</span> np.sqrt(sample_sizes)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>ax2.plot(sample_sizes, reference_line, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, </span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'$1/</span><span class="ch">\\</span><span class="st">sqrt</span><span class="sc">{N}</span><span class="st">$ scaling'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notice how the sample mean oscillates around the true value but gradually settles down. The confidence interval shrinks, but not linearly—it follows a <span class="math inline">\(1/\sqrt{N}\)</span> pattern. This means:</p>
<ul>
<li>To halve your error, you need 4x more samples</li>
<li>To reduce error by 10x, you need 100x more samples</li>
</ul>
<p>Why do you think the convergence is so slow? What does this tell you about the computational cost of Monte Carlo methods, in general?</p>
</section>
<section id="expectation-of-a-nonlinear-function" class="level3" data-number="D.1.4">
<h3 data-number="D.1.4" class="anchored" data-anchor-id="expectation-of-a-nonlinear-function"><span class="header-section-number">D.1.4</span> Expectation of a Nonlinear Function</h3>
<p>So far we’ve estimated the mean of a simple identity function. But Monte Carlo really shines when computing expectations of complex, nonlinear functions. Let’s estimate <span class="math inline">\(\mathbb{E}[X^2]\)</span> where <span class="math inline">\(X \sim \mathcal{N}(0, 1)\)</span>.</p>
<div id="e4658769" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For a standard normal, E[X^2] = Var(X) + E[X]^2 = 1 + 0 = 1</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>true_expectation <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples and compute E[X^2]</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="op">=</span> np.logspace(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">200</span>).astype(<span class="bu">int</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Function we want to compute the expectation of</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Monte Carlo estimates</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>mc_estimates <span class="op">=</span> []</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> N <span class="kw">in</span> sample_sizes:</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, N)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    estimate <span class="op">=</span> np.mean(f(samples))</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    mc_estimates.append(estimate)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>mc_estimates <span class="op">=</span> np.array(mc_estimates)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="a860430a" class="cell">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Left plot: Convergence to true value</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>ax1.plot(sample_sizes, mc_estimates, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Monte Carlo Estimate'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>ax1.axhline(true_expectation, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True Value = </span><span class="sc">{</span>true_expectation<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Number of Samples (N)'</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Estimated $</span><span class="ch">\\</span><span class="st">mathbb</span><span class="sc">{E}</span><span class="st">[X^2]$'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>ax1.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Monte Carlo Estimation of $</span><span class="ch">\\</span><span class="st">mathbb</span><span class="sc">{E}</span><span class="st">[X^2]$'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>ax1.set_ylim(<span class="fl">0.8</span>, <span class="fl">1.2</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Right plot: Absolute error</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>absolute_error <span class="op">=</span> np.<span class="bu">abs</span>(mc_estimates <span class="op">-</span> true_expectation)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>ax2.plot(sample_sizes, absolute_error, <span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Number of Samples (N)'</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Absolute Error'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>ax2.set_xscale(<span class="st">'log'</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>ax2.set_yscale(<span class="st">'log'</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Error Decreases as $1/</span><span class="ch">\\</span><span class="st">sqrt</span><span class="sc">{N}</span><span class="st">$'</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Add reference line</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>reference <span class="op">=</span> absolute_error[<span class="dv">0</span>] <span class="op">*</span> np.sqrt(sample_sizes[<span class="dv">0</span>]) <span class="op">/</span> np.sqrt(sample_sizes)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>ax2.plot(sample_sizes, reference, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'$1/</span><span class="ch">\\</span><span class="st">sqrt</span><span class="sc">{N}</span><span class="st">$ scaling'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="change-of-variables-jacobians" class="level2" data-number="D.2">
<h2 data-number="D.2" class="anchored" data-anchor-id="change-of-variables-jacobians"><span class="header-section-number">D.2</span> Change of Variables &amp; Jacobians</h2>
<section id="concepts-1" class="level3" data-number="D.2.1">
<h3 data-number="D.2.1" class="anchored" data-anchor-id="concepts-1"><span class="header-section-number">D.2.1</span> Concepts:</h3>
<ul>
<li>When you transform a random variable, the probability density changes</li>
<li>The <strong>Jacobian matrix</strong> captures how a transformation stretches or compresses space</li>
<li>The <strong>determinant of the Jacobian</strong> computes how the volume scales in the new space operated on by the Jacobian</li>
<li>This principle underlies <strong>normalizing flows</strong> and other generative models</li>
<li>In 1D: <span class="math inline">\(|\frac{dy}{dx}|\)</span> tells us how density scales; in higher dimensions we use <span class="math inline">\(|\det J|\)</span></li>
</ul>
</section>
<section id="key-equations-1" class="level3" data-number="D.2.2">
<h3 data-number="D.2.2" class="anchored" data-anchor-id="key-equations-1"><span class="header-section-number">D.2.2</span> Key Equations:</h3>
<p><strong>Change of Variables Formula (1D):</strong> <span class="math display">\[p_Y(y) = p_X(x) \left| \frac{dx}{dy} \right| = p_X(g^{-1}(y)) \left| \frac{dg^{-1}}{dy} \right|\]</span></p>
<p>where <span class="math inline">\(y = g(x)\)</span> is a transformation.</p>
<p><strong>Change of Variables Formula (Multidimensional):</strong> <span class="math display">\[p_Y(y) = p_X(x) \left| \det \frac{\partial x}{\partial y} \right| = p_X(g^{-1}(y)) \left| \det J_{g^{-1}}(y) \right|\]</span></p>
<p><strong>Intuition:</strong> When you transform a random variable, the probability density must be adjusted by how much the transformation stretches or compresses space. Think of it like this: if a transformation spreads points apart (stretches), the density must decrease to keep total probability = 1.</p>
</section>
<section id="example-linear-transformation-1d" class="level3" data-number="D.2.3">
<h3 data-number="D.2.3" class="anchored" data-anchor-id="example-linear-transformation-1d"><span class="header-section-number">D.2.3</span> Example: Linear Transformation (1D)</h3>
<p>Let’s start with a simple linear transformation: <span class="math inline">\(y = 2x + 1\)</span>. We’ll sample from a standard normal and see how the distribution changes. Recall that for a normal distribution <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>, a linear transformation <span class="math inline">\(y = ax + b\)</span> results in <span class="math inline">\(y \sim \mathcal{N}(a\mu + b, (a\sigma)^2)\)</span>.</p>
<p>In this example, we should expect the expected mean of Y to be 1 and the standard deviation to be 2. Moreover, we should expect the density scaling factor from the Jacobian to be:</p>
<p><span class="math display">\[
\left| \frac{dx}{dy} \right| = \frac{1}{a} = 0.5
\]</span></p>
<p>which should be multiplied into the original density in the plots below.</p>
<div id="11c99b47" class="cell">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample from standard normal</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>x_samples <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n_samples)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply linear transformation: y = 2x + 1</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>a, b <span class="op">=</span> <span class="dv">2</span>, <span class="dv">1</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>y_samples <span class="op">=</span> a <span class="op">*</span> x_samples <span class="op">+</span> b</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For plotting, create a grid</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>x_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1000</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>y_grid <span class="op">=</span> a <span class="op">*</span> x_grid <span class="op">+</span> b</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Original density: N(0, 1)</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>px <span class="op">=</span> stats.norm.pdf(x_grid, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformed density (analytical): N(a*0 + b, (a*1)^2)</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>py_analytical <span class="op">=</span> stats.norm.pdf(y_grid, b, np.<span class="bu">abs</span>(a))</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Using change of variables: p_Y(y) = p_X((y-b)/a) * |1/a|</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co"># For y = ax + b, we have x = (y-b)/a, so dx/dy = 1/a</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>py_cov <span class="op">=</span> stats.norm.pdf((y_grid <span class="op">-</span> b) <span class="op">/</span> a, <span class="dv">0</span>, <span class="dv">1</span>) <span class="op">*</span> np.<span class="bu">abs</span>(<span class="dv">1</span><span class="op">/</span>a)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Top left: Original samples histogram</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].hist(x_samples, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].plot(x_grid, px, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True PDF'</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Original Distribution: $X </span><span class="ch">\\</span><span class="st">sim </span><span class="ch">\\</span><span class="st">mathcal</span><span class="sc">{N}</span><span class="st">(0, 1)$'</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].legend()</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Top right: Transformed samples histogram</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].hist(y_samples, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].plot(y_grid, py_analytical, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Analytical PDF'</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].plot(y_grid, py_cov, <span class="st">'k--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Change of Variables'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'y'</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Transformed Distribution: $Y = 2X + 1$'</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].legend()</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Bottom left: Side-by-side comparison</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].plot(x_grid, px, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'$p_X(x)$'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot transformed density on same scale (shift y_grid back to x scale for comparison)</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].plot(y_grid, py_analytical, <span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'$p_Y(y)$'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Comparing Densities (notice the scaling)'</span>)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].legend()</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Bottom right: Derivative visualization</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].plot(y_grid, np.ones_like(y_grid) <span class="op">*</span> np.<span class="bu">abs</span>(<span class="dv">1</span><span class="op">/</span>a), <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].axhline(np.<span class="bu">abs</span>(<span class="dv">1</span><span class="op">/</span>a), color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'y'</span>)</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'$|dx/dy|$'</span>)</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="ss">f'Jacobian Factor: $|dx/dy| = |1/</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">| = </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(<span class="dv">1</span><span class="op">/</span>a)<span class="sc">:.2f}</span><span class="ss">$'</span>)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].text(<span class="dv">0</span>, <span class="fl">0.6</span>, <span class="ss">f'Density is scaled by </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(<span class="dv">1</span><span class="op">/</span>a)<span class="sc">:.2f}</span><span class="ch">\n</span><span class="ss">'</span> <span class="op">+</span> </span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'(stretched by factor of </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(a)<span class="sc">}</span><span class="ss">)'</span>, </span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">11</span>, ha<span class="op">=</span><span class="st">'center'</span>,</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>                bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">'round'</span>, facecolor<span class="op">=</span><span class="st">'wheat'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample mean of Y: </span><span class="sc">{</span>np<span class="sc">.</span>mean(y_samples)<span class="sc">:.4f}</span><span class="ss"> (expected: </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample std of Y: </span><span class="sc">{</span>np<span class="sc">.</span>std(y_samples)<span class="sc">:.4f}</span><span class="ss"> (expected: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(a)<span class="sc">:.4f}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample mean of Y: 0.9957 (expected: 1)
Sample std of Y: 2.0068 (expected: 2.0000)

Jacobian factor |dx/dy| = 0.5000
Density is compressed by factor of 2</code></pre>
</div>
</div>
<p>Notice how the transformation <span class="math inline">\(y = 2x + 1\)</span> shifts the mean (the <span class="math inline">\(+1\)</span> part) and stretches the distribution (the <span class="math inline">\(2\)</span> x part). The density gets compressed because the same probability mass is now spread over a wider range.</p>
<p>The Jacobian factor <span class="math inline">\(|dx/dy| = 1/2\)</span> tells us exactly how much to scale the density.</p>
</section>
<section id="example-nonlinear-transformation" class="level3" data-number="D.2.4">
<h3 data-number="D.2.4" class="anchored" data-anchor-id="example-nonlinear-transformation"><span class="header-section-number">D.2.4</span> Example: Nonlinear Transformation</h3>
<p>Linear transformations are straightforward, but what about nonlinear ones? Let’s try <span class="math inline">\(y = \tanh(x)\)</span>, which squashes values into the range <span class="math inline">\((-1, 1)\)</span>.</p>
<div id="04d7af4e" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample from standard normal</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>z_samples <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n_samples)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply nonlinear transformation: y = tanh(z)</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>y_samples <span class="op">=</span> np.tanh(z_samples)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create grids for visualization</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>z_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1000</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>y_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">0.99</span>, <span class="fl">0.99</span>, <span class="dv">1000</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Original density</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>pz <span class="op">=</span> stats.norm.pdf(z_grid, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># For transformed density, we need the inverse: z = arctanh(y)</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># and the derivative: dz/dy = 1/(1-y^2)</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>z_from_y <span class="op">=</span> np.arctanh(y_grid)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>dz_dy <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> y_grid<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply change of variables</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>py_analytical <span class="op">=</span> stats.norm.pdf(z_from_y, <span class="dv">0</span>, <span class="dv">1</span>) <span class="op">*</span> np.<span class="bu">abs</span>(dz_dy)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Top left: Original samples</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].hist(z_samples, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].plot(z_grid, pz, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True PDF'</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'z'</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Original: $Z </span><span class="ch">\\</span><span class="st">sim </span><span class="ch">\\</span><span class="st">mathcal</span><span class="sc">{N}</span><span class="st">(0, 1)$'</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].legend()</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Top right: Transformed samples</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].hist(y_samples, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'green'</span>, </span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="st">'Empirical (samples)'</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].plot(y_grid, py_analytical, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Analytical (CoV)'</span>)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'y'</span>)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Transformed: $Y = </span><span class="ch">\\</span><span class="st">tanh(Z)$'</span>)</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].legend()</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Bottom left: Transformation function</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].plot(z_grid, np.tanh(z_grid), <span class="st">'purple'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].plot(z_grid, z_grid, <span class="st">'k--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, label<span class="op">=</span><span class="st">'Identity'</span>)</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'z'</span>)</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'y = tanh(z)'</span>)</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'The Transformation Function'</span>)</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].legend()</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_xlim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylim(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Bottom right: Jacobian (derivative)</span></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].plot(y_grid, dz_dy, <span class="st">'orange'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'y'</span>)</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'$|dz/dy| = 1/(1-y^2)$'</span>)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Jacobian Factor (notice the blow-up near ±1)'</span>)</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_ylim(<span class="dv">0</span>, <span class="dv">20</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <span class="math inline">\(\tanh\)</span> function compresses the tails of the Gaussian distribution into a bounded range. Notice how the Jacobian factor <span class="math inline">\(|dz/dy| = 1/(1-y^2)\)</span> grows very large near <span class="math inline">\(y = \pm 1\)</span>. This creates the characteristic “U-shaped” density—probability piles up where the transformation compresses most severely.</p>
<p>This type of transformation is common in neural networks (e.g., in activation functions). What do you think would happen if we used a transformation that wasn’t invertible?</p>
</section>
<section id="example-2d-transformation-and-grid-deformation" class="level3" data-number="D.2.5">
<h3 data-number="D.2.5" class="anchored" data-anchor-id="example-2d-transformation-and-grid-deformation"><span class="header-section-number">D.2.5</span> Example: 2D Transformation and Grid Deformation</h3>
<p>In higher dimensions, the Jacobian is a matrix, and its determinant tells us about volume changes. Let’s visualize this with a 2D linear transformation.</p>
<div id="9bab12ca" class="cell">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a 2D linear transformation matrix</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll use a matrix that scales by 2 in x-direction and rotates</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.pi <span class="op">/</span> <span class="dv">6</span>  <span class="co"># 30 degrees</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>scale_x, scale_y <span class="op">=</span> <span class="fl">2.0</span>, <span class="fl">1.0</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformation matrix: scale then rotate</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> np.array([[np.cos(theta), <span class="op">-</span>np.sin(theta)],</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>              [np.sin(theta), np.cos(theta)]])</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>S <span class="op">=</span> np.array([[scale_x, <span class="dv">0</span>],</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">0</span>, scale_y]])</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> R <span class="op">@</span> S</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Transformation matrix A:"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Determinant (area scaling factor): </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>det(A)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a regular grid</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>n_grid <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>x_range <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, n_grid)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>y_range <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, n_grid)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x_range, y_range)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack into points</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> np.stack([X.ravel(), Y.ravel()], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform the grid</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>transformed_points <span class="op">=</span> points <span class="op">@</span> A.T</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>X_transformed <span class="op">=</span> transformed_points[:, <span class="dv">0</span>].reshape(X.shape)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>Y_transformed <span class="op">=</span> transformed_points[:, <span class="dv">1</span>].reshape(Y.shape)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample from 2D Gaussian</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> np.random.multivariate_normal([<span class="dv">0</span>, <span class="dv">0</span>], np.eye(<span class="dv">2</span>), n_samples)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>transformed_samples <span class="op">=</span> samples <span class="op">@</span> A.T</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">7</span>))</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Left plot: Original grid and samples</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw grid lines</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_grid):</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    ax1.plot(X[i, :], Y[i, :], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    ax1.plot(X[:, i], Y[:, i], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw a unit square to highlight</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>square <span class="op">=</span> np.array([[<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">0</span>]])</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>ax1.plot(square[:, <span class="dv">0</span>], square[:, <span class="dv">1</span>], <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="st">'Unit Square'</span>)</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>ax1.fill(square[:, <span class="dv">0</span>], square[:, <span class="dv">1</span>], <span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot samples</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>ax1.scatter(samples[:, <span class="dv">0</span>], samples[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Original Space'</span>)</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>ax1.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>ax1.set_xlim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>ax1.set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Right plot: Transformed grid and samples</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw transformed grid lines</span></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_grid):</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    ax2.plot(X_transformed[i, :], Y_transformed[i, :], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    ax2.plot(X_transformed[:, i], Y_transformed[:, i], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw transformed unit square</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>transformed_square <span class="op">=</span> square <span class="op">@</span> A.T</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>ax2.plot(transformed_square[:, <span class="dv">0</span>], transformed_square[:, <span class="dv">1</span>], <span class="st">'r-'</span>, </span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>         linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="ss">f'Transformed Square (area x </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>det(A)<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>ax2.fill(transformed_square[:, <span class="dv">0</span>], transformed_square[:, <span class="dv">1</span>], <span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot transformed samples</span></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>ax2.scatter(transformed_samples[:, <span class="dv">0</span>], transformed_samples[:, <span class="dv">1</span>], </span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'$y_1$'</span>)</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'$y_2$'</span>)</span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Transformed Space: $y = Ax$'</span>)</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>ax2.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>ax2.set_xlim(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>ax2.set_ylim(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate areas</span></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>original_area <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># Unit square</span></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>transformed_area <span class="op">=</span> np.linalg.det(A) <span class="op">*</span> original_area</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original unit square area: </span><span class="sc">{</span>original_area<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Transformed square area: </span><span class="sc">{</span>transformed_area<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Area scaling factor: </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>det(A)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Transformation matrix A:
[[ 1.73205081 -0.5       ]
 [ 1.          0.8660254 ]]

Determinant (area scaling factor): 2.0000</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Original unit square area: 1.0000
Transformed square area: 2.0000
Area scaling factor: 2.0000

This means density must be scaled by 0.5000 to preserve probability mass</code></pre>
</div>
</div>
</section>
<section id="example-computing-jacobians-with-pytorch" class="level3" data-number="D.2.6">
<h3 data-number="D.2.6" class="anchored" data-anchor-id="example-computing-jacobians-with-pytorch"><span class="header-section-number">D.2.6</span> Example: Computing Jacobians with PyTorch</h3>
<p>Let’s use PyTorch’s automatic differentiation to compute Jacobians for us. This is especially useful for complex non-linear functions for which writing out the analytical gradients might not be practical.</p>
<div id="2a953feb" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a transformation function</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform_2d(x):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">    A nonlinear transformation: </span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">    y1 = x1^2 + 0.5*x2</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">    y2 = x1 + sin(x2)</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    y1 <span class="op">=</span> x[:, <span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> x[:, <span class="dv">1</span>]</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    y2 <span class="op">=</span> x[:, <span class="dv">0</span>] <span class="op">+</span> torch.sin(x[:, <span class="dv">1</span>])</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.stack([y1, y2], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute Jacobian determinant using PyTorch</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> jacobian_determinant(func, x):</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute the Jacobian determinant for a batch of inputs.</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co">        func: transformation function</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co">        x: input tensor of shape (batch_size, input_dim)</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co">        det_J: Jacobian determinants of shape (batch_size,)</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    batch_size, input_dim <span class="op">=</span> x.shape</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    x_var <span class="op">=</span> x.clone().detach().requires_grad_(<span class="va">True</span>)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute Jacobian for each sample</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    jacobians <span class="op">=</span> []</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute Jacobian for single sample</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>        jac <span class="op">=</span> torch.autograd.functional.jacobian(func, x_var[i:i<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>        jac <span class="op">=</span> jac.squeeze()  <span class="co"># Remove batch dimensions</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>        jacobians.append(jac)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    jacobians <span class="op">=</span> torch.stack(jacobians)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute determinants</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    det_J <span class="op">=</span> torch.det(jacobians)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> det_J, jacobians</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize how Jacobian determinant varies across space</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>x1_range <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">30</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>x2_range <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">30</span>)</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>X1, X2 <span class="op">=</span> torch.meshgrid(x1_range, x2_range, indexing<span class="op">=</span><span class="st">'ij'</span>)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>grid_points <span class="op">=</span> torch.stack([X1.flatten(), X2.flatten()], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>det_J_grid, _ <span class="op">=</span> jacobian_determinant(transform_2d, grid_points)</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>det_J_grid <span class="op">=</span> det_J_grid.<span class="bu">abs</span>().reshape(X1.shape)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>contour <span class="op">=</span> ax.contourf(X1.numpy(), X2.numpy(), det_J_grid.detach().numpy(), </span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>                       levels<span class="op">=</span><span class="dv">20</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>plt.colorbar(contour, ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'$|</span><span class="ch">\\</span><span class="st">det(J)|$'</span>)</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Jacobian Determinant Varies Across Space</span><span class="ch">\n</span><span class="st">(shows how much stretching/compression at each point)'</span>)</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Understanding how to compute and interpret Jacobians is useful in many modern machine learning models. The Jacobian determinant tells us the local volume scaling at each point. For nonlinear transformations, this varies across space—some regions expand while others compress.</p>
<p>This is the core principle used in <strong>normalizing flows</strong>: by chaining multiple invertible transformations (each with computable Jacobians), we can transform a simple distribution (like a Gaussian) into arbitrarily complex distributions. The key requirement is that we can compute <span class="math inline">\(|\det(J)|\)</span> efficiently.</p>
<p>Can you think of why we need the transformation to be invertible for normalizing flows? How would you chain multiple transformations together? What happens to the overall Jacobian determinant? (We will revisit these in the relevant generative models chapter.)</p>
</section>
</section>
<section id="linear-algebra-spectral-norms" class="level2" data-number="D.3">
<h2 data-number="D.3" class="anchored" data-anchor-id="linear-algebra-spectral-norms"><span class="header-section-number">D.3</span> Linear Algebra &amp; Spectral Norms</h2>
<section id="concepts-2" class="level3" data-number="D.3.1">
<h3 data-number="D.3.1" class="anchored" data-anchor-id="concepts-2"><span class="header-section-number">D.3.1</span> Concepts:</h3>
<ul>
<li>Matrices represent <strong>linear transformations</strong> that stretch, rotate, and compress space</li>
<li><strong>Singular values</strong> measure how much a matrix stretches along different directions</li>
<li>The <strong>spectral norm</strong> (largest singular value) gives the maximum stretching factor</li>
<li><strong>Matrix conditioning</strong> (ratio of largest to smallest singular value) indicates numerical stability</li>
<li>Understanding these geometric properties is essential for analyzing neural networks and optimization</li>
</ul>
</section>
<section id="key-equations-2" class="level3" data-number="D.3.2">
<h3 data-number="D.3.2" class="anchored" data-anchor-id="key-equations-2"><span class="header-section-number">D.3.2</span> Key Equations:</h3>
<p><strong>Singular Value Decomposition:</strong> <span class="math display">\[A = U \Sigma V^T\]</span> where <span class="math inline">\(U, V\)</span> are orthogonal and <span class="math inline">\(\Sigma\)</span> contains singular values <span class="math inline">\(\sigma_1 \geq \sigma_2 \geq \ldots \geq 0\)</span></p>
<p><strong>Spectral Norm (Matrix 2-norm):</strong> <span class="math display">\[\|A\|_2 = \sigma_{\max}(A) = \max_{\|x\|=1} \|Ax\|\]</span></p>
<p><strong>Condition Number:</strong> <span class="math display">\[\kappa(A) = \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\]</span></p>
<p><strong>Intuition:</strong> The spectral norm tells you “how much can this transformation amplify a vector?” Large spectral norms mean the transformation can greatly magnify small changes in input—this is crucial for understanding gradient flow in deep networks.</p>
</section>
<section id="example-2d-linear-transform-visualization" class="level3" data-number="D.3.3">
<h3 data-number="D.3.3" class="anchored" data-anchor-id="example-2d-linear-transform-visualization"><span class="header-section-number">D.3.3</span> Example: 2D Linear Transform Visualization</h3>
<p>Let’s see how a matrix transforms space by watching what it does to a regular grid. This gives us intuition for singular values and the spectral norm.</p>
<div id="2670ca7e" class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an interesting transformation matrix</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Mix of rotation and stretching</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="fl">2.0</span>, <span class="fl">0.5</span>],</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.3</span>, <span class="fl">1.0</span>]])</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Transformation matrix A:"</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute SVD</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>U, singular_values, Vt <span class="op">=</span> np.linalg.svd(A)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Singular values: </span><span class="sc">{</span>singular_values<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Spectral norm (max singular value): </span><span class="sc">{</span>singular_values[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Condition number: </span><span class="sc">{</span>singular_values[<span class="dv">0</span>]<span class="op">/</span>singular_values[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of points</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>n_grid <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, n_grid)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, n_grid)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create points on grid</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> np.stack([X.ravel(), Y.ravel()], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply transformation</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>transformed_points <span class="op">=</span> A <span class="op">@</span> points</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape back to grid</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>X_trans <span class="op">=</span> transformed_points[<span class="dv">0</span>, :].reshape(X.shape)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>Y_trans <span class="op">=</span> transformed_points[<span class="dv">1</span>, :].reshape(Y.shape)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">7</span>))</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Left: Original grid</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>, aspect<span class="op">=</span><span class="st">'equal'</span>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_grid):</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    ax1.plot(X[i, :], Y[i, :], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    ax1.plot(X[:, i], Y[:, i], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw unit circle</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">100</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>unit_circle_x <span class="op">=</span> np.cos(theta)</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>unit_circle_y <span class="op">=</span> np.sin(theta)</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>ax1.plot(unit_circle_x, unit_circle_y, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="st">'Unit Circle'</span>)</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>ax1.fill(unit_circle_x, unit_circle_y, <span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw coordinate axes</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>ax1.arrow(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.9</span>, <span class="dv">0</span>, head_width<span class="op">=</span><span class="fl">0.05</span>, head_length<span class="op">=</span><span class="fl">0.05</span>, fc<span class="op">=</span><span class="st">'green'</span>, ec<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>ax1.arrow(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.9</span>, head_width<span class="op">=</span><span class="fl">0.05</span>, head_length<span class="op">=</span><span class="fl">0.05</span>, fc<span class="op">=</span><span class="st">'purple'</span>, ec<span class="op">=</span><span class="st">'purple'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>ax1.text(<span class="fl">1.0</span>, <span class="dv">0</span>, <span class="st">'$e_1$'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, color<span class="op">=</span><span class="st">'green'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>ax1.text(<span class="dv">0</span>, <span class="fl">1.0</span>, <span class="st">'$e_2$'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, color<span class="op">=</span><span class="st">'purple'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>ax1.set_xlim(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>ax1.set_ylim(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Original Space'</span>)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Right: Transformed grid</span></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, aspect<span class="op">=</span><span class="st">'equal'</span>)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_grid):</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    ax2.plot(X_trans[i, :], Y_trans[i, :], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>    ax2.plot(X_trans[:, i], Y_trans[:, i], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform unit circle -&gt; ellipse</span></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>ellipse_points <span class="op">=</span> A <span class="op">@</span> np.stack([unit_circle_x, unit_circle_y])</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>ax2.plot(ellipse_points[<span class="dv">0</span>, :], ellipse_points[<span class="dv">1</span>, :], <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, </span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Transformed Circle'</span>)</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>ax2.fill(ellipse_points[<span class="dv">0</span>, :], ellipse_points[<span class="dv">1</span>, :], <span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw transformed coordinate axes</span></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>e1_trans <span class="op">=</span> A <span class="op">@</span> np.array([<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>e2_trans <span class="op">=</span> A <span class="op">@</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, e1_trans[<span class="dv">0</span>]<span class="op">*</span><span class="fl">0.9</span>, e1_trans[<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.9</span>, </span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>          head_width<span class="op">=</span><span class="fl">0.1</span>, head_length<span class="op">=</span><span class="fl">0.1</span>, fc<span class="op">=</span><span class="st">'green'</span>, ec<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, e2_trans[<span class="dv">0</span>]<span class="op">*</span><span class="fl">0.9</span>, e2_trans[<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.9</span>, </span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>          head_width<span class="op">=</span><span class="fl">0.1</span>, head_length<span class="op">=</span><span class="fl">0.1</span>, fc<span class="op">=</span><span class="st">'purple'</span>, ec<span class="op">=</span><span class="st">'purple'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>ax2.text(e1_trans[<span class="dv">0</span>]<span class="op">*</span><span class="fl">1.1</span>, e1_trans[<span class="dv">1</span>]<span class="op">*</span><span class="fl">1.1</span>, <span class="st">'$Ae_1$'</span>, </span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>         fontsize<span class="op">=</span><span class="dv">14</span>, color<span class="op">=</span><span class="st">'green'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>ax2.text(e2_trans[<span class="dv">0</span>]<span class="op">*</span><span class="fl">1.1</span>, e2_trans[<span class="dv">1</span>]<span class="op">*</span><span class="fl">1.1</span>, <span class="st">'$Ae_2$'</span>, </span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>         fontsize<span class="op">=</span><span class="dv">14</span>, color<span class="op">=</span><span class="st">'purple'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw singular vectors</span></span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Right singular vectors (V) point in direction of maximum stretch</span></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a><span class="co"># Left singular vectors (U) point in direction of output</span></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>v1 <span class="op">=</span> Vt[<span class="dv">0</span>, :]  <span class="co"># Direction of max stretch in input</span></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>v2 <span class="op">=</span> Vt[<span class="dv">1</span>, :]  <span class="co"># Direction of min stretch in input</span></span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>u1 <span class="op">=</span> U[:, <span class="dv">0</span>]   <span class="co"># Direction in output</span></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>u2 <span class="op">=</span> U[:, <span class="dv">1</span>]</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw principal directions in transformed space</span></span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>sigma1_vec <span class="op">=</span> singular_values[<span class="dv">0</span>] <span class="op">*</span> u1</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>sigma2_vec <span class="op">=</span> singular_values[<span class="dv">1</span>] <span class="op">*</span> u2</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, sigma1_vec[<span class="dv">0</span>]<span class="op">*</span><span class="fl">0.9</span>, sigma1_vec[<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.9</span>, </span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>          head_width<span class="op">=</span><span class="fl">0.15</span>, head_length<span class="op">=</span><span class="fl">0.15</span>, fc<span class="op">=</span><span class="st">'orange'</span>, ec<span class="op">=</span><span class="st">'orange'</span>, </span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>          linewidth<span class="op">=</span><span class="dv">3</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, sigma2_vec[<span class="dv">0</span>]<span class="op">*</span><span class="fl">0.9</span>, sigma2_vec[<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.9</span>, </span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>          head_width<span class="op">=</span><span class="fl">0.15</span>, head_length<span class="op">=</span><span class="fl">0.15</span>, fc<span class="op">=</span><span class="st">'cyan'</span>, ec<span class="op">=</span><span class="st">'cyan'</span>, </span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>          linewidth<span class="op">=</span><span class="dv">3</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>ax2.set_xlim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>ax2.set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'$y_1$'</span>)</span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'$y_2$'</span>)</span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Transformed Space: $y = Ax$'</span>)</span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Transformation matrix A:
[[2.  0.5]
 [0.3 1. ]]

Singular values: [2.14364206 0.86301721]
Spectral norm (max singular value): 2.1436
Condition number: 2.4839</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The transformation turns a circle into an ellipse. The singular values tell us exactly how much the matrix stretches in its principal directions. The spectral norm is the maximum stretching factor, which in the above example is 2.1436 and the same as the ellipse’s semi-major axis length, with 0.863 being the semi-minor axis length. This is crucial for understanding how errors propagate through linear transformations. For example, in deep learning, if weight matrices have large spectral norms, small input perturbations can get amplified dramatically. What problems do you think this might cause?</p>
</section>
<section id="example-spectral-norms-and-condition-numbers-of-different-matrices" class="level3" data-number="D.3.4">
<h3 data-number="D.3.4" class="anchored" data-anchor-id="example-spectral-norms-and-condition-numbers-of-different-matrices"><span class="header-section-number">D.3.4</span> Example: Spectral Norms and Condition Numbers of Different Matrices</h3>
<p>Let’s explore how different matrices have different spectral properties and what that means for numerical stability.</p>
<div id="9f80aecc" class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code-fold: false</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create different types of matrices</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>matrices <span class="op">=</span> {</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Well-conditioned'</span>: np.array([[<span class="fl">1.0</span>, <span class="fl">0.2</span>], [<span class="fl">0.2</span>, <span class="fl">1.0</span>]]),</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Stretched'</span>: np.array([[<span class="fl">5.0</span>, <span class="fl">0.0</span>], [<span class="fl">0.0</span>, <span class="fl">1.0</span>]]),</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Ill-conditioned'</span>: np.array([[<span class="fl">10.0</span>, <span class="fl">9.99</span>], [<span class="fl">9.99</span>, <span class="fl">10.0</span>]]),</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Nearly singular'</span>: np.array([[<span class="fl">1.0</span>, <span class="fl">1.0</span>], [<span class="fl">1.0</span>, <span class="fl">1.001</span>]])</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze each matrix</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, A <span class="kw">in</span> matrices.items():</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    U, s, Vt <span class="op">=</span> np.linalg.svd(A)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    spectral_norm <span class="op">=</span> s[<span class="dv">0</span>]</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    condition_number <span class="op">=</span> s[<span class="dv">0</span>] <span class="op">/</span> s[<span class="dv">1</span>] <span class="cf">if</span> s[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="fl">1e-10</span> <span class="cf">else</span> np.inf</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    det_A <span class="op">=</span> np.linalg.det(A)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    results[name] <span class="op">=</span> {</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'A'</span>: A,</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'singular_values'</span>: s,</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'spectral_norm'</span>: spectral_norm,</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'condition_number'</span>: condition_number,</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'determinant'</span>: det_A,</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'U'</span>: U,</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Vt'</span>: Vt</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="36d1a572" class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">10</span>))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (name, info) <span class="kw">in</span> <span class="bu">enumerate</span>(results.items()):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Top row: transformed unit circle</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    ax_circle <span class="op">=</span> axes[<span class="dv">0</span>, idx]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw unit circle</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">100</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    circle <span class="op">=</span> np.stack([np.cos(theta), np.sin(theta)])</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform circle</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    ellipse <span class="op">=</span> info[<span class="st">'A'</span>] <span class="op">@</span> circle</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    ax_circle.plot(circle[<span class="dv">0</span>, :], circle[<span class="dv">1</span>, :], <span class="st">'b--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, </span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>                   alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Unit circle'</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    ax_circle.plot(ellipse[<span class="dv">0</span>, :], ellipse[<span class="dv">1</span>, :], <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span><span class="st">'Transformed'</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    ax_circle.fill(ellipse[<span class="dv">0</span>, :], ellipse[<span class="dv">1</span>, :], <span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw singular value directions</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> info[<span class="st">'singular_values'</span>]</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> info[<span class="st">'U'</span>]</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    ax_circle.arrow(<span class="dv">0</span>, <span class="dv">0</span>, s[<span class="dv">0</span>]<span class="op">*</span>U[<span class="dv">0</span>,<span class="dv">0</span>]<span class="op">*</span><span class="fl">0.9</span>, s[<span class="dv">0</span>]<span class="op">*</span>U[<span class="dv">1</span>,<span class="dv">0</span>]<span class="op">*</span><span class="fl">0.9</span>,</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>                    head_width<span class="op">=</span><span class="fl">0.3</span>, head_length<span class="op">=</span><span class="fl">0.2</span>, fc<span class="op">=</span><span class="st">'orange'</span>, ec<span class="op">=</span><span class="st">'orange'</span>,</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>                    linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    ax_circle.arrow(<span class="dv">0</span>, <span class="dv">0</span>, s[<span class="dv">1</span>]<span class="op">*</span>U[<span class="dv">0</span>,<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.9</span>, s[<span class="dv">1</span>]<span class="op">*</span>U[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">*</span><span class="fl">0.9</span>,</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>                    head_width<span class="op">=</span><span class="fl">0.3</span>, head_length<span class="op">=</span><span class="fl">0.2</span>, fc<span class="op">=</span><span class="st">'cyan'</span>, ec<span class="op">=</span><span class="st">'cyan'</span>,</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>                    linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    ax_circle.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    ax_circle.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    ax_circle.set_title(name)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    ax_circle.legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    ax_circle.set_xlim(<span class="op">-</span><span class="dv">12</span>, <span class="dv">12</span>)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    ax_circle.set_ylim(<span class="op">-</span><span class="dv">12</span>, <span class="dv">12</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bottom row: Singular value bar chart</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    ax_sv <span class="op">=</span> axes[<span class="dv">1</span>, idx]</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    ax_sv.bar([<span class="st">'$</span><span class="ch">\\</span><span class="st">sigma_1$'</span>, <span class="st">'$</span><span class="ch">\\</span><span class="st">sigma_2$'</span>], s, color<span class="op">=</span>[<span class="st">'orange'</span>, <span class="st">'cyan'</span>], alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    ax_sv.set_ylabel(<span class="st">'Singular Value'</span>)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    ax_sv.set_title(<span class="ss">f'$</span><span class="ch">\\</span><span class="ss">|A</span><span class="ch">\\</span><span class="ss">|_2$=</span><span class="sc">{</span>info[<span class="st">"spectral_norm"</span>]<span class="sc">:.2f}</span><span class="ss">, $</span><span class="ch">\\</span><span class="ss">kappa$=</span><span class="sc">{</span>info[<span class="st">"condition_number"</span>]<span class="sc">:.1f}</span><span class="ss">'</span>)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    ax_sv.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    ax_sv.set_ylim(<span class="dv">0</span>, <span class="bu">max</span>(s[<span class="dv">0</span>], <span class="dv">10</span>))</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Print detailed comparison</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Matrix Analysis Summary"</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Name'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'‖A‖₂'</span><span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'κ(A)'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'det(A)'</span><span class="sc">:&lt;12}</span><span class="ss">"</span>)</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, info <span class="kw">in</span> results.items():</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    spec_norm <span class="op">=</span> info[<span class="st">'spectral_norm'</span>]</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    cond_num <span class="op">=</span> info[<span class="st">'condition_number'</span>]</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    det_val <span class="op">=</span> info[<span class="st">'determinant'</span>]</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>spec_norm<span class="sc">:&lt;12.4f}</span><span class="ss"> </span><span class="sc">{</span>cond_num<span class="sc">:&lt;15.2f}</span><span class="ss"> </span><span class="sc">{</span>det_val<span class="sc">:&lt;12.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Matrix Analysis Summary
================================================================================
Name                 ‖A‖₂         κ(A)            det(A)      
--------------------------------------------------------------------------------
Well-conditioned     1.2000       1.50            0.960000    
Stretched            5.0000       5.00            5.000000    
Ill-conditioned      19.9900      1999.00         0.199900    
Nearly singular      2.0005       4002.00         0.001000    </code></pre>
</div>
</div>
<p>We see that for well-conditioned matrices, they have a small condition number that barely amplifies or stretches the origina data. As we increase the condition number, small perturbations in the input can cause large changes in the output matrix. However, even if the spectral norm is small, the matrix can still have a large condition number, which can make the matrix difficult to invert or compute stable gradients with respect to.</p>
</section>
<section id="example-neural-network-jacobian-and-local-geometry" class="level3" data-number="D.3.5">
<h3 data-number="D.3.5" class="anchored" data-anchor-id="example-neural-network-jacobian-and-local-geometry"><span class="header-section-number">D.3.5</span> Example: Neural Network Jacobian and Local Geometry</h3>
<p>Neural networks are compositions of nonlinear transformations. At any point, the local behavior is captured by the Jacobian matrix. Let’s visualize how a simple neural network transforms space locally.</p>
<div id="b665ba10" class="cell" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a simple 2-layer neural network: R^2 -&gt; R^2</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNet(nn.Module):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">2</span>, <span class="dv">8</span>, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">8</span>, <span class="dv">2</span>, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.tanh(<span class="va">self</span>.fc1(x))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize network with specific seed</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> SimpleNet()</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute Jacobian at a point</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_jacobian(model, x):</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute Jacobian matrix of model output w.r.t. input at point x"""</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    x_tensor <span class="op">=</span> torch.tensor(x, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> model(x_tensor.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    jacobian <span class="op">=</span> []</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y.shape[<span class="dv">1</span>]):</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        grad <span class="op">=</span> torch.autograd.grad(y[<span class="dv">0</span>, i], x_tensor, </span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>                                   create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        jacobian.append(grad.detach().numpy())</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(jacobian)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize transformation at different points in space</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>test_points <span class="op">=</span> [</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>]),</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    np.array([<span class="fl">1.0</span>, <span class="fl">1.0</span>]),</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    np.array([<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.5</span>]),</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="b5907933" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, point <span class="kw">in</span> <span class="bu">enumerate</span>(test_points):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute Jacobian at this point</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> compute_jacobian(net, point)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute singular values</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    U, s, Vt <span class="op">=</span> np.linalg.svd(J)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    spectral_norm <span class="op">=</span> s[<span class="dv">0</span>]</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a small grid around the point</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    delta <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    n_grid <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    x_local <span class="op">=</span> np.linspace(<span class="op">-</span>delta, delta, n_grid)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    y_local <span class="op">=</span> np.linspace(<span class="op">-</span>delta, delta, n_grid)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    X_local, Y_local <span class="op">=</span> np.meshgrid(x_local, y_local)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform grid through network</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    grid_points <span class="op">=</span> np.stack([X_local.ravel() <span class="op">+</span> point[<span class="dv">0</span>], </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>                           Y_local.ravel() <span class="op">+</span> point[<span class="dv">1</span>]], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        grid_tensor <span class="op">=</span> torch.tensor(grid_points.T, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        transformed <span class="op">=</span> net(grid_tensor).numpy()</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    X_trans <span class="op">=</span> transformed[:, <span class="dv">0</span>].reshape(X_local.shape)</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    Y_trans <span class="op">=</span> transformed[:, <span class="dv">1</span>].reshape(Y_local.shape)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot transformed grid</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_grid):</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        ax.plot(X_trans[i, :], Y_trans[i, :], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        ax.plot(X_trans[:, i], Y_trans[:, i], <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw a small circle around the point and its transformation</span></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">50</span>)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    radius <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>    circle <span class="op">=</span> radius <span class="op">*</span> np.stack([np.cos(theta), np.sin(theta)])</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>    circle_centered <span class="op">=</span> circle <span class="op">+</span> point[:, np.newaxis]</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        circle_tensor <span class="op">=</span> torch.tensor(circle_centered.T, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        circle_transformed <span class="op">=</span> net(circle_tensor).numpy()</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    ax.plot(circle_transformed[:, <span class="dv">0</span>], circle_transformed[:, <span class="dv">1</span>], <span class="st">'r-'</span>, </span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>            linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="st">'Transformed circle'</span>)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw ellipse predicted by linear approximation (Jacobian)</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform centered circle with Jacobian, then translate</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        point_tensor <span class="op">=</span> torch.tensor(point, dtype<span class="op">=</span>torch.float32).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        center_transformed <span class="op">=</span> net(point_tensor).numpy()[<span class="dv">0</span>]</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>    ellipse_linear <span class="op">=</span> J <span class="op">@</span> circle <span class="op">+</span> center_transformed[:, np.newaxis]</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>    ax.plot(ellipse_linear[<span class="dv">0</span>, :], ellipse_linear[<span class="dv">1</span>, :], <span class="st">'g--'</span>, </span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>            linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Linear approximation'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>    ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'At point </span><span class="sc">{</span>point<span class="sc">}</span><span class="ch">\n</span><span class="ss">$</span><span class="ch">\\</span><span class="ss">|J</span><span class="ch">\\</span><span class="ss">|_2$ = </span><span class="sc">{</span>spectral_norm<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Output dim 1'</span>)</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Output dim 2'</span>)</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Print Jacobian analysis</span></span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> point <span class="kw">in</span> test_points:</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> compute_jacobian(net, point)</span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a>    U, s, Vt <span class="op">=</span> np.linalg.svd(J)</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">At point </span><span class="sc">{</span>point<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Jacobian matrix:"</span>)</span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(J)</span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Singular values: </span><span class="sc">{</span>s<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Spectral norm: </span><span class="sc">{</span>s[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Condition number: </span><span class="sc">{</span>s[<span class="dv">0</span>]<span class="op">/</span>s[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
At point [0. 0.]:
Jacobian matrix:
[[-0.12561867 -0.3354176 ]
 [ 0.23783804  0.2557892 ]]
Singular values: [0.4907707  0.09707827]
Spectral norm: 0.4908
Condition number: 5.0554

At point [1. 1.]:
Jacobian matrix:
[[ 0.04538195 -0.19429947]
 [ 0.10090272  0.12735607]]
Singular values: [0.23314807 0.10887937]
Spectral norm: 0.2331
Condition number: 2.1413

At point [-1.   0.5]:
Jacobian matrix:
[[-0.20401104 -0.28298327]
 [ 0.20504908  0.24390957]]
Singular values: [0.47215527 0.01750529]
Spectral norm: 0.4722
Condition number: 26.9721</code></pre>
</div>
</div>
<p>We can see that the neural network’s Jacobian is changing across the input space. The Jacobian tells us how the neural network behaves locally—like a linear approximation at each point. The red curve shows the actual transformation of a small circle, while the green dashed line shows what the Jacobian predicts. When they match well, the network is locally linear; when they diverge, the nonlinearity is strong.</p>
</section>
<section id="example-spectral-normalization" class="level3" data-number="D.3.6">
<h3 data-number="D.3.6" class="anchored" data-anchor-id="example-spectral-normalization"><span class="header-section-number">D.3.6</span> Example: Spectral Normalization</h3>
<p>Spectral normalization is a technique to control the Lipschitz constant of neural networks by constraining weight matrices to have spectral norm <span class="math inline">\(\leq 1\)</span>. Let’s see how this affects the transformation.</p>
<div id="f17fab6b" class="cell" data-execution_count="39">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to apply spectral normalization to a weight matrix</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> spectral_normalize(W, n_iterations<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Normalize a weight matrix so its spectral norm is 1.</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Uses power iteration to estimate the largest singular value.</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    U, s, Vt <span class="op">=</span> np.linalg.svd(W, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    sigma_max <span class="op">=</span> s[<span class="dv">0</span>]</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> W <span class="op">/</span> sigma_max, sigma_max</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create two versions of a weight matrix</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>W_original <span class="op">=</span> np.random.randn(<span class="dv">2</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="dv">2</span>  <span class="co"># Scaled up for effect</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply spectral normalization</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>W_normalized, original_spectral_norm <span class="op">=</span> spectral_normalize(W_original)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="f820854f" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original weight matrix:"</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(W_original)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Spectral norm: </span><span class="sc">{</span>original_spectral_norm<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Spectral normalized weight matrix:"</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(W_normalized)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Spectral norm: </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>svd(W_normalized, compute_uv<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the effect on unit circle</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">100</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>unit_circle <span class="op">=</span> np.stack([np.cos(theta), np.sin(theta)])</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>transformed_original <span class="op">=</span> W_original <span class="op">@</span> unit_circle</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>transformed_normalized <span class="op">=</span> W_normalized <span class="op">@</span> unit_circle</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Left: Original transformation</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> axes[<span class="dv">0</span>]</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>ax.plot(unit_circle[<span class="dv">0</span>, :], unit_circle[<span class="dv">1</span>, :], <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'Unit circle'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>ax.plot(transformed_original[<span class="dv">0</span>, :], transformed_original[<span class="dv">1</span>, :], <span class="st">'r-'</span>, </span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="st">'Transformed'</span>)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>ax.fill(transformed_original[<span class="dv">0</span>, :], transformed_original[<span class="dv">1</span>, :], <span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="ss">f'Original Weights</span><span class="ch">\n</span><span class="ss">Spectral Norm = </span><span class="sc">{</span>original_spectral_norm<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Middle: Normalized transformation</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> axes[<span class="dv">1</span>]</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>ax.plot(unit_circle[<span class="dv">0</span>, :], unit_circle[<span class="dv">1</span>, :], <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'Unit circle'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>ax.plot(transformed_normalized[<span class="dv">0</span>, :], transformed_normalized[<span class="dv">1</span>, :], <span class="st">'g-'</span>, </span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="st">'Transformed'</span>)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>ax.fill(transformed_normalized[<span class="dv">0</span>, :], transformed_normalized[<span class="dv">1</span>, :], <span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw unit circle as reference</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>circle_ref <span class="op">=</span> plt.Circle((<span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">1</span>, fill<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>                        linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="st">'Unit circle reference'</span>)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>ax.add_patch(circle_ref)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Spectral Normalized</span><span class="ch">\n</span><span class="st">Spectral Norm = 1.000'</span>)</span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Right: Comparison</span></span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> axes[<span class="dv">2</span>]</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a>ax.plot(unit_circle[<span class="dv">0</span>, :], unit_circle[<span class="dv">1</span>, :], <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'Input'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>ax.plot(transformed_original[<span class="dv">0</span>, :], transformed_original[<span class="dv">1</span>, :], <span class="st">'r-'</span>, </span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Original'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>ax.plot(transformed_normalized[<span class="dv">0</span>, :], transformed_normalized[<span class="dv">1</span>, :], <span class="st">'g-'</span>, </span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Normalized'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Comparison'</span>)</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'$x_1$'</span>)</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'$x_2$'</span>)</span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original weight matrix:
[[ 0.99342831 -0.2765286 ]
 [ 1.29537708  3.04605971]]
Spectral norm: 3.3131

Spectral normalized weight matrix:
[[ 0.29985151 -0.08346603]
 [ 0.39099024  0.91940767]]
Spectral norm: 1.0000</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-17-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Spectral normalization ensures that no input vector gets amplified by more than a factor of 1. This is useful for training stability in deep networks since repeated multiplications by weight matrices with large spectral norms can cause gradients to explode. It can also have benefits in cases where we might wish to bound the amount that a given input perturbation can affect a network (e.g., for adversarial robustness).</p>
</section>
</section>
<section id="differentiation-curvature" class="level2" data-number="D.4">
<h2 data-number="D.4" class="anchored" data-anchor-id="differentiation-curvature"><span class="header-section-number">D.4</span> Differentiation &amp; Curvature</h2>
<section id="concepts-3" class="level3" data-number="D.4.1">
<h3 data-number="D.4.1" class="anchored" data-anchor-id="concepts-3"><span class="header-section-number">D.4.1</span> Concepts:</h3>
<ul>
<li><strong>Gradients</strong> point in the direction of steepest ascent and guide first-order optimization</li>
<li><strong>Hessians</strong> capture curvature (second-order information) about the function’s shape</li>
<li><strong>Jacobian-vector products (JVPs)</strong> and <strong>Hessian-vector products (HVPs)</strong> allow efficient computation without forming full matrices</li>
<li>Curvature determines optimization difficulty: flat regions are slow, steep valleys cause oscillation</li>
<li>Understanding higher-order structure is useful for advanced optimization and model analysis</li>
</ul>
</section>
<section id="key-equations-3" class="level3" data-number="D.4.2">
<h3 data-number="D.4.2" class="anchored" data-anchor-id="key-equations-3"><span class="header-section-number">D.4.2</span> Key Equations:</h3>
<p><strong>Gradient (First derivative):</strong> <span class="math display">\[\nabla f(x) = \begin{bmatrix} \frac{\partial f}{\partial x_1} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{bmatrix}\]</span></p>
<p><strong>Hessian (Second derivative matrix):</strong> <span class="math display">\[H(f)(x) = \begin{bmatrix} \frac{\partial^2 f}{\partial x_i \partial x_j} \end{bmatrix}\]</span></p>
<p><strong>Intuition:</strong> The gradient tells you which way is “downhill,” but the Hessian tells you how quickly the slope is changing. Various optimizers like Newton’s method or L-BFGS can use curvature to take smarter steps than simple gradient descent.</p>
</section>
<section id="example-gradient-and-hessian-visualization" class="level3" data-number="D.4.3">
<h3 data-number="D.4.3" class="anchored" data-anchor-id="example-gradient-and-hessian-visualization"><span class="header-section-number">D.4.3</span> Example: Gradient and Hessian Visualization</h3>
<p>Let’s visualize how the gradient (slope) and Hessian (curvature) change at different points along a function. We’ll use <span class="math inline">\(f(x) = x^3 - 3x\)</span> and detect different gradient and curvature regions.</p>
<div id="329b9cb3" class="cell" data-execution_count="44">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define function and its derivatives</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""f(x) = x^3 - 3x"""</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x<span class="op">**</span><span class="dv">3</span> <span class="op">-</span> <span class="dv">3</span><span class="op">*</span>x</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f_prime(x):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""First derivative: f'(x) = 3x^2 - 3"""</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">3</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">3</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f_double_prime(x):</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Second derivative: f''(x) = 6x"""</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">6</span><span class="op">*</span>x</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Points to analyze</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>test_points <span class="op">=</span> [<span class="op">-</span><span class="fl">1.5</span>, <span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">1.5</span>]</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create grid for plotting</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>x_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">500</span>)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>y_grid <span class="op">=</span> f(x_grid)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="bu">len</span>(test_points), figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">8</span>))</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, x0 <span class="kw">in</span> <span class="bu">enumerate</span>(test_points):</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute derivatives at x0</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    y0 <span class="op">=</span> f(x0)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    gradient <span class="op">=</span> f_prime(x0)</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    hessian <span class="op">=</span> f_double_prime(x0)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Top row: Function with tangent line</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    ax_top <span class="op">=</span> axes[<span class="dv">0</span>, idx]</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>    ax_top.plot(x_grid, y_grid, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'$f(x)$'</span>)</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    ax_top.plot(x0, y0, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="ss">f'$x_0=</span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw tangent line</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    tangent_x <span class="op">=</span> np.linspace(x0 <span class="op">-</span> <span class="fl">0.5</span>, x0 <span class="op">+</span> <span class="fl">0.5</span>, <span class="dv">100</span>)</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    tangent_y <span class="op">=</span> y0 <span class="op">+</span> gradient <span class="op">*</span> (tangent_x <span class="op">-</span> x0)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>    ax_top.plot(tangent_x, tangent_y, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Tangent'</span>)</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw gradient arrow</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    arrow_scale <span class="op">=</span> <span class="fl">0.3</span></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    ax_top.arrow(x0, y0, arrow_scale, gradient <span class="op">*</span> arrow_scale,</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>                 head_width<span class="op">=</span><span class="fl">0.3</span>, head_length<span class="op">=</span><span class="fl">0.15</span>, fc<span class="op">=</span><span class="st">'orange'</span>, ec<span class="op">=</span><span class="st">'orange'</span>,</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>                 linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>    ax_top.set_xlabel(<span class="st">'$x$'</span>)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    ax_top.set_ylabel(<span class="st">'$f(x)$'</span>)</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>    ax_top.set_title(<span class="ss">f'$x_0 = </span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$</span><span class="ch">\n</span><span class="ss">$f</span><span class="ch">\'</span><span class="ss">(x_0) = </span><span class="sc">{</span>gradient<span class="sc">:.2f}</span><span class="ss">$'</span>)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>    ax_top.legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>    ax_top.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    ax_top.set_xlim(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>    ax_top.set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bottom row: Second derivative (curvature)</span></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>    ax_bottom <span class="op">=</span> axes[<span class="dv">1</span>, idx]</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>    ax_bottom.plot(x_grid, f_double_prime(x_grid), <span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'$f</span><span class="ch">\'\'</span><span class="st">(x)$'</span>)</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>    ax_bottom.plot(x0, hessian, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="ss">f'$f</span><span class="ch">\'\'</span><span class="ss">(x_0)=</span><span class="sc">{</span>hessian<span class="sc">:.2f}</span><span class="ss">$'</span>)</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>    ax_bottom.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Shade regions</span></span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> hessian <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>        ax_bottom.axvspan(x0 <span class="op">-</span> <span class="fl">0.3</span>, x0 <span class="op">+</span> <span class="fl">0.3</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'blue'</span>, </span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>                          label<span class="op">=</span><span class="st">'Convex (positive curvature)'</span>)</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> hessian <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>        ax_bottom.axvspan(x0 <span class="op">-</span> <span class="fl">0.3</span>, x0 <span class="op">+</span> <span class="fl">0.3</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'red'</span>,</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>                          label<span class="op">=</span><span class="st">'Concave (negative curvature)'</span>)</span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>        ax_bottom.axvspan(x0 <span class="op">-</span> <span class="fl">0.3</span>, x0 <span class="op">+</span> <span class="fl">0.3</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'gray'</span>,</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>                          label<span class="op">=</span><span class="st">'Inflection point'</span>)</span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>    ax_bottom.set_xlabel(<span class="st">'$x$'</span>)</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a>    ax_bottom.set_ylabel(<span class="st">'$f</span><span class="ch">\'\'</span><span class="st">(x)$'</span>)</span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>    ax_bottom.set_title(<span class="ss">f'Curvature at $x_0 = </span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>    ax_bottom.legend(fontsize<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a>    ax_bottom.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>    ax_bottom.set_xlim(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a>    ax_bottom.set_ylim(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The gradient tells you the instantaneous rate of change (the slope of the tangent line), while the Hessian tells you how fast that slope is changing (the curvature). When the Hessian is positive, the function curves upward like a bowl—this is where gradient descent naturally converges. When it’s negative, the function curves downward—a local maximum. At the inflection point (x=0), the curvature is zero.</p>
</section>
<section id="example-reducing-computational-cost-using-jvps-and-hvps" class="level3" data-number="D.4.4">
<h3 data-number="D.4.4" class="anchored" data-anchor-id="example-reducing-computational-cost-using-jvps-and-hvps"><span class="header-section-number">D.4.4</span> Example: Reducing Computational Cost using JVPs and HVPs</h3>
<p>Jacobian-vector products (JVPs) and Hessian-vector products (HVPs) let us compute directional derivatives efficiently without forming the full Jacobian or Hessian matrix. This is crucial for large-scale problems. We will first see how this works on a simple 2D function, and then later move to a more realistic case of a Neural Network.</p>
<div id="f9628a84" class="cell" data-execution_count="57">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A simple 2D function f(x, y)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(xy):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> xy[..., <span class="dv">0</span>], xy[..., <span class="dv">1</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>) <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> x <span class="op">*</span> y<span class="op">**</span><span class="dv">3</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">2.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>f_val <span class="op">=</span> f(xy)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient (Jacobian of f wrt xy)</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># create_graph=True so we can differentiate the gradient later</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>grad <span class="op">=</span> torch.autograd.grad(f_val, xy, create_graph<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gradient:"</span>, grad)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose a direction vector v (match dtype/device of xy)</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="op">-</span><span class="fl">0.5</span>], dtype<span class="op">=</span>xy.dtype, device<span class="op">=</span>xy.device)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Directional derivative (scalar): ∇f(x) · v</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>jvp_scalar <span class="op">=</span> (grad <span class="op">*</span> v).<span class="bu">sum</span>()</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Directional derivative (∇f · v):"</span>, jvp_scalar.item())</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Hessian-vector product: H·v = ∇_x (∇f · v)</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>hvp <span class="op">=</span> torch.autograd.grad(jvp_scalar, xy)[<span class="dv">0</span>]</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Hessian-Vector Product (H·v):"</span>, hvp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gradient: tensor([ 6., 10.], grad_fn=&lt;AddBackward0&gt;)
Directional derivative (∇f · v): 1.0
Hessian-Vector Product (H·v): tensor([-1.,  2.])</code></pre>
</div>
</div>
<div id="374b64bc" class="cell" data-execution_count="58">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sweep along direction v</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> xy <span class="op">+</span> alphas[:, <span class="va">None</span>] <span class="op">*</span> v</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>f_vals <span class="op">=</span> torch.stack([f(p) <span class="cf">for</span> p <span class="kw">in</span> points]).detach()</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># First and second order Taylor approximations</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>f0 <span class="op">=</span> f_val.detach()</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>grad_v <span class="op">=</span> (grad <span class="op">@</span> v).detach()</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>curv_v <span class="op">=</span> (v <span class="op">@</span> hvp).detach()</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>f_linear <span class="op">=</span> f0 <span class="op">+</span> alphas <span class="op">*</span> grad_v</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>f_quadratic <span class="op">=</span> f0 <span class="op">+</span> alphas <span class="op">*</span> grad_v <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> (alphas<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> curv_v</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>plt.plot(alphas, f_vals, label<span class="op">=</span><span class="st">"True f(x + αv)"</span>)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>plt.plot(alphas, f_linear, <span class="st">'--'</span>, label<span class="op">=</span><span class="st">"1st order (JVP)"</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>plt.plot(alphas, f_quadratic, <span class="st">':'</span>, label<span class="op">=</span><span class="st">"2nd order (HVP)"</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"α (step along v)"</span>)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"f(x + αv)"</span>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Directional derivatives and curvature via JVP/HVP"</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now let’s show how this might be useful in a Neural Network context:</p>
<div id="5991592c" class="cell" data-execution_count="69">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Small network: 2 inputs → 4 hidden → 1 output</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> nn.Sequential(</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">2</span>, <span class="dv">4</span>),</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    nn.Tanh(),</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Make output scalar to ensure gradients are well-defined for higher-order derivatives</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> net(x).<span class="bu">sum</span>()  <span class="co"># sum to scalar</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect parameters</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [p <span class="cf">for</span> p <span class="kw">in</span> net.parameters() <span class="cf">if</span> p.requires_grad]</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="co"># First-order gradients (create_graph=True so we can compute higher-order derivatives)</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>grads <span class="op">=</span> torch.autograd.grad(y, params, create_graph<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Random direction in parameter space</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> [torch.randn_like(p) <span class="cf">for</span> p <span class="kw">in</span> params]</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute JVP contributions per-parameter (these are tensors shaped like each parameter)</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>jvp_per_param <span class="op">=</span> [g <span class="op">*</span> vi <span class="cf">for</span> g, vi <span class="kw">in</span> <span class="bu">zip</span>(grads, v)]</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar directional derivative (sum over all parameters) = (∂y/∂θ) · v</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>jvp_scalar <span class="op">=</span> <span class="bu">sum</span>((jp).<span class="bu">sum</span>() <span class="cf">for</span> jp <span class="kw">in</span> jvp_per_param)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Hessian-vector product H·v computed as gradient of the scalar jvp_scalar w.r.t. params</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a><span class="co"># allow_unused=True may return None for parameters that did not contribute to jvp_scalar</span></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>hvp <span class="op">=</span> torch.autograd.grad(jvp_scalar, params, retain_graph<span class="op">=</span><span class="va">True</span>, allow_unused<span class="op">=</span><span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="90913948" class="cell" data-execution_count="70">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Report norms (handle possible None entries safely)</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (p, j_contrib, h) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(params, jvp_per_param, hvp)):</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># j_contrib is the per-parameter contribution to the JVP; take its norm if available</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        j_norm <span class="op">=</span> j_contrib.norm().item() <span class="cf">if</span> j_contrib <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="bu">float</span>(<span class="st">'nan'</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        j_norm <span class="op">=</span> <span class="bu">float</span>(<span class="st">'nan'</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># h may be None if the corresponding parameter did not affect jvp_scalar</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        h_norm <span class="op">=</span> h.norm().item() <span class="cf">if</span> (h <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> <span class="bu">isinstance</span>(h, torch.Tensor)) <span class="cf">else</span> <span class="bu">float</span>(<span class="st">'nan'</span>)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        h_norm <span class="op">=</span> <span class="bu">float</span>(<span class="st">'nan'</span>)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Layer </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> | Param shape </span><span class="sc">{</span><span class="bu">tuple</span>(p.shape)<span class="sc">}</span><span class="ss"> | JVP contrib norm=</span><span class="sc">{</span>j_norm<span class="sc">:.3f}</span><span class="ss"> | HVP norm=</span><span class="sc">{</span>h_norm<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Layer 0 | Param shape (4, 2) | JVP contrib norm=0.246 | HVP norm=2.030
Layer 1 | Param shape (4,) | JVP contrib norm=0.176 | HVP norm=1.066
Layer 2 | Param shape (1, 4) | JVP contrib norm=1.220 | HVP norm=0.983
Layer 3 | Param shape (1,) | JVP contrib norm=0.027 | HVP norm=nan</code></pre>
</div>
</div>
<div id="233a6d56" class="cell" data-execution_count="71">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize how the output changes along an input direction</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> net</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> model(x)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>, <span class="fl">0.0</span>]])</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>y_val, jvp <span class="op">=</span> torch.autograd.functional.jvp(model, x, v)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">100</span>).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> [model(x <span class="op">+</span> α<span class="op">*</span>v).item() <span class="cf">for</span> α <span class="kw">in</span> alphas]</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>plt.plot(alphas, outputs, label<span class="op">=</span><span class="st">"True model output"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>plt.plot(alphas, y_val.item() <span class="op">+</span> alphas<span class="op">*</span>jvp.item(), <span class="st">'--'</span>, label<span class="op">=</span><span class="st">"Linearized (JVP)"</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Step along v"</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Model output"</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Local linear approximation using JVP"</span>)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The full Hessian of a neural network with <span class="math inline">\(p\)</span> parameters is a <span class="math inline">\(p \times p\)</span> matrix, and for modern networks with millions of parameters, this is completely infeasible. JVPs and HVPs give us access to gradient and curvature information, respectively. along specific directions at a fraction of the cost.</p>
</section>
</section>
<section id="marginalization-of-probability-distributions" class="level2" data-number="D.5">
<h2 data-number="D.5" class="anchored" data-anchor-id="marginalization-of-probability-distributions"><span class="header-section-number">D.5</span> Marginalization of Probability Distributions</h2>
<section id="concepts-4" class="level3" data-number="D.5.1">
<h3 data-number="D.5.1" class="anchored" data-anchor-id="concepts-4"><span class="header-section-number">D.5.1</span> Concepts:</h3>
<ul>
<li><strong>Joint distributions</strong> <span class="math inline">\(p(x, z)\)</span> describe the probability of multiple variables together</li>
<li><strong>Marginal distributions</strong> <span class="math inline">\(p(x)\)</span> are obtained by integrating (or summing) out other variables</li>
<li>Marginalization is fundamental to probabilistic inference and latent variable models</li>
<li>For continuous variables: <span class="math inline">\(p(x) = \int p(x, z) dz\)</span></li>
<li>For discrete variables: <span class="math inline">\(p(x) = \sum_z p(x, z)\)</span></li>
<li>This operation removes nuisance variables and reveals the distribution of the variable we care about</li>
</ul>
</section>
<section id="key-equations-4" class="level3" data-number="D.5.2">
<h3 data-number="D.5.2" class="anchored" data-anchor-id="key-equations-4"><span class="header-section-number">D.5.2</span> Key Equations:</h3>
<p><strong>Marginalization (continuous):</strong> <span class="math display">\[p(x) = \int p(x, z) \, dz\]</span></p>
<p><strong>Law of Total Probability:</strong> <span class="math display">\[p(x) = \int p(x | z) p(z) \, dz = \mathbb{E}_Z[p(x|Z)]\]</span></p>
<p><strong>Conditional Distribution:</strong> <span class="math display">\[p(x | z) = \frac{p(x, z)}{p(z)}\]</span></p>
<p><strong>Intuition:</strong> Marginalization asks “what’s the probability of <span class="math inline">\(x\)</span>, averaging over all possible values of <span class="math inline">\(z\)</span>?” It’s like projecting a 2D distribution onto a 1D axis: you’re summing up all the probability mass along one direction.</p>
</section>
<section id="example-2d-gaussian-marginalization" class="level3" data-number="D.5.3">
<h3 data-number="D.5.3" class="anchored" data-anchor-id="example-2d-gaussian-marginalization"><span class="header-section-number">D.5.3</span> Example: 2D Gaussian Marginalization</h3>
<p>Let’s visualize a 2D Gaussian distribution and see what happens when we marginalize out one variable. This is the foundation for understanding latent variable models.</p>
<div id="7497309c" class="cell" data-execution_count="76">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a 2D Gaussian with correlation</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">2.0</span>])</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">0.7</span>],</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                [<span class="fl">0.7</span>, <span class="fl">1.5</span>]])</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>x_range <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">100</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>z_range <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">100</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>X, Z <span class="op">=</span> np.meshgrid(x_range, z_range)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate joint density p(x, z)</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> np.dstack((X, Z))</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>joint_dist <span class="op">=</span> multivariate_normal(mean, cov)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>joint_pdf <span class="op">=</span> joint_dist.pdf(pos)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute marginal p(x) by integrating over z</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a><span class="co"># For a Gaussian, this is analytically known: p(x) ~ N(μ_x, Σ_xx)</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>marginal_x_mean <span class="op">=</span> mean[<span class="dv">0</span>]</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>marginal_x_var <span class="op">=</span> cov[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>marginal_x <span class="op">=</span> stats.norm(marginal_x_mean, np.sqrt(marginal_x_var))</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>marginal_x_pdf <span class="op">=</span> marginal_x.pdf(x_range)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute marginal p(z) by integrating over x</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>marginal_z_mean <span class="op">=</span> mean[<span class="dv">1</span>]</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>marginal_z_var <span class="op">=</span> cov[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>marginal_z <span class="op">=</span> stats.norm(marginal_z_mean, np.sqrt(marginal_z_var))</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>marginal_z_pdf <span class="op">=</span> marginal_z.pdf(z_range)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Numerical integration to verify</span></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>marginal_x_numerical <span class="op">=</span> np.trapezoid(joint_pdf, z_range, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>marginal_z_numerical <span class="op">=</span> np.trapezoid(joint_pdf, x_range, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize numerical marginals</span></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>marginal_x_numerical <span class="op">=</span> marginal_x_numerical <span class="op">/</span> np.trapezoid(marginal_x_numerical, x_range)</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>marginal_z_numerical <span class="op">=</span> marginal_z_numerical <span class="op">/</span> np.trapezoid(marginal_z_numerical, z_range)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">12</span>))</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Top-left: 2D joint distribution</span></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> plt.subplot2grid((<span class="dv">3</span>, <span class="dv">3</span>), (<span class="dv">0</span>, <span class="dv">0</span>), colspan<span class="op">=</span><span class="dv">2</span>, rowspan<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>contour <span class="op">=</span> ax1.contourf(X, Z, joint_pdf, levels<span class="op">=</span><span class="dv">20</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>ax1.contour(X, Z, joint_pdf, levels<span class="op">=</span><span class="dv">10</span>, colors<span class="op">=</span><span class="st">'white'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.colorbar(contour, ax=ax1, label='$p(x, z)$')</span></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'$x$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'$z$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Joint Distribution $p(x, z)$'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Top-right: Marginal p(z)</span></span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> plt.subplot2grid((<span class="dv">3</span>, <span class="dv">3</span>), (<span class="dv">0</span>, <span class="dv">2</span>), rowspan<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>ax2.plot(marginal_z_pdf, z_range, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Analytical $p(z)$'</span>)</span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>ax2.plot(marginal_z_numerical, z_range, <span class="st">'b--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'Numerical'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>ax2.fill_betweenx(z_range, <span class="dv">0</span>, marginal_z_pdf, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'$z$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'$p(z)$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Marginal $p(z)$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>ax2.legend(fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>ax2.set_ylim(z_range[<span class="dv">0</span>], z_range[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Bottom-left: Marginal p(x)</span></span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>ax3 <span class="op">=</span> plt.subplot2grid((<span class="dv">3</span>, <span class="dv">3</span>), (<span class="dv">2</span>, <span class="dv">0</span>), colspan<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>ax3.plot(x_range, marginal_x_pdf, <span class="st">'g-'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Analytical $p(x)$'</span>)</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>ax3.plot(x_range, marginal_x_numerical, <span class="st">'b--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">'Numerical'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>ax3.fill_between(x_range, <span class="dv">0</span>, marginal_x_pdf, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>ax3.set_xlabel(<span class="st">'$x$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>ax3.set_ylabel(<span class="st">'$p(x)$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>ax3.set_title(<span class="st">'Marginal $p(x)$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>ax3.legend(fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a>ax3.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>ax3.set_xlim(x_range[<span class="dv">0</span>], x_range[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Marginalization “collapses” the joint distribution onto one axis by integrating out the other variable. Think of it as viewing the shadow of a 3D object—you lose information about one dimension but get a simpler view.</p>
<p>The marginal distributions don’t tell you anything about the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span>. If you only observe <span class="math inline">\(p(x)\)</span> and <span class="math inline">\(p(z)\)</span> separately, could you reconstruct <span class="math inline">\(p(x, z)\)</span>?</p>
</section>
<section id="example-conditional-sampling-and-the-joint-distribution" class="level3" data-number="D.5.4">
<h3 data-number="D.5.4" class="anchored" data-anchor-id="example-conditional-sampling-and-the-joint-distribution"><span class="header-section-number">D.5.4</span> Example: Conditional Sampling and the Joint Distribution</h3>
<p>The joint distribution can be decomposed as <span class="math inline">\(p(x, z) = p(x|z) p(z)\)</span>. Let’s visualize how conditionals <span class="math inline">\(p(x|z)\)</span> for different values of <span class="math inline">\(z\)</span> shape the joint distribution.</p>
<div id="0dba11cd" class="cell" data-execution_count="78">
<details class="code-fold">
<summary>Show Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use same joint distribution as before</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">2.0</span>])</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">0.7</span>],</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                [<span class="fl">0.7</span>, <span class="fl">1.5</span>]])</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>joint_dist <span class="op">=</span> multivariate_normal(mean, cov)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Select several z values to condition on</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>z_values <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">7</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># For each z, compute the conditional p(x | z)</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co"># For a 2D Gaussian: p(x|z) ~ N(μ_x + (Σ_xz/Σ_zz)(z - μ_z), Σ_xx - Σ_xz²/Σ_zz)</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conditional_params(z_val):</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute parameters of p(x|z) for a 2D Gaussian"""</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    mu_x, mu_z <span class="op">=</span> mean[<span class="dv">0</span>], mean[<span class="dv">1</span>]</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    sigma_xx <span class="op">=</span> cov[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    sigma_zz <span class="op">=</span> cov[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    sigma_xz <span class="op">=</span> cov[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Conditional mean and variance</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    cond_mean <span class="op">=</span> mu_x <span class="op">+</span> (sigma_xz <span class="op">/</span> sigma_zz) <span class="op">*</span> (z_val <span class="op">-</span> mu_z)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    cond_var <span class="op">=</span> sigma_xx <span class="op">-</span> (sigma_xz <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> sigma_zz</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cond_mean, cond_var</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Left plot: Joint distribution with conditional slices</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> axes[<span class="dv">0</span>]</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>X_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">100</span>)</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>Z_grid <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">100</span>)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>X_mesh, Z_mesh <span class="op">=</span> np.meshgrid(X_grid, Z_grid)</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>pos_mesh <span class="op">=</span> np.dstack((X_mesh, Z_mesh))</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>joint_pdf_mesh <span class="op">=</span> joint_dist.pdf(pos_mesh)</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>contour <span class="op">=</span> ax1.contourf(X_mesh, Z_mesh, joint_pdf_mesh, levels<span class="op">=</span><span class="dv">15</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>ax1.contour(X_mesh, Z_mesh, joint_pdf_mesh, levels<span class="op">=</span><span class="dv">10</span>, colors<span class="op">=</span><span class="st">'white'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw conditional distributions as curves</span></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> plt.cm.rainbow(np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="bu">len</span>(z_values)))</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> z_val, color <span class="kw">in</span> <span class="bu">zip</span>(z_values, colors):</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute conditional p(x | z)</span></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>    cond_mean, cond_var <span class="op">=</span> conditional_params(z_val)</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>    cond_dist <span class="op">=</span> stats.norm(cond_mean, np.sqrt(cond_var))</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scale pdf for visualization</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>    scale_factor <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>    x_cond <span class="op">=</span> X_grid</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>    pdf_cond <span class="op">=</span> cond_dist.pdf(x_cond) <span class="op">*</span> scale_factor</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot as curve at height z</span></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>    ax1.plot(x_cond, z_val <span class="op">+</span> pdf_cond, color<span class="op">=</span>color, linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="ss">f'$z=</span><span class="sc">{</span>z_val<span class="sc">:.1f}</span><span class="ss">$'</span>)</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>    ax1.axhline(z_val, color<span class="op">=</span>color, linestyle<span class="op">=</span><span class="st">':'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'$x$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'$z$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Joint $p(x,z)$ with Conditional Slices $p(x|z)$'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>ax1.legend(fontsize<span class="op">=</span><span class="dv">8</span>, loc<span class="op">=</span><span class="st">'upper right'</span>)</span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Right plot: Individual conditionals</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> axes[<span class="dv">1</span>]</span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> z_val, color <span class="kw">in</span> <span class="bu">zip</span>(z_values, colors):</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>    cond_mean, cond_var <span class="op">=</span> conditional_params(z_val)</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>    cond_dist <span class="op">=</span> stats.norm(cond_mean, np.sqrt(cond_var))</span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a>    x_plot <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">200</span>)</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>    pdf_plot <span class="op">=</span> cond_dist.pdf(x_plot)</span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>    ax2.plot(x_plot, pdf_plot, color<span class="op">=</span>color, linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="ss">f'$p(x|z=</span><span class="sc">{</span>z_val<span class="sc">:.1f}</span><span class="ss">)$'</span>)</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'$x$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'$p(x|z)$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Conditional Distributions $p(x|z)$ for Different $z$'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>ax2.legend(fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample from joint and visualize</span></span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> joint_dist.rvs(n_samples)</span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Create scatter plot with conditional structure</span></span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot samples colored by z-value</span></span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> ax.scatter(samples[:, <span class="dv">0</span>], samples[:, <span class="dv">1</span>], c<span class="op">=</span>samples[:, <span class="dv">1</span>], </span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>                    cmap<span class="op">=</span><span class="st">'rainbow'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">30</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'$z$ value'</span>)</span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlay conditional means</span></span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a>z_plot <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">50</span>)</span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a>conditional_means <span class="op">=</span> [conditional_params(z)[<span class="dv">0</span>] <span class="cf">for</span> z <span class="kw">in</span> z_plot]</span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a>ax.plot(conditional_means, z_plot, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Conditional mean $E[x|z]$'</span>)</span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'$x$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'$z$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Samples from $p(x,z)$ showing Conditional Structure'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a>ax.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="review_of_math_and_computing_foundations_files/figure-html/cell-25-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The conditional distributions <span class="math inline">\(p(x|z)\)</span> show how knowing <span class="math inline">\(z\)</span> affects our beliefs about <span class="math inline">\(x\)</span>. When variables are correlated, observing one variable shifts the expected value of the other. The “ridge” of the joint distribution follows the conditional mean. In VAEs and other latent variable models, we often work with <span class="math inline">\(p(x|z)\)</span> where the decoder generates <span class="math inline">\(x\)</span> given a latent code <span class="math inline">\(z\)</span>.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../appendices/review_of_singular_value_decomposition.html" class="pagination-link" aria-label="Review of Matrices and the Singular Value Decomposition">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Review of Matrices and the Singular Value Decomposition</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Machine Learning for Mechanical Engineers © 2025 by <a href="./index.qmd#sec-contributors">Mark Fuge and IDEAL Lab Contributors</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>