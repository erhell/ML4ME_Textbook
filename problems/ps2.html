<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="ML4ME Course Team">

<title>Problem Set: Improving GANs for Airfoil Generation – Machine Learning for Mechanical Engineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notebooks/notebooks.html" rel="next">
<link href="../problems/ps1.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-0dd2bd5de344125cf763a379ddc3eb04.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../problems/problems.html">Problems</a></li><li class="breadcrumb-item"><a href="../problems/ps2.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Problem Set 2</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning for Mechanical Engineering</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part1/part1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundational Skills</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/reviewing_supervised_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Reviewing Supervised Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/cross_validation_linear_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Evaluating Machine Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/supervised_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Gradient Descent</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/linear_decompositions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Review of Linear Unsupervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/taking_derivatives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Taking Derivatives with Automatic Differentiation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/distribution_distance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Measuring Distribution Distances</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part1/introduction_to_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to Inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part2/part2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Model-Specific Approaches</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/review_neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Review of Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/intro_to_GANS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Push-Forward Generative Models – Generative Adversarial Networks (GANs)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/GAN_pitfalls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">GAN Training Pitfalls</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/OT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Optimal Transport for Generative Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/VAEs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Variational Autoencoders (VAEs)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/normalizing_flows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Normalizing Flows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/continuous_flows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">From Discrete Transformations to Continuous Flows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/score_matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">From Continuous Flows to Score Matching</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/diffusion_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">From Score Matching to Diffusion Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part2/gen_models/flow_matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Flow Matching</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../problems/problems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../problems/ps1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Problem Set 1</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../problems/ps2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Problem Set 2</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../notebooks/notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">In-Class Notebooks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/california_housing_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Housing Price Data Visualization In-Class Exercise</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/helpful_tooling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Helpful Tooling for Working with and Debugging Machine Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/course_progression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Course Lecture Progression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/review_of_singular_value_decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Review of Matrices and the Singular Value Decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/review_of_math_and_computing_foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Reviewing Mathematical and Computational Foundations for Machine Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../problems/problems.html">Problems</a></li><li class="breadcrumb-item"><a href="../problems/ps2.html"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Problem Set 2</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Problem Set: Improving GANs for Airfoil Generation</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 27 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/ML4ME_Textbook/ML4ME_Textbook/problems/ps2_part1_autodiff.ipynb" data-notebook-title="Problem Set 2 Part 1: Automatic Differentiation" data-notebook-cellid="cell-0">
<section id="problem-set-2-part-1-automatic-differentiation" class="level2" data-number="19.1">
<h2 data-number="19.1" class="anchored" data-anchor-id="problem-set-2-part-1-automatic-differentiation"><span class="header-section-number">19.1</span> Problem Set 2 Part 1: Automatic Differentiation</h2>
<section id="overview" class="level3" data-number="19.1.1">
<h3 data-number="19.1.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">19.1.1</span> Overview</h3>
<p>This problem set is designed for independent exploration of automatic differentiation (AD) and its applications.</p>
<div id="cell-1" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> optimize</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>sns.set_context(<span class="st">'notebook'</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>&lt;torch._C.Generator at 0x27affd53c30&gt;</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="problem-1-manual-forward-and-backward-mode-ad" class="level2" data-number="19.2">
<h2 data-number="19.2" class="anchored" data-anchor-id="problem-1-manual-forward-and-backward-mode-ad"><span class="header-section-number">19.2</span> Problem 1: Manual Forward and Backward Mode AD</h2>
<section id="background" class="level3" data-number="19.2.1">
<h3 data-number="19.2.1" class="anchored" data-anchor-id="background"><span class="header-section-number">19.2.1</span> Background</h3>
<p>Recall, the main idea behind automatic differentiation is to apply the chain rule systematically to computational operations.</p>
<p>There are two main ‘modes’:</p>
<p><strong>Forward Mode AD</strong>: Propagates derivatives forward through the computation graph alongside the function values. If you have a function <span class="math inline">\(f: \mathbb{R}^n \to \mathbb{R}^m\)</span>, forward mode computes one column of the Jacobian matrix per pass.</p>
<p><strong>Backward Mode AD</strong>: Propagates derivatives backward through the computation graph (this is the same as backpropagation used in neural networks). Backward mode computes one row of the Jacobian matrix per pass.</p>
</section>
<section id="the-problem" class="level3" data-number="19.2.2">
<h3 data-number="19.2.2" class="anchored" data-anchor-id="the-problem"><span class="header-section-number">19.2.2</span> The Problem</h3>
<p>Consider the following function with 2 inputs and 2 outputs:</p>
<p><span class="math display">\[
\begin{aligned}
f_1(x_1, x_2) &amp;= x_1^2 + \sin(x_2) \\
f_2(x_1, x_2) &amp;= x_1 \cdot x_2 + \exp(x_1)
\end{aligned}
\]</span></p>
<p>We want to compute the <strong>Jacobian matrix</strong>:</p>
<p><span class="math display">\[
J = \begin{bmatrix}
\frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2} \\
\frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2}
\end{bmatrix}
\]</span></p>
<p>evaluated at the point <span class="math inline">\((x_1, x_2) = (2, \pi)\)</span>.</p>
</section>
<section id="part-a-forward-mode-ad" class="level3" data-number="19.2.3">
<h3 data-number="19.2.3" class="anchored" data-anchor-id="part-a-forward-mode-ad"><span class="header-section-number">19.2.3</span> Part A: Forward Mode AD</h3>
<p>In forward mode, you augment each variable with its derivative. For each variable <span class="math inline">\(v\)</span>, you track both: - <span class="math inline">\(v\)</span> (the value) - <span class="math inline">\(\dot{v}\)</span> (the derivative)</p>
<p><strong>Example</strong>: For <span class="math inline">\(v = x_1^2\)</span>, we have: - Value: <span class="math inline">\(v = x_1^2 = 2^2 = 4\)</span> - Derivative: <span class="math inline">\(\dot{v} = 2x_1 \cdot \dot{x}_1 = 2(2)(1) = 4\)</span> (if we seeded with <span class="math inline">\(\dot{x}_1 = 1\)</span>)</p>
<p><strong>Your Task</strong>: Compute the Jacobian using forward mode automatic differentiation. You should:</p>
<ol type="1">
<li><strong>Draw the computational graph</strong> for both <span class="math inline">\(f_1\)</span> and <span class="math inline">\(f_2\)</span>, showing all intermediate variables</li>
<li><strong>Perform the forward pass</strong> to compute function values at <span class="math inline">\((2, \pi)\)</span></li>
<li><strong>Perform forward mode AD with seed vector <span class="math inline">\(\dot{x} = [1, 0]^T\)</span></strong> (What does this compute?)</li>
<li><strong>Perform forward mode AD with seed vector <span class="math inline">\(\dot{x} = [0, 1]^T\)</span></strong> (What does this compute?)</li>
<li><strong>Assemble the complete Jacobian matrix</strong></li>
</ol>
<p><strong>Show all intermediate computations.</strong></p>
<p><strong>Student Response:</strong></p>
<p>[Write out your computational graph here (or on paper, possibly)]</p>
<p>[Insert your forward mode AD calculations here]</p>
<p>Jacobian (Forward Mode): <span class="math display">\[
J = \begin{bmatrix}
? &amp; ? \\
? &amp; ?
\end{bmatrix}
\]</span></p>
</section>
<section id="part-b-backward-mode-ad" class="level3" data-number="19.2.4">
<h3 data-number="19.2.4" class="anchored" data-anchor-id="part-b-backward-mode-ad"><span class="header-section-number">19.2.4</span> Part B: Backward Mode AD</h3>
<p>In backward mode (backpropagation), you first compute all the forward values, then propagate derivatives backward. For each variable <span class="math inline">\(v\)</span>, you compute: - <span class="math inline">\(\bar{v} = \frac{\partial f}{\partial v}\)</span> (the adjoint or “sensitivity” of <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(v\)</span>)</p>
<p><strong>Example</strong>: For <span class="math inline">\(f_1 = v_3\)</span> where <span class="math inline">\(v_3 = v_1 + v_2\)</span>: - If <span class="math inline">\(\bar{v}_3 = 1\)</span> (seed value for output) - Then <span class="math inline">\(\bar{v}_1 = \bar{v}_3 \cdot \frac{\partial v_3}{\partial v_1} = 1 \cdot 1 = 1\)</span> - And <span class="math inline">\(\bar{v}_2 = \bar{v}_3 \cdot \frac{\partial v_3}{\partial v_2} = 1 \cdot 1 = 1\)</span></p>
<p><strong>Your Task</strong>: Compute the same Jacobian using backward mode automatic differentiation. You should:</p>
<ol type="1">
<li>Use the same computational graph from Part A</li>
<li><strong>Perform backward mode AD starting from <span class="math inline">\(f_1\)</span></strong> with seed vector <span class="math inline">\(\bar{f} = [1, 0]^T\)</span> (What does this compute?)</li>
<li><strong>Perform backward mode AD starting from <span class="math inline">\(f_2\)</span></strong> with seed vector <span class="math inline">\(\bar{f} = [0, 1]^T\)</span> (What does this compute?)</li>
<li><strong>Assemble the complete Jacobian matrix</strong></li>
</ol>
<p><strong>Show all intermediate computations.</strong></p>
<p><strong>Student Response:</strong></p>
<p>[Insert your backward mode AD calculations here]</p>
<p>Jacobian (Backward Mode, should match Forward Mode if done correctly): <span class="math display">\[
J = \begin{bmatrix}
? &amp; ? \\
? &amp; ?
\end{bmatrix}
\]</span></p>
</section>
<section id="part-c-method-comparison-and-understanding" class="level3" data-number="19.2.5">
<h3 data-number="19.2.5" class="anchored" data-anchor-id="part-c-method-comparison-and-understanding"><span class="header-section-number">19.2.5</span> Part C: Method Comparison and Understanding</h3>
<p>Now that you’ve computed the Jacobian both ways, let’s reflect on the computational cost.</p>
<p><strong>Question 1</strong>: How many forward passes did you need to compute the complete Jacobian using forward mode AD?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 2</strong>: How many backward passes did you need to compute the complete Jacobian using backward mode AD?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 3</strong>: For this problem, is there a preferred method (forward vs backward AD) in terms of computational efficiency?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
</section>
</section>
<section id="problem-2-aircraft-external-fuel-tank-design-optimization" class="level2" data-number="19.3">
<h2 data-number="19.3" class="anchored" data-anchor-id="problem-2-aircraft-external-fuel-tank-design-optimization"><span class="header-section-number">19.3</span> Problem 2: Aircraft External Fuel Tank Design Optimization</h2>
<section id="background-1" class="level3" data-number="19.3.1">
<h3 data-number="19.3.1" class="anchored" data-anchor-id="background-1"><span class="header-section-number">19.3.1</span> Background</h3>
<p><em>This problem is adapted, with modification, from Martins, J. R. R. A., &amp; Ning, A. (2021). Engineering Design Optimization, Cambridge University Press (page 218, problem 5.11).</em></p>
<p>In aerospace engineering, external fuel tanks are often used to extend aircraft range. These streamlined containers must carry a specific volume of fuel while minimizing aerodynamic drag.</p>
<p><strong>The Design Problem</strong>: A jet aircraft needs to carry a streamlined external fuel tank with a required volume. We want to minimize the drag of an ellipsoid-shaped tank by controlling: - <span class="math inline">\(l\)</span>: length (semi-axis along the flow direction) - <span class="math inline">\(d\)</span>: diameter (semi-axis perpendicular to flow)</p>
<p><strong>Geometry Equations</strong>:</p>
<p>For an ellipsoid, the surface area is: <span class="math display">\[
S = \frac{\pi}{2}d^{2}\left(1 + \frac{l}{d\sqrt{1-\frac{d^{2}}{l^{2}}}}\arcsin\left(\sqrt{1-\frac{d^{2}}{l^{2}}}\right)\right)
\]</span></p>
<p>And the volume is: <span class="math display">\[
V = \frac{\pi}{6}d^{2}l
\]</span></p>
<p><strong>Aerodynamics</strong>:</p>
<p>The drag force on the tank is given by: <span class="math display">\[
D = \frac{1}{2}\rho U^{2} C_{D} S
\]</span></p>
<p>where: - <span class="math inline">\(\rho\)</span> = air density = 0.312 kg/m³ (at 12,000m altitude) - <span class="math inline">\(U\)</span> = velocity = 200 m/s - <span class="math inline">\(C_D\)</span> = drag coefficient - <span class="math inline">\(S\)</span> = surface area</p>
<p>The drag coefficient for an ellipsoid can be estimated (from Martins &amp; Ning) as: <span class="math display">\[
C_D = C_f \cdot \left[1 + 1.5\left(\frac{d}{l}\right)^{3/2} + 7\left(\frac{d}{l}\right)^{3}\right]
\]</span></p>
<p>where <span class="math inline">\(C_f\)</span> = 0.0035 (skin friction coefficient).</p>
<p><strong>Engineering Insight</strong>: - Long, slender tanks (small <span class="math inline">\(d/l\)</span>) have less drag but require more material - Short, fat tanks (large <span class="math inline">\(d/l\)</span>) have more drag but are more compact - We need to maintain a minimum volume for fuel storage</p>
<p>Let’s first visualize what we’re designing!</p>
<div id="cell-7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interactive visualization of ellipsoid fuel tank</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_ellipsoid(l, d, title<span class="op">=</span><span class="st">"Ellipsoid Fuel Tank"</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Visualize the ellipsoid fuel tank design"""</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3D view</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate ellipsoid surface</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, <span class="dv">50</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> np.linspace(<span class="dv">0</span>, np.pi, <span class="dv">50</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> l <span class="op">*</span> np.outer(np.cos(u), np.sin(v))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> d<span class="op">/</span><span class="dv">2</span> <span class="op">*</span> np.outer(np.sin(u), np.sin(v))</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> d<span class="op">/</span><span class="dv">2</span> <span class="op">*</span> np.outer(np.ones(np.size(u)), np.cos(v))</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot surface</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    ax1.plot_surface(x, y, z, alpha<span class="op">=</span><span class="fl">0.7</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>, edgecolor<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'Length (l)'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'Diameter (d)'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    ax1.set_zlabel(<span class="st">'Diameter (d)'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(title, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    ax1.set_box_aspect([l, d<span class="op">/</span><span class="dv">2</span>, d<span class="op">/</span><span class="dv">2</span>])</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Side view showing dimensions</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">100</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    x_side <span class="op">=</span> l <span class="op">*</span> np.cos(theta)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    y_side <span class="op">=</span> d<span class="op">/</span><span class="dv">2</span> <span class="op">*</span> np.sin(theta)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    ax2.plot(x_side, y_side, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    ax2.fill(x_side, y_side, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, l, <span class="dv">0</span>, head_width<span class="op">=</span><span class="fl">0.1</span>, head_length<span class="op">=</span><span class="fl">0.1</span>, fc<span class="op">=</span><span class="st">'red'</span>, ec<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    ax2.text(l<span class="op">/</span><span class="dv">2</span>, <span class="op">-</span><span class="fl">0.3</span>, <span class="ss">f'l = </span><span class="sc">{</span>l<span class="sc">:.2f}</span><span class="ss"> m'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, ha<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'red'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, d<span class="op">/</span><span class="dv">2</span>, head_width<span class="op">=</span><span class="fl">0.1</span>, head_length<span class="op">=</span><span class="fl">0.05</span>, fc<span class="op">=</span><span class="st">'blue'</span>, ec<span class="op">=</span><span class="st">'blue'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    ax2.arrow(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="op">-</span>d<span class="op">/</span><span class="dv">2</span>, head_width<span class="op">=</span><span class="fl">0.1</span>, head_length<span class="op">=</span><span class="fl">0.05</span>, fc<span class="op">=</span><span class="st">'blue'</span>, ec<span class="op">=</span><span class="st">'blue'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    ax2.text(<span class="fl">0.3</span>, d<span class="op">/</span><span class="dv">4</span>, <span class="ss">f'd = </span><span class="sc">{</span>d<span class="sc">:.2f}</span><span class="ss"> m'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, color<span class="op">=</span><span class="st">'blue'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'x (flow direction)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'y'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="st">'Side View with Dimensions'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    ax2.axis(<span class="st">'equal'</span>)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: visualize a candidate design</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>l_example <span class="op">=</span> <span class="fl">2.0</span>  <span class="co"># meters</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>d_example <span class="op">=</span> <span class="fl">0.8</span>  <span class="co"># meters</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>plot_ellipsoid(l_example, d_example, <span class="st">"Example Fuel Tank Design"</span>)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute properties for this design</span></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>V_example <span class="op">=</span> (np.pi<span class="op">/</span><span class="dv">6</span>) <span class="op">*</span> d_example<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> l_example</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Example Design Properties:"</span>)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Length (l) = </span><span class="sc">{</span>l_example<span class="sc">:.2f}</span><span class="ss"> m"</span>)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Diameter (d) = </span><span class="sc">{</span>d_example<span class="sc">:.2f}</span><span class="ss"> m"</span>)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Volume = </span><span class="sc">{</span>V_example<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Aspect ratio (l/d) = </span><span class="sc">{</span>l_example<span class="op">/</span>d_example<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ps2_files/figure-html/ps2_part1_autodiff-cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Example Design Properties:
  Length (l) = 2.00 m
  Diameter (d) = 0.80 m
  Volume = 0.6702 m³
  Aspect ratio (l/d) = 2.50</code></pre>
</div>
</div>
</section>
<section id="part-a-computing-derivatives" class="level3" data-number="19.3.2">
<h3 data-number="19.3.2" class="anchored" data-anchor-id="part-a-computing-derivatives"><span class="header-section-number">19.3.2</span> Part A: Computing Derivatives</h3>
<p>As engineers, we need to compute the derivatives of the output objectives (drag <span class="math inline">\(D\)</span> and volume <span class="math inline">\(V\)</span>) with respect to the design inputs (length <span class="math inline">\(l\)</span> and diameter <span class="math inline">\(d\)</span>). Although we <em>could</em> do this analytically using calculus, we want to test the best method for computing derivatives so we can adapt when problems become more complex.</p>
<p><strong>Design Point</strong>: Let’s analyze a baseline design with <span class="math inline">\(l = 2.5\)</span> m and <span class="math inline">\(d = 0.8\)</span> m.</p>
<p>First, let’s implement the objective functions:</p>
<div id="cell-9" class="cell" data-execution_count="56">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Constants</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>RHO <span class="op">=</span> <span class="fl">0.312</span>  <span class="co"># Air density at 12,000m (kg/m³)</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> <span class="fl">200.0</span>    <span class="co"># Velocity (m/s)</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>C_F <span class="op">=</span> <span class="fl">0.0035</span> <span class="co"># Skin friction coefficient</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># NumPy implementations</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> surface_area(l, d):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Ellipsoid surface area (numpy version)"""</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure l &gt; d to avoid domain errors in arcsin</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    ratio_sq <span class="op">=</span> (d <span class="op">/</span> l) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ratio_sq <span class="op">&gt;=</span> <span class="fl">1.0</span>:</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Degenerate case - return sphere surface area as approximation</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">4</span> <span class="op">*</span> np.pi <span class="op">*</span> (d<span class="op">/</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    sqrt_term <span class="op">=</span> np.sqrt(<span class="dv">1</span> <span class="op">-</span> ratio_sq)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    S <span class="op">=</span> (np.pi <span class="op">/</span> <span class="dv">2</span>) <span class="op">*</span> d<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> (l <span class="op">/</span> (d <span class="op">*</span> sqrt_term)) <span class="op">*</span> np.arcsin(sqrt_term))</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> S</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> volume(l, d):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Ellipsoid volume (numpy version)"""</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (np.pi <span class="op">/</span> <span class="dv">6</span>) <span class="op">*</span> d<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> l</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag_coefficient(l, d):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Drag coefficient for ellipsoid (numpy version)"""</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    ratio <span class="op">=</span> d <span class="op">/</span> l</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    C_D <span class="op">=</span> C_F <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> <span class="fl">1.5</span> <span class="op">*</span> ratio<span class="op">**</span>(<span class="dv">3</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span> <span class="dv">7</span> <span class="op">*</span> ratio<span class="op">**</span><span class="dv">3</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> C_D</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag(l, d):</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Total drag force (numpy version)"""</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    S <span class="op">=</span> surface_area(l, d)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    C_D <span class="op">=</span> drag_coefficient(l, d)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> RHO <span class="op">*</span> U<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> C_D <span class="op">*</span> S</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> D</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Test at baseline design - use a design where l &gt; d</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>l_baseline <span class="op">=</span> <span class="fl">2.5</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>d_baseline <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>S_baseline <span class="op">=</span> surface_area(l_baseline, d_baseline)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>V_baseline <span class="op">=</span> volume(l_baseline, d_baseline)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>CD_baseline <span class="op">=</span> drag_coefficient(l_baseline, d_baseline)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>D_baseline <span class="op">=</span> drag(l_baseline, d_baseline)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Baseline Design (l=</span><span class="sc">{</span>l_baseline<span class="sc">}</span><span class="ss">m, d=</span><span class="sc">{</span>d_baseline<span class="sc">}</span><span class="ss">m):"</span>)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Surface area: </span><span class="sc">{</span>S_baseline<span class="sc">:.4f}</span><span class="ss"> m²"</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Volume: </span><span class="sc">{</span>V_baseline<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Drag coefficient: </span><span class="sc">{</span>CD_baseline<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Drag force: </span><span class="sc">{</span>D_baseline<span class="sc">:.2f}</span><span class="ss"> N"</span>)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Aspect ratio l/d: </span><span class="sc">{</span>l_baseline<span class="op">/</span>d_baseline<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Baseline Design (l=2.5m, d=0.8m):
  Surface area: 5.1339 m²
  Volume: 0.8378 m³
  Drag coefficient: 0.005253
  Drag force: 168.29 N
  Aspect ratio l/d: 3.12</code></pre>
</div>
</div>
</section>
<section id="understanding-backward-mode-ad" class="level3" data-number="19.3.3">
<h3 data-number="19.3.3" class="anchored" data-anchor-id="understanding-backward-mode-ad"><span class="header-section-number">19.3.3</span> Understanding Backward Mode AD</h3>
<p>Backward mode AD works by: 1. <strong>Forward pass</strong>: Compute all intermediate values from inputs to output 2. <strong>Backward pass</strong>: Starting from the output, propagate gradients backward using the chain rule</p>
<p>In our case we have a function with <strong>2 inputs</strong> (<span class="math inline">\(l\)</span>, <span class="math inline">\(d\)</span>) and <strong>1 output</strong> (<span class="math inline">\(D\)</span>, drag force). Let’s focus on computing the gradient of drag:</p>
<p><span class="math display">\[
\nabla D = \begin{bmatrix}
\frac{\partial D}{\partial l} \\
\frac{\partial D}{\partial d}
\end{bmatrix}
\]</span></p>
<p>For each intermediate variable <span class="math inline">\(v\)</span>, we compute its <strong>adjoint</strong> (sensitivity): <span class="math display">\[
\bar{v} = \frac{\partial D}{\partial v}
\]</span></p>
<p>The adjoint tells us “how much does the output <span class="math inline">\(D\)</span> change if we perturb <span class="math inline">\(v\)</span>?”</p>
<p><strong>Your Task</strong>: Compute this gradient using <strong>backward mode automatic differentiation</strong> (also called reverse-mode AD or backpropagation).</p>
</section>
<section id="step-1-draw-the-computational-graph" class="level3" data-number="19.3.4">
<h3 data-number="19.3.4" class="anchored" data-anchor-id="step-1-draw-the-computational-graph"><span class="header-section-number">19.3.4</span> Step 1: Draw the Computational Graph</h3>
<p>First, break down the drag computation into elementary operations. Here’s a template to get you started:</p>
<pre><code>Inputs: l, d

Intermediate calculations example (fill in the formulas):
v₁ = d/l                     (diameter-to-length ratio)
v₂ = v₁²                     
v₃ = 1 - v₂                  
v₄ = √v₃                     
v₅ = arcsin(v₄)              
v₆ = d²                      
v₇ = d·v₄                   
v₈ = l/v₇                   
v₉ = v₈·v₅                  
v₁₀ = 1 + v₉                
...
[Continue adding intermediate variables until you reach D]</code></pre>
<p><strong>Task 1a</strong>: Complete the computational graph by identifying ALL intermediate variables from the inputs (<span class="math inline">\(l\)</span>, <span class="math inline">\(d\)</span>) to the final output (<span class="math inline">\(D\)</span>). Number them sequentially (v₁, v₂, v₃, …, v_N).</p>
<p><strong>Student Response:</strong> [Draw or write out your complete computational graph here]</p>
</section>
<section id="step-2-forward-pass" class="level3" data-number="19.3.5">
<h3 data-number="19.3.5" class="anchored" data-anchor-id="step-2-forward-pass"><span class="header-section-number">19.3.5</span> Step 2: Forward Pass</h3>
<p>Evaluate all intermediate variables at the baseline design point: <span class="math inline">\(l = 2.5\)</span> m, <span class="math inline">\(d = 0.8\)</span> m.</p>
<p><strong>Task 1b</strong>: Compute the numerical values of all intermediate variables in your graph.</p>
<p><strong>Student Response:</strong></p>
<pre><code>l = 2.5
d = 0.8
v₁ = ?
v₂ = ?
v₃ = ?
...
D = ?</code></pre>
</section>
<section id="step-3-backward-pass" class="level3" data-number="19.3.6">
<h3 data-number="19.3.6" class="anchored" data-anchor-id="step-3-backward-pass"><span class="header-section-number">19.3.6</span> Step 3: Backward Pass</h3>
<p>Now propagate gradients backward! Start with <span class="math inline">\(\bar{D} = 1\)</span> (the gradient of <span class="math inline">\(D\)</span> with respect to itself), then work backward through the graph.</p>
<p><strong>Task 1c</strong>: Compute all adjoints working backward from <span class="math inline">\(\bar{D} = 1\)</span> to <span class="math inline">\(\bar{l}\)</span> and <span class="math inline">\(\bar{d}\)</span>.</p>
<p><strong>Student Response:</strong></p>
<pre><code>Backward pass starting from D:
D̄ = 1  (seed value)

[Work backward through your computational graph]
v̄_N = ?
v̄_{N-1} = ?
...
v̄₃ = ?
v̄₂ = ?
v̄₁ = ?

Final gradients (these are what we want!):
∂D/∂l = l̄ = ?
∂D/∂d = d̄ = ?</code></pre>
</section>
<section id="step-4-interpretation" class="level3" data-number="19.3.7">
<h3 data-number="19.3.7" class="anchored" data-anchor-id="step-4-interpretation"><span class="header-section-number">19.3.7</span> Step 4: Interpretation</h3>
<p><strong>Task 1d</strong>: Once you’ve computed the gradients, interpret them physically:</p>
<p><strong>Question 1</strong>: What does the value of <span class="math inline">\(\frac{\partial D}{\partial l}\)</span> imply physically? (If we increase length, does drag increase or decrease?)</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 2</strong>: What does the value of <span class="math inline">\(\frac{\partial D}{\partial d}\)</span> imply physically?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 3</strong>: Which variable has a larger effect on drag? Does this make engineering sense?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
</section>
<section id="part-b-implementing-ad-with-pytorch" class="level3" data-number="19.3.8">
<h3 data-number="19.3.8" class="anchored" data-anchor-id="part-b-implementing-ad-with-pytorch"><span class="header-section-number">19.3.8</span> Part B: Implementing AD with PyTorch</h3>
<p>Now let’s implement automatic differentiation using PyTorch and time both the forward and backward passes.</p>
<p><strong>Your Task</strong>: 1. Reimplement your functions using PyTorch operations (torch tensors) 2. Compute the Jacobian matrix using PyTorch’s autograd 3. Time the forward pass (function evaluation) 4. Time the backward pass (gradient computation)</p>
<div id="cell-12" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Student Task: Implement PyTorch versions of the functions</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> surface_area_torch(l, d):</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""PyTorch version of surface_area"""</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement using torch operations (torch.arcsin, torch.sqrt, etc.)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> volume_torch(l, d):</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""PyTorch version of volume"""</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag_coefficient_torch(l, d):</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""PyTorch version of drag_coefficient"""</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag_torch(l, d):</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""PyTorch version of drag"""</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Jacobian using PyTorch</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Hints:</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Create torch tensors for l and d with requires_grad=True</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compute both outputs (D and V)</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Use torch.autograd.grad or .backward() to get gradients</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. For a Jacobian with multiple outputs, you need to call backward() for each output</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([l_baseline, d_baseline], requires_grad<span class="op">=</span><span class="va">True</span>, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>l_t, d_t <span class="op">=</span> x[<span class="dv">0</span>], x[<span class="dv">1</span>]</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="co"># First row: gradients of D</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> drag_torch(l_t, d_t)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>grad_D <span class="op">=</span> torch.autograd.grad(D, x, retain_graph<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Second row: gradients of V  </span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> volume_torch(l_t, d_t)</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>grad_V <span class="op">=</span> torch.autograd.grad(V, x)[<span class="dv">0</span>]</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>jacobian <span class="op">=</span> torch.stack([grad_D, grad_V]).numpy()</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Jacobian Matrix (from PyTorch AD):"</span>)</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ∂D/∂l = </span><span class="sc">{</span>jacobian[<span class="dv">0</span>,<span class="dv">0</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ∂D/∂d = </span><span class="sc">{</span>jacobian[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ∂V/∂l = </span><span class="sc">{</span>jacobian[<span class="dv">1</span>,<span class="dv">0</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ∂V/∂d = </span><span class="sc">{</span>jacobian[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Time the forward and backward passes</span></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>n_reps <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Time forward pass</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_reps):</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.tensor([l_baseline, d_baseline], requires_grad<span class="op">=</span><span class="va">True</span>, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> drag_torch(x[<span class="dv">0</span>], x[<span class="dv">1</span>])</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> volume_torch(x[<span class="dv">0</span>], x[<span class="dv">1</span>])</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>time_forward <span class="op">=</span> (time.time() <span class="op">-</span> start) <span class="op">/</span> n_reps</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Time backward pass</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_reps):</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.tensor([l_baseline, d_baseline], requires_grad<span class="op">=</span><span class="va">True</span>, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> drag_torch(x[<span class="dv">0</span>], x[<span class="dv">1</span>])</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> volume_torch(x[<span class="dv">0</span>], x[<span class="dv">1</span>])</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>    grad_D <span class="op">=</span> torch.autograd.grad(D, x, retain_graph<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>    grad_V <span class="op">=</span> torch.autograd.grad(V, x)[<span class="dv">0</span>]</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>time_backward <span class="op">=</span> (time.time() <span class="op">-</span> start) <span class="op">/</span> n_reps</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Timing Results:"</span>)</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Forward pass:  </span><span class="sc">{</span>time_forward<span class="op">*</span><span class="fl">1e6</span><span class="sc">:.2f}</span><span class="ss"> µs"</span>)</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Backward pass: </span><span class="sc">{</span>time_backward<span class="op">*</span><span class="fl">1e6</span><span class="sc">:.2f}</span><span class="ss"> µs"</span>)</span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Overhead of AD: </span><span class="sc">{</span>(time_backward<span class="op">/</span>time_forward <span class="op">-</span> <span class="dv">1</span>)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><em>Reflection</em>: Did you observe the backward pass taking more time than the forward pass? If you did, does this make sense?</p>
</section>
<section id="part-c-constrained-optimization" class="level3" data-number="19.3.9">
<h3 data-number="19.3.9" class="anchored" data-anchor-id="part-c-constrained-optimization"><span class="header-section-number">19.3.9</span> Part C: Constrained Optimization</h3>
<p>Now for the real engineering problem! The aircraft requires the fuel tank to have a volume of <strong>at least 0.5 m³</strong> to carry enough fuel. This gives us a constraint:</p>
<p><span class="math display">\[
V \geq V_{\text{req}} = 0.5 \text{ m}^3
\]</span></p>
<p>Or equivalently (for standard optimization form): <span class="math display">\[
g(l, d) = V_{\text{req}} - V(l, d) \leq 0
\]</span></p>
<p><strong>Optimization Problem</strong>: <span class="math display">\[
\begin{aligned}
\text{minimize} \quad &amp; D(l, d) \\
\text{subject to} \quad &amp; V(l, d) \geq 0.5 \\
&amp; l &gt; 0, \quad d &gt; 0
\end{aligned}
\]</span></p>
<p><strong>Your Task</strong>: Solve this optimization problem using three different methods for computing gradients: 1. <strong>Finite differences</strong> (from Problem 3, Part B) 2. <strong>PyTorch automatic differentiation</strong> 3. <strong>Third Method: Could be the SciPy default gradient computation (SciPy defaults to a “2-point finite difference estimation with an absolute step size”), or another method, such as <a href="https://mdolab.engin.umich.edu/wiki/guide-complex-step-derivative-approximation">complex-step method</a> (which can be done manually but is also built in to SciPy), another FD method, or an analytical gradient method</strong></p>
<p>We’ll use scipy’s SLSQP optimizer, which is designed for constrained optimization problems. The code is provided below - your job is to implement the gradient functions and compare the results. When you compare the results, it may be useful to run multiple trials</p>
<div id="cell-15" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>V_REQUIRED <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># m³</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrapper functions for scipy (which expects 1D arrays)</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag_wrapper(x):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Objective function: drag"""</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    l, d <span class="op">=</span> x[<span class="dv">0</span>], x[<span class="dv">1</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> drag(l, d)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> volume_constraint(x):</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Constraint function: V - V_req &gt;= 0"""</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    l, d <span class="op">=</span> x[<span class="dv">0</span>], x[<span class="dv">1</span>]</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> volume(l, d) <span class="op">-</span> V_REQUIRED</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Student Task: Implement gradient functions</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag_gradient_fd(x, eps<span class="op">=</span><span class="fl">1e-7</span>):</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute gradient of drag using finite differences.</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">    Use the finite_difference_gradient function from Problem 3!</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> drag_gradient_torch(x):</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute gradient of drag using PyTorch AD.</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Hint: Convert x to torch tensor, compute drag, call backward(), extract gradient</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> constraint_gradient_fd(x, eps<span class="op">=</span><span class="fl">1e-7</span>):</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Gradient of volume constraint using finite differences"""</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> constraint_gradient_torch(x):</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Gradient of volume constraint using PyTorch AD"""</span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Depending on what you do, you can also manually define the third method gradients here. </span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a><span class="co"># If you are using SciPy's built in gradient estimation methods, you do not need to define these functions.</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess (start from baseline design)</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([l_baseline, d_baseline])</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SOLVING CONSTRAINED OPTIMIZATION PROBLEM"</span>)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Objective: Minimize drag"</span>)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Constraint: Volume &gt;= </span><span class="sc">{</span>V_REQUIRED<span class="sc">}</span><span class="ss"> m³"</span>)</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial design: l=</span><span class="sc">{</span>x0[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">m, d=</span><span class="sc">{</span>x0[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">m"</span>)</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial drag: </span><span class="sc">{</span>drag_wrapper(x0)<span class="sc">:.2f}</span><span class="ss"> N"</span>)</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial volume: </span><span class="sc">{</span>volume(x0[<span class="dv">0</span>], x0[<span class="dv">1</span>])<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
SOLVING CONSTRAINED OPTIMIZATION PROBLEM
======================================================================
Objective: Minimize drag
Constraint: Volume &gt;= 0.5 m³
Initial design: l=2.50m, d=0.80m
Initial drag: 168.29 N
Initial volume: 0.8378 m³
</code></pre>
</div>
</div>
<p><strong>Implementation Note</strong>: The optimization problem below may converge to different local minima depending on the initial guess. For a more robust analysis, consider running multiple trials with random initial guesses and computing both the average and best results.</p>
<div id="cell-17" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Method 1: Finite Differences</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Method 1: Optimization with Finite Difference Gradients"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>constraint_fd <span class="op">=</span> {<span class="st">'type'</span>: <span class="st">'ineq'</span>, <span class="st">'fun'</span>: volume_constraint, <span class="st">'jac'</span>: constraint_gradient_fd}</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [(<span class="fl">0.1</span>, <span class="fl">10.0</span>), (<span class="fl">0.1</span>, <span class="fl">10.0</span>)]  <span class="co"># l and d must be positive</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>result_fd <span class="op">=</span> optimize.minimize(</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    drag_wrapper,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    x0<span class="op">=</span>x0,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">'SLSQP'</span>,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    jac<span class="op">=</span>drag_gradient_fd,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    constraints<span class="op">=</span>constraint_fd,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>bounds,</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>, <span class="st">'maxiter'</span>: <span class="dv">100</span>} <span class="co"># If you are averaging over many trials, consider turning disp off (this prints convergence information)</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>l_opt_fd, d_opt_fd <span class="op">=</span> result_fd.x</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal design (FD):"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  l = </span><span class="sc">{</span>l_opt_fd<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  d = </span><span class="sc">{</span>d_opt_fd<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Drag = </span><span class="sc">{</span>drag_wrapper(result_fd.x)<span class="sc">:.2f}</span><span class="ss"> N"</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Volume = </span><span class="sc">{</span>volume(l_opt_fd, d_opt_fd)<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Function evaluations: </span><span class="sc">{</span>result_fd<span class="sc">.</span>nfev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Gradient evaluations: </span><span class="sc">{</span>result_fd<span class="sc">.</span>njev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-18" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Method 2: PyTorch AD</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Method 2: Optimization with PyTorch AD Gradients"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>constraint_torch <span class="op">=</span> {<span class="st">'type'</span>: <span class="st">'ineq'</span>, <span class="st">'fun'</span>: volume_constraint, <span class="st">'jac'</span>: constraint_gradient_torch}</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>result_torch <span class="op">=</span> optimize.minimize(</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    drag_wrapper,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    x0<span class="op">=</span>x0,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">'SLSQP'</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    jac<span class="op">=</span>drag_gradient_torch,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    constraints<span class="op">=</span>constraint_torch,</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>bounds,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>, <span class="st">'maxiter'</span>: <span class="dv">100</span>} </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>l_opt_torch, d_opt_torch <span class="op">=</span> result_torch.x</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal design (PyTorch AD):"</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  l = </span><span class="sc">{</span>l_opt_torch<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  d = </span><span class="sc">{</span>d_opt_torch<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Drag = </span><span class="sc">{</span>drag_wrapper(result_torch.x)<span class="sc">:.2f}</span><span class="ss"> N"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Volume = </span><span class="sc">{</span>volume(l_opt_torch, d_opt_torch)<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Function evaluations: </span><span class="sc">{</span>result_torch<span class="sc">.</span>nfev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Gradient evaluations: </span><span class="sc">{</span>result_torch<span class="sc">.</span>njev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-19" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Method 3: Your Choice</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Method 3: Optimization with [Third Method]"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># bogus placeholder for third method constraint</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>constraint_gradient_third_method <span class="op">=</span> <span class="va">None</span>  <span class="co"># Implement OR use a built in method from the SciPy documentation</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>constraint_third_method <span class="op">=</span> {<span class="st">'type'</span>: <span class="st">'ineq'</span>, <span class="st">'fun'</span>: volume_constraint, <span class="st">'jac'</span>: constraint_gradient_third_method}</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>result_third_method <span class="op">=</span> optimize.minimize(</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    drag_wrapper,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    x0<span class="op">=</span>x0,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">'SLSQP'</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    jac<span class="op">=</span>constraint_gradient_third_method,  <span class="co"># Actually implement this with your third method gradient function if applicable</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    constraints<span class="op">=</span>constraint_third_method,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>bounds,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>, <span class="st">'maxiter'</span>: <span class="dv">100</span>}</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>l_opt_third_method, d_opt_third_method <span class="op">=</span> result_third_method.x</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal design ([Third Method]):"</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  l = </span><span class="sc">{</span>l_opt_third_method<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  d = </span><span class="sc">{</span>d_opt_third_method<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Drag = </span><span class="sc">{</span>drag_wrapper(result_third_method.x)<span class="sc">:.2f}</span><span class="ss"> N"</span>)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Volume = </span><span class="sc">{</span>volume(l_opt_third_method, d_opt_third_method)<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Function evaluations: </span><span class="sc">{</span>result_third_method<span class="sc">.</span>nfev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Gradient evaluations: </span><span class="sc">{</span>result_third_method<span class="sc">.</span>njev<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Average and find the best results</p>
<div id="cell-21" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"OPTIMIZATION RESULTS SUMMARY (BEST TRIALS)"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Method'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'l (m)'</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'d (m)'</span><span class="sc">:&lt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Drag (N)'</span><span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Func Evals'</span><span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Grad Evals'</span><span class="sc">:&lt;12}</span><span class="ss">"</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># bogus values:</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>l_opt_fd_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>d_opt_fd_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>nfev_fd_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>njev_fd_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>l_opt_torch_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>d_opt_torch_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>nfev_torch_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>njev_torch_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>l_opt_third_method_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>d_opt_third_method_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>nfev_third_method_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>njev_third_method_best <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>l_opt_fd_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>d_opt_fd_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>nfev_fd_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>njev_fd_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>l_opt_torch_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>d_opt_torch_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>nfev_torch_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>njev_torch_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>l_opt_third_method_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>d_opt_third_method_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>nfev_third_method_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>njev_third_method_avg <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'(best) Finite Diff'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>l_opt_fd_best<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>d_opt_fd_best<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>drag_wrapper([l_opt_fd_best, d_opt_fd_best])<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>nfev_fd_best<span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span>njev_fd_best<span class="sc">:&lt;12}</span><span class="ss">"</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'(best) PyTorch AD'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>l_opt_torch_best<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>d_opt_torch_best<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>drag_wrapper([l_opt_torch_best, d_opt_torch_best])<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>nfev_torch_best<span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span>njev_torch_best<span class="sc">:&lt;12}</span><span class="ss">"</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'(best) Third Method'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>l_opt_third_method_best<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>d_opt_third_method_best<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>drag_wrapper([l_opt_third_method_best, d_opt_third_method_best])<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>nfev_third_method_best<span class="sc">:&lt;12}</span><span class="ss"> </span><span class="sc">{</span>njev_third_method_best<span class="sc">:&lt;12}</span><span class="ss">"</span>)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Average Finite Diff'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>l_opt_fd_avg<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>d_opt_fd_avg<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>drag_wrapper([l_opt_fd_avg, d_opt_fd_avg])<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>nfev_fd_avg<span class="sc">:&lt;12.1f}</span><span class="ss"> </span><span class="sc">{</span>njev_fd_avg<span class="sc">:&lt;12.1f}</span><span class="ss">"</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Average PyTorch AD'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>l_opt_torch_avg<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>d_opt_torch_avg<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>drag_wrapper([l_opt_torch_avg, d_opt_torch_avg])<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>nfev_torch_avg<span class="sc">:&lt;12.1f}</span><span class="ss"> </span><span class="sc">{</span>njev_torch_avg<span class="sc">:&lt;12.1f}</span><span class="ss">"</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Average [Third Method]'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>l_opt_third_method_avg<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>d_opt_third_method_avg<span class="sc">:&lt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>drag_wrapper([l_opt_third_method_avg, d_opt_third_method_avg])<span class="sc">:&lt;12.2f}</span><span class="ss"> </span><span class="sc">{</span>nfev_third_method_avg<span class="sc">:&lt;12.1f}</span><span class="ss"> </span><span class="sc">{</span>njev_third_method_avg<span class="sc">:&lt;12.1f}</span><span class="ss">"</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracies could be done too if you get the analytical solution:</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="co"># This can be useful, since the methods may converge to very similar results</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="co"># You can also try to exclude convergence failures from the averages above based on tolerances</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="co"># bogus values:</span></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>l_analytical <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>d_analytical <span class="op">=</span> <span class="op">-</span><span class="dv">999</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Analytical Values (if derived - see the 'Bonus Side Note' if you are interested):"</span>)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  l = </span><span class="sc">{</span>l_analytical<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  d = </span><span class="sc">{</span>d_analytical<span class="sc">:.4f}</span><span class="ss"> m"</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Drag = </span><span class="sc">{</span>drag_wrapper([l_analytical, d_analytical])<span class="sc">:.2f}</span><span class="ss"> N"</span>)</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Volume = </span><span class="sc">{</span>volume(l_analytical, d_analytical)<span class="sc">:.4f}</span><span class="ss"> m³"</span>)</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Analytical Error Comparison (best):"</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Method'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'l Error (m)'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'d Error (m)'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Drag Error (N)'</span><span class="sc">:&lt;15}</span><span class="ss">"</span>)</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'(best) Finite Diff'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(l_opt_fd_best <span class="op">-</span> l_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(d_opt_fd_best <span class="op">-</span> d_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(drag_wrapper([l_opt_fd_best, d_opt_fd_best]) <span class="op">-</span> drag_wrapper([l_analytical, d_analytical]))<span class="sc">:&lt;15.6f}</span><span class="ss">"</span>)</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'(best) PyTorch AD'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(l_opt_torch_best <span class="op">-</span> l_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(d_opt_torch_best <span class="op">-</span> d_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(drag_wrapper([l_opt_torch_best, d_opt_torch_best]) <span class="op">-</span> drag_wrapper([l_analytical, d_analytical]))<span class="sc">:&lt;15.6f}</span><span class="ss">"</span>)</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'(best) Third Method'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(l_opt_third_method_best <span class="op">-</span> l_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(d_opt_third_method_best <span class="op">-</span> d_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(drag_wrapper([l_opt_third_method_best, d_opt_third_method_best]) <span class="op">-</span> drag_wrapper([l_analytical, d_analytical]))<span class="sc">:&lt;15.6f}</span><span class="ss">"</span>)</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Average Finite Diff'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(l_opt_fd_avg <span class="op">-</span> l_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(d_opt_fd_avg <span class="op">-</span> d_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(drag_wrapper([l_opt_fd_avg, d_opt_fd_avg]) <span class="op">-</span> drag_wrapper([l_analytical, d_analytical]))<span class="sc">:&lt;15.6f}</span><span class="ss">"</span>)</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Average PyTorch AD'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(l_opt_torch_avg <span class="op">-</span> l_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(d_opt_torch_avg <span class="op">-</span> d_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(drag_wrapper([l_opt_torch_avg, d_opt_torch_avg]) <span class="op">-</span> drag_wrapper([l_analytical, d_analytical]))<span class="sc">:&lt;15.6f}</span><span class="ss">"</span>)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Average [Third Method]'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(l_opt_third_method_avg <span class="op">-</span> l_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(d_opt_third_method_avg <span class="op">-</span> d_analytical)<span class="sc">:&lt;15.6f}</span><span class="ss"> </span><span class="sc">{</span><span class="bu">abs</span>(drag_wrapper([l_opt_third_method_avg, d_opt_third_method_avg]) <span class="op">-</span> drag_wrapper([l_analytical, d_analytical]))<span class="sc">:&lt;15.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
OPTIMIZATION RESULTS SUMMARY (BEST TRIALS)
======================================================================
Method               l (m)      d (m)      Drag (N)     Func Evals   Grad Evals  
----------------------------------------------------------------------
(best) Finite Diff   -999.0000  -999.0000  650514660.30 -999         -999        
(best) PyTorch AD    -999.0000  -999.0000  650514660.30 -999         -999        
(best) Third Method  -999.0000  -999.0000  650514660.30 -999         -999        
Average Finite Diff  -999.0000  -999.0000  650514660.30 -999.0       -999.0      
Average PyTorch AD   -999.0000  -999.0000  650514660.30 -999.0       -999.0      
Average Third Method -999.0000  -999.0000  650514660.30 -999.0       -999.0      

Analytical Values (if derived - see the 'Bonus Side Note' if you are interested):
  l = -999.0000 m
  d = -999.0000 m
  Drag = 650514660.30 N
  Volume = -522029549.5442 m³

Analytical Error Comparison (best):
Method               l Error (m)     d Error (m)     Drag Error (N) 
----------------------------------------------------------------------
(best) Finite Diff   0.000000        0.000000        0.000000       
(best) PyTorch AD    0.000000        0.000000        0.000000       
(best) Third Method  0.000000        0.000000        0.000000       
Average Finite Diff  0.000000        0.000000        0.000000       
Average PyTorch AD   0.000000        0.000000        0.000000       
Average Third Method 0.000000        0.000000        0.000000       </code></pre>
</div>
</div>
<div id="cell-22" class="cell" data-execution_count="73">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize initial and optimal designs</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>designs <span class="op">=</span> [</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    (l_baseline, d_baseline, <span class="st">"Initial Design"</span>),</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    (l_opt_fd_best, d_opt_fd_best, <span class="st">"Optimal (Finite Diff)"</span>),</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    (l_opt_torch_best, d_opt_torch_best, <span class="st">"Optimal (PyTorch AD)"</span>),</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    (l_opt_third_method_best, d_opt_third_method_best, <span class="st">"Optimal ([Third Method])"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(l_baseline, d_baseline, l_opt_fd_best, d_opt_fd_best, l_opt_torch_best, d_opt_torch_best)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (l, d, title) <span class="kw">in</span> <span class="bu">enumerate</span>(designs):</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, <span class="dv">100</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    x_side <span class="op">=</span> l <span class="op">*</span> np.cos(theta)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    y_side <span class="op">=</span> d<span class="op">/</span><span class="dv">2</span> <span class="op">*</span> np.sin(theta)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    ax.plot(x_side, y_side, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    ax.fill(x_side, y_side, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'x (flow direction) [m]'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'y [m]'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    drag_val <span class="op">=</span> drag(l, d)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    vol_val <span class="op">=</span> volume(l, d)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>title<span class="sc">}</span><span class="ch">\n</span><span class="ss">Drag: </span><span class="sc">{</span>drag_val<span class="sc">:.1f}</span><span class="ss">N, Vol: </span><span class="sc">{</span>vol_val<span class="sc">:.3f}</span><span class="ss">m³, l/d: </span><span class="sc">{</span>l<span class="op">/</span>d<span class="sc">:.1f}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'equal'</span>)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add aspect markers</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    ax.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>    ax.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Initial aspect ratio: </span><span class="sc">{</span>x0[<span class="dv">0</span>]<span class="op">/</span>x0[<span class="dv">1</span>]<span class="sc">:.1f}</span><span class="ss">:1"</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal aspect ratio: </span><span class="sc">{</span>l_opt_torch_best<span class="op">/</span>d_opt_torch_best<span class="sc">:.1f}</span><span class="ss">:1"</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Drag reduction: </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> drag(l_opt_torch_best, d_opt_torch_best)<span class="op">/</span>drag(x0[<span class="dv">0</span>], x0[<span class="dv">1</span>]))<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.5 0.8 -999 -999 -999 -999</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ps2_files/figure-html/ps2_part1_autodiff-cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Initial aspect ratio: 3.1:1
Optimal aspect ratio: 1.0:1
Drag reduction: -386548751.7%</code></pre>
</div>
</div>
</section>
<section id="bonus-side-note" class="level3" data-number="19.3.10">
<h3 data-number="19.3.10" class="anchored" data-anchor-id="bonus-side-note"><span class="header-section-number">19.3.10</span> Bonus Side Note:</h3>
<p>As a smart engineer, you may have realized that the volume constraint is probably active at the optimum (i.e., the tank will just meet the volume requirement). With this information, you can reduce the problem to a single-variable optimization by expressing one variable in terms of the other using the volume constraint, allowing you to solve this analytically without the need for constrained optimization methods.</p>
<p>If you want, you can easily derive this, and compare your solution against the analytical one - this could help you compare the numerical accuracy of your optimization results in a more rigorous way.</p>
</section>
</section>
<section id="problem-3-bouncing-ball-sensitivity-analysis" class="level2" data-number="19.4">
<h2 data-number="19.4" class="anchored" data-anchor-id="problem-3-bouncing-ball-sensitivity-analysis"><span class="header-section-number">19.4</span> Problem 3: Bouncing Ball Sensitivity Analysis</h2>
<section id="background-2" class="level3" data-number="19.4.1">
<h3 data-number="19.4.1" class="anchored" data-anchor-id="background-2"><span class="header-section-number">19.4.1</span> Background</h3>
<p>One powerful application of automatic differentiation is <strong>sensitivity analysis</strong>: understanding how outputs depend on inputs.</p>
<p>AD makes sensitivity analysis trivial—we just compute gradients! Without AD, you’d need finite differences (slow and inaccurate) or hand-derived formulas (error-prone and not maintainable).</p>
</section>
<section id="the-problem-1" class="level3" data-number="19.4.2">
<h3 data-number="19.4.2" class="anchored" data-anchor-id="the-problem-1"><span class="header-section-number">19.4.2</span> The Problem</h3>
<p>Consider a simple physics simulation: a bouncing ball. The simulation has parameters: - <code>g</code>: gravitational acceleration (m/s²) - <code>e</code>: coefficient of restitution - controls energy loss (0 &lt; e &lt; 1) - <code>v0</code>: initial velocity (m/s) - <code>h0</code>: initial height (m)</p>
<p>We will use the following parameters: g = 10.0 m/s² e = 0.9 v0 = 0.0 m/s h0 = 10.0 m</p>
<p>And we will use a dt of 0.01 seconds for the simulation time step, for a total of 1000 time steps.</p>
<p>The simulation uses a simple Euler integrator with a conditional (bounce detection), making it non-trivial to differentiate by hand!</p>
<div id="cell-25" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bounce_simulation(g, e, v0, h0, num_timesteps<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Simulate a bouncing ball using Euler integration.</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">        g: gravity</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co">        e: coefficient of restitution</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">        v0: initial velocity</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">        h0: initial height</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">        num_timesteps: number of timesteps to simulate</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co">        v_final: final velocity after simulation</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    hprev <span class="op">=</span> h0</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    vprev <span class="op">=</span> v0</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    dt <span class="op">=</span> <span class="fl">0.01</span> <span class="co"># seconds</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    h_tape <span class="op">=</span> [hprev]</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    t_tape <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    v_tape <span class="op">=</span> [vprev]</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, num_timesteps):</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># # Update position and velocity</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> hprev <span class="op">+</span> vprev <span class="op">*</span> dt</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> vprev <span class="op">-</span> g <span class="op">*</span> dt</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for bounce (conditional!)</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> h <span class="op">&lt;=</span> <span class="dv">0</span>:  </span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="op">-</span>h  <span class="co"># Assume ball regains height lost</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> <span class="op">-</span>e <span class="op">*</span> v  <span class="co"># Reverse velocity with energy loss</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        hprev <span class="op">=</span> h</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        vprev <span class="op">=</span> v</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        t_tape.append(t_tape[<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> dt)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        h_tape.append(h)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>        v_tape.append(v)</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> v, h, h_tape, t_tape, v_tape</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Side note: Since we are using Euler/verlet integration - </span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a><span class="co"># if you change h0 or another parameter to get a lot of bounces, the error may accumulate significantly.</span></span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="co"># This could result in an unphysical result (e.g., the ball bouncing higher than its initial height).</span></span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="co"># For our purposes here, dt and timesteps have been tuned for the parameters you will try to keep this error small.</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>v0 <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>h0 <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the simulation</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>v_final, h_final, h_tape, t_tape, v_tape <span class="op">=</span> bounce_simulation(g, e, v0, h0, <span class="dv">1000</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Final velocity: </span><span class="sc">{</span>v_final<span class="sc">:.2f}</span><span class="ss"> m/s"</span>)</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Final height: </span><span class="sc">{</span>h_final<span class="sc">:.2f}</span><span class="ss"> m"</span>)</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Parameters: g=</span><span class="sc">{</span>g<span class="sc">}</span><span class="ss">, e=</span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">, v0=</span><span class="sc">{</span>v0<span class="sc">}</span><span class="ss">, h0=</span><span class="sc">{</span>h0<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>plt.plot(t_tape, h_tape, label<span class="op">=</span><span class="st">'Height (m)'</span>)</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Time (s)'</span>)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Height (m)'</span>)</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>v_tape_h0_1 <span class="op">=</span> v_tape</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>h_tape_h0_1 <span class="op">=</span> h_tape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Final velocity: -5.48 m/s
Final height: 3.41 m

Parameters: g=10.0, e=0.9, v0=0.0, h0=10.0</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ps2_files/figure-html/ps2_part1_autodiff-cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="part-a-sensitivity-analysis" class="level3" data-number="19.4.3">
<h3 data-number="19.4.3" class="anchored" data-anchor-id="part-a-sensitivity-analysis"><span class="header-section-number">19.4.3</span> Part A: Sensitivity Analysis</h3>
<p><strong>Question</strong>: Which parameter has the biggest influence on the final velocity?</p>
<p>With AD, we want to compute the sensitivities: <span class="math display">\[
\nabla v_{\text{final}} = \left[\frac{\partial v_{\text{final}}}{\partial g}, \frac{\partial v_{\text{final}}}{\partial e}, \frac{\partial v_{\text{final}}}{\partial v_0}, \frac{\partial v_{\text{final}}}{\partial h_0}\right]
\]</span></p>
<p><strong>Your Task</strong>: Use PyTorch to compute these sensitivities at the final timestep. Also, plot your sensitivities as a function of time. You may want to change the function such that the input is a vector of parameters rather than separate scalars.</p>
<div id="cell-27" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute gradient using PyTorch</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Hint: Call backward() on the final velocity with respect to inputs within a loop over the timesteps</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="cf">pass</span>  <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement your PyTorch AD sensitivity analysis here</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Question 1</strong>: Which parameter has the largest influence on the final velocity (largest absolute sensitivity)?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 2</strong>: How do the sensitivities behave as a function of time? What happens to each parameter at and between bounces?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 3</strong>: What happens when we change <span class="math inline">\(h_0\)</span> to 1.0 m? How do the sensitivities change?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 4</strong>: What parameters have the least influence on the final velocity? Is there a flaw in the simulation or AD approach that could explain this - or does everything make sense physically?</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
</section>
<section id="part-b-diagnosing-the-results" class="level3" data-number="19.4.4">
<h3 data-number="19.4.4" class="anchored" data-anchor-id="part-b-diagnosing-the-results"><span class="header-section-number">19.4.4</span> Part B: Diagnosing the Results</h3>
<p><strong>Observation</strong>: You may have noticed that the sensitivity to one of the parameters is approximately zero. Let’s investigate this further.</p>
<p>We can confirm our suspicions by double-checking our AD result against an approximate sensitivity calculation.</p>
<p><strong>Task</strong>: For the parameter(s) you found to have near-zero sensitivity, compute a sensitivity approximation by perturbing the parameter in question. Plot the sensitvity as a function of time and compare it to the AD result.</p>
<div id="cell-30" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the sensitivity results</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="cf">pass</span>  <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement your sensitivity plotting code here</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Question 1</strong>: Is there a discrepancy between the AD and approximated results? If so, why could this be happening? (Hint: are there discontinuities in the simulation or not?)</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
<p><strong>Question 2</strong>: If there is a discrepancy, how would you fix it? If not, why does everything make sense physically? (You do not actually need to implement the fix, just describe it. Alternatively, you can try and prove that no discrepancy exists (i.e by writing out an example AD computation through a bounce))</p>
<p><strong>Student Response:</strong> [Insert your answer here]</p>
</section>
</section>
</div>
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/ML4ME_Textbook/ML4ME_Textbook/problems/ps2_part2.ipynb" data-notebook-title="Problem Set: Improving GANs for Airfoil Generation" data-notebook-cellid="cell-0">
<section id="problem-set-improving-gans-for-airfoil-generation" class="level1" data-number="20">
<h1 data-number="20"><span class="header-section-number">20</span> Problem Set: Improving GANs for Airfoil Generation</h1>
<section id="learning-objectives" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">20.1</span> Learning Objectives</h2>
<p>In this problem set, you will: 1. Train a baseline GAN on 1D airfoil curves 2. Diagnose training issues using metrics and visualizations 3. Select and implement GAN improvements from a “word bank” of modern techniques 4. Hypothesize the impact of each improvement before testing 5. Compare results and understand which techniques help in which scenarios</p>
</section>
<section id="overview-1" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="overview-1"><span class="header-section-number">20.2</span> Overview</h2>
<p>Generative Adversarial Networks are notoriously difficult to train. Over the years, researchers have developed various techniques to improve training stability, output quality, and diversity. In this exercise, you’ll work with a 1D GAN that generates airfoil shapes.</p>
<p>You’ll start with a <strong>baseline implementation</strong> that has known issues, then systematically apply improvements from the literature to see their effects.</p>
<hr>
</section>
<section id="problem-setup-airfoil-generation" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="problem-setup-airfoil-generation"><span class="header-section-number">20.3</span> Problem Setup: Airfoil Generation</h2>
<p><strong>Dataset:</strong> 1,528 airfoil curves, each represented as 192 (x,y) coordinate pairs<br>
<strong>Task:</strong> Generate realistic airfoil shapes<br>
<strong>Challenge:</strong> Airfoils must be smooth, physically valid, and diverse</p>
</section>
<section id="setup-and-imports" class="level2" data-number="20.4">
<h2 data-number="20.4" class="anchored" data-anchor-id="setup-and-imports"><span class="header-section-number">20.4</span> Setup and Imports</h2>
<div id="cell-3" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch <span class="im">as</span> th</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, TensorDataset</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.gridspec <span class="im">import</span> GridSpec</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> NamedTuple, Optional</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Set style</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.dpi'</span>] <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seeds for reproducibility</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>random.seed(SEED)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>np.random.seed(SEED)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>th.manual_seed(SEED)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>th.cuda.manual_seed(SEED)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>th.cuda.manual_seed_all(SEED)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>th.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>th.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Device selection</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> th.backends.mps.is_available():</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> th.device(<span class="st">"mps"</span>)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set MPS seed</span></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>    th.mps.manual_seed(SEED)</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> th.cuda.is_available():</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> th.device(<span class="st">"cuda"</span>)</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> th.device(<span class="st">"cpu"</span>)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random seed: </span><span class="sc">{</span>SEED<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using device: mps</code></pre>
</div>
</div>
</section>
<section id="load-airfoil-dataset" class="level2" data-number="20.5">
<h2 data-number="20.5" class="anchored" data-anchor-id="load-airfoil-dataset"><span class="header-section-number">20.5</span> Load Airfoil Dataset</h2>
<div id="cell-5" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load airfoil data</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://github.com/IDEALLab/ML4ME_Textbook/raw/main/part1/airfoil_interp_uniform.npy"</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(url)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>X_airfoils <span class="op">=</span> np.load(io.BytesIO(response.content))  <span class="co"># Shape: (1528, 192, 2)</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset shape: </span><span class="sc">{</span>X_airfoils<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of airfoils: </span><span class="sc">{</span>X_airfoils<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Points per airfoil: </span><span class="sc">{</span>X_airfoils<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten to (N, 384) for easier handling</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>X_flat <span class="op">=</span> X_airfoils.reshape(X_airfoils.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize to [-1, 1] range (important for tanh output)</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>X_mean <span class="op">=</span> X_flat.mean(axis<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>X_std <span class="op">=</span> X_flat.std(axis<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-8</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>X_normalized <span class="op">=</span> (X_flat <span class="op">-</span> X_mean) <span class="op">/</span> X_std</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>X_normalized <span class="op">=</span> np.clip(X_normalized, <span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>) <span class="op">/</span> <span class="dv">3</span>  <span class="co"># Soft clip to [-1, 1]</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Normalized data range: [</span><span class="sc">{</span>X_normalized<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>X_normalized<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize some airfoils</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>):</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="bu">len</span>(X_airfoils))</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    airfoil <span class="op">=</span> X_airfoils[idx]</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    axes[i].plot(airfoil[:, <span class="dv">0</span>], airfoil[:, <span class="dv">1</span>], <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    axes[i].set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'Airfoil </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    axes[i].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlim(<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylim(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Sample Airfoils from Dataset'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset shape: (1528, 192, 2)
Number of airfoils: 1528
Points per airfoil: 192

Normalized data range: [-1.000, 1.000]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ps2_files/figure-html/ps2_part2-cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="convert-to-pytorch-tensor" class="level2" data-number="20.6">
<h2 data-number="20.6" class="anchored" data-anchor-id="convert-to-pytorch-tensor"><span class="header-section-number">20.6</span> Convert to PyTorch Tensor</h2>
<div id="cell-7" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to PyTorch tensor</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>X_tensor <span class="op">=</span> th.FloatTensor(X_normalized).to(device)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor shape: </span><span class="sc">{</span>X_tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor shape: torch.Size([1528, 384])</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrainingHistory(NamedTuple):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Store training metrics."""</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    d_loss: <span class="bu">list</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    g_loss: <span class="bu">list</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    d_real_score: <span class="bu">list</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    d_fake_score: <span class="bu">list</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    diversity: <span class="bu">list</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    gradient_penalty: <span class="bu">list</span>  <span class="co"># For WGAN-GP</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_diversity(samples: th.Tensor) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute diversity using average pairwise L2 distance."""</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    samples_flat <span class="op">=</span> samples.reshape(samples.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    dists <span class="op">=</span> th.cdist(samples_flat, samples_flat, p<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> samples.size(<span class="dv">0</span>)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.0</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Average of upper triangular (exclude diagonal)</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dists.<span class="bu">sum</span>().item() <span class="op">/</span> (n <span class="op">*</span> (n <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_pca_coverage(generator, latent_dim: <span class="bu">int</span>, title_suffix: <span class="bu">str</span> <span class="op">=</span> <span class="st">""</span>, n_samples: <span class="bu">int</span> <span class="op">=</span> <span class="dv">500</span>):</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Plot 2D PCA visualization comparing real vs generated distribution."""</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    generator.<span class="bu">eval</span>()</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate samples</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> th.no_grad():</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> th.randn(n_samples, latent_dim, device<span class="op">=</span>device)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>        gen_designs_flat <span class="op">=</span> generator(z).cpu().numpy()</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Denormalize generated samples</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    gen_designs_flat <span class="op">=</span> gen_designs_flat <span class="op">*</span> <span class="dv">3</span> <span class="op">*</span> X_std <span class="op">+</span> X_mean</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get real samples (denormalized)</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    real_designs_flat <span class="op">=</span> X_flat</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit PCA on real data</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>    real_pca <span class="op">=</span> pca.fit_transform(real_designs_flat)</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    gen_pca <span class="op">=</span> pca.transform(gen_designs_flat)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot real data</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>    ax.scatter(real_pca[:, <span class="dv">0</span>], real_pca[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">20</span>, c<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Real'</span>, edgecolors<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot generated data</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>    ax.scatter(gen_pca[:, <span class="dv">0</span>], gen_pca[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">20</span>, c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Generated'</span>, edgecolors<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> variance)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss"> variance)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'2D PCA: Real vs Generated Distribution</span><span class="sc">{</span>title_suffix<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_training_diagnostics(history: TrainingHistory, title_suffix: <span class="bu">str</span> <span class="op">=</span> <span class="st">""</span>):</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Plot comprehensive training diagnostics."""</span></span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">10</span>))</span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>    gs <span class="op">=</span> GridSpec(<span class="dv">3</span>, <span class="dv">3</span>, figure<span class="op">=</span>fig, hspace<span class="op">=</span><span class="fl">0.3</span>, wspace<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="bu">len</span>(history.d_loss) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Row 1: Losses</span></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> fig.add_subplot(gs[<span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>    ax1.plot(epochs, history.d_loss, label<span class="op">=</span><span class="st">'Discriminator'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'C0'</span>)</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>    ax1.plot(epochs, history.g_loss, label<span class="op">=</span><span class="st">'Generator'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'C1'</span>)</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="st">'Training Losses'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>    ax1.legend()</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>    ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> fig.add_subplot(gs[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>    ax2.plot(epochs, history.d_real_score, label<span class="op">=</span><span class="st">'D(real)'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'C2'</span>)</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>    ax2.plot(epochs, history.d_fake_score, label<span class="op">=</span><span class="st">'D(fake)'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'C3'</span>)</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>    ax2.axhline(y<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.4</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="st">'Random'</span>)</span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'Score'</span>)</span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="st">'Discriminator Predictions'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>    ax2.legend()</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>    ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylim(<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>)</span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>    ax3 <span class="op">=</span> fig.add_subplot(gs[<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>    loss_ratio <span class="op">=</span> np.array(history.d_loss) <span class="op">/</span> (np.array(history.g_loss) <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>    ax3.plot(epochs, loss_ratio, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'purple'</span>)</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>    ax3.axhline(y<span class="op">=</span><span class="fl">1.0</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.4</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>    ax3.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>    ax3.set_ylabel(<span class="st">'D_loss / G_loss'</span>)</span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>    ax3.set_title(<span class="st">'Loss Ratio (Balance Check)'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>    ax3.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Row 2: Diversity and gradient penalty</span></span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>    ax4 <span class="op">=</span> fig.add_subplot(gs[<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>    ax4.plot(epochs, history.diversity, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'teal'</span>)</span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>    ax4.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a>    ax4.set_ylabel(<span class="st">'Avg Pairwise Distance'</span>)</span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a>    ax4.set_title(<span class="st">'Sample Diversity'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>    ax4.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">any</span>(gp <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">for</span> gp <span class="kw">in</span> history.gradient_penalty):</span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>        ax5 <span class="op">=</span> fig.add_subplot(gs[<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>        ax5.plot(epochs, history.gradient_penalty, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>        ax5.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>        ax5.set_ylabel(<span class="st">'Gradient Penalty'</span>)</span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>        ax5.set_title(<span class="st">'WGAN Gradient Penalty'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>        ax5.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Row 3: Score gap and loss smoothness</span></span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a>    ax6 <span class="op">=</span> fig.add_subplot(gs[<span class="dv">1</span>, <span class="dv">2</span>])</span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a>    score_gap <span class="op">=</span> np.array(history.d_real_score) <span class="op">-</span> np.array(history.d_fake_score)</span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a>    ax6.plot(epochs, score_gap, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, color<span class="op">=</span><span class="st">'darkgreen'</span>)</span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a>    ax6.axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.4</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>    ax6.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a>    ax6.set_ylabel(<span class="st">'D(real) - D(fake)'</span>)</span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a>    ax6.set_title(<span class="st">'Discriminator Score Gap'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a>    ax6.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f'Training Diagnostics</span><span class="sc">{</span>title_suffix<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">16</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_generated_airfoils(generator, latent_dim: <span class="bu">int</span>, </span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a>                           title_suffix: <span class="bu">str</span> <span class="op">=</span> <span class="st">""</span>, n_samples: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>):</span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Visualize generated airfoils."""</span></span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a>    generator.<span class="bu">eval</span>()</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample random airfoils from dataset for comparison</span></span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_airfoils), n_samples, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a>    real_designs <span class="op">=</span> X_airfoils[indices]</span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate airfoils</span></span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> th.no_grad():</span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> th.randn(n_samples, latent_dim, device<span class="op">=</span>device)</span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a>        gen_designs_flat <span class="op">=</span> generator(z).cpu().numpy()</span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Denormalize</span></span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a>    gen_designs_flat <span class="op">=</span> gen_designs_flat <span class="op">*</span> <span class="dv">3</span> <span class="op">*</span> X_std <span class="op">+</span> X_mean</span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a>    gen_designs <span class="op">=</span> gen_designs_flat.reshape(n_samples, <span class="dv">192</span>, <span class="dv">2</span>)</span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot</span></span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, n_samples, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">6</span>))</span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-149"><a href="#cb31-149" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb31-150"><a href="#cb31-150" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Real</span></span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].plot(real_designs[i, :, <span class="dv">0</span>], real_designs[i, :, <span class="dv">1</span>], <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb31-153"><a href="#cb31-153" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].set_xlim(<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>)</span>
<span id="cb31-154"><a href="#cb31-154" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].set_ylim(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb31-155"><a href="#cb31-155" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-156"><a href="#cb31-156" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb31-157"><a href="#cb31-157" aria-hidden="true" tabindex="-1"></a>            axes[<span class="dv">0</span>, i].set_ylabel(<span class="st">'Real'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-158"><a href="#cb31-158" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].set_xticks([])</span>
<span id="cb31-159"><a href="#cb31-159" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">0</span>, i].set_yticks([])</span>
<span id="cb31-160"><a href="#cb31-160" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-161"><a href="#cb31-161" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generated</span></span>
<span id="cb31-162"><a href="#cb31-162" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].plot(gen_designs[i, :, <span class="dv">0</span>], gen_designs[i, :, <span class="dv">1</span>], <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-163"><a href="#cb31-163" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb31-164"><a href="#cb31-164" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].set_xlim(<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>)</span>
<span id="cb31-165"><a href="#cb31-165" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].set_ylim(<span class="op">-</span><span class="fl">0.3</span>, <span class="fl">0.3</span>)</span>
<span id="cb31-166"><a href="#cb31-166" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-167"><a href="#cb31-167" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb31-168"><a href="#cb31-168" aria-hidden="true" tabindex="-1"></a>            axes[<span class="dv">1</span>, i].set_ylabel(<span class="st">'Generated'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-169"><a href="#cb31-169" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].set_xticks([])</span>
<span id="cb31-170"><a href="#cb31-170" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, i].set_yticks([])</span>
<span id="cb31-171"><a href="#cb31-171" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-172"><a href="#cb31-172" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f'Real vs Generated Airfoils</span><span class="sc">{</span>title_suffix<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-173"><a href="#cb31-173" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb31-174"><a href="#cb31-174" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb31-175"><a href="#cb31-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-176"><a href="#cb31-176" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training utilities defined."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training utilities defined.</code></pre>
</div>
</div>
<p>—# Part 1: Baseline GANWe start with a <strong>vanilla GAN</strong> using:- Binary Cross-Entropy (BCE) loss- Standard fully-connected architectures- Basic Adam optimizer- <strong>No batch normalization</strong>- <strong>No dropout</strong>- <strong>Moderate learning rates</strong> (1e-4)<strong>Note:</strong> The baseline is intentionally simplified to create a clean starting point. This helps you better appreciate the benefits of the improvement techniques you’ll implement later.</p>
</section>
<section id="baseline-architecture" class="level2" data-number="20.7">
<h2 data-number="20.7" class="anchored" data-anchor-id="baseline-architecture"><span class="header-section-number">20.7</span> Baseline Architecture</h2>
<div id="cell-11" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BaselineGenerator(nn.Module):    <span class="st">"""Baseline unconditional generator for 1D airfoil curves."""</span>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, latent_dim: <span class="bu">int</span>, output_dim: <span class="bu">int</span>):        <span class="bu">super</span>().<span class="fu">__init__</span>()                <span class="kw">def</span> block(in_feat: <span class="bu">int</span>, out_feat: <span class="bu">int</span>):            layers <span class="op">=</span> [nn.Linear(in_feat, out_feat)]            layers.append(nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>))            <span class="cf">return</span> layers                <span class="co"># Main generation path        self.model = nn.Sequential(            *block(latent_dim, 256),            *block(256, 512),            *block(512, 1024),            nn.Linear(1024, output_dim),            nn.Tanh(),  # Output in [-1, 1]        )        def forward(self, z: th.Tensor) -&gt; th.Tensor:        return self.model(z)class BaselineDiscriminator(nn.Module):    """Baseline unconditional discriminator for 1D airfoil curves."""        def __init__(self, input_dim: int):        super().__init__()                # Main discrimination path        model_layers = [            nn.Linear(input_dim, 512),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(512, 512),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(512, 256),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(256, 1),            nn.Sigmoid(),  # Probability output        ]                self.model = nn.Sequential(*model_layers)        def forward(self, design: th.Tensor) -&gt; th.Tensor:        return self.model(design)print("Baseline models defined.")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="baseline-training-function" class="level2" data-number="20.8">
<h2 data-number="20.8" class="anchored" data-anchor-id="baseline-training-function"><span class="header-section-number">20.8</span> Baseline Training Function</h2>
<div id="cell-13" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_baseline_gan(X_data: th.Tensor,                       n_epochs: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100</span>, batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span>,                       latent_dim: <span class="bu">int</span> <span class="op">=</span> <span class="dv">64</span>, lr_gen: <span class="bu">float</span> <span class="op">=</span> <span class="fl">5e-4</span>, lr_disc: <span class="bu">float</span> <span class="op">=</span> <span class="fl">5e-4</span>,                       seed: <span class="bu">int</span> <span class="op">=</span> <span class="dv">42</span>, print_every: <span class="bu">int</span> <span class="op">=</span> <span class="dv">20</span>):    <span class="st">"""    Train baseline unconditional GAN.        Args:        X_data: Normalized design data (N, output_dim)        n_epochs: Number of training epochs        batch_size: Batch size        latent_dim: Latent noise dimension        lr_gen: Generator learning rate        lr_disc: Discriminator learning rate        seed: Random seed        print_every: Print frequency        Returns:        generator, discriminator, history    """</span>    <span class="co"># Setup    th.manual_seed(seed)    np.random.seed(seed)        output_dim = X_data.shape[1]        # Create DataLoader    dataset = TensorDataset(X_data)    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)        # Initialize models    generator = BaselineGenerator(latent_dim, output_dim).to(device)    discriminator = BaselineDiscriminator(output_dim).to(device)        # Loss and optimizers    criterion = nn.BCELoss()    opt_gen = optim.Adam(generator.parameters(), lr=lr_gen, betas=(0.5, 0.999))    opt_disc = optim.Adam(discriminator.parameters(), lr=lr_disc, betas=(0.5, 0.999))        # Training history    history = TrainingHistory([], [], [], [], [], [])        # Training loop    for epoch in range(n_epochs):        d_losses, g_losses = [], []        d_real_scores, d_fake_scores = [], []                for (designs,) in dataloader:            batch_size_actual = designs.size(0)            valid = th.ones(batch_size_actual, device=device)            fake = th.zeros(batch_size_actual, device=device)                        # -----------------            # Train Discriminator            # -----------------            opt_disc.zero_grad()                        # Real samples            real_pred = discriminator(designs).squeeze()            real_loss = criterion(real_pred, valid)                        # Fake samples            z = th.randn(batch_size_actual, latent_dim, device=device)            gen_designs = generator(z)            fake_pred = discriminator(gen_designs.detach()).squeeze()            fake_loss = criterion(fake_pred, fake)                        # Total discriminator loss            d_loss = (real_loss + fake_loss) / 2            d_loss.backward()            opt_disc.step()                        # -----------------            # Train Generator            # -----------------            opt_gen.zero_grad()                        z = th.randn(batch_size_actual, latent_dim, device=device)            gen_designs = generator(z)            gen_pred = discriminator(gen_designs).squeeze()                        g_loss = criterion(gen_pred, valid)  # Want discriminator to predict "real"            g_loss.backward()            opt_gen.step()                        # Record metrics            d_losses.append(d_loss.item())            g_losses.append(g_loss.item())            d_real_scores.append(real_pred.mean().item())            d_fake_scores.append(fake_pred.mean().item())                # Compute diversity        with th.no_grad():            z_eval = th.randn(100, latent_dim, device=device)            samples_eval = generator(z_eval)            diversity = compute_diversity(samples_eval)                # Store epoch metrics        history.d_loss.append(np.mean(d_losses))        history.g_loss.append(np.mean(g_losses))        history.d_real_score.append(np.mean(d_real_scores))        history.d_fake_score.append(np.mean(d_fake_scores))        history.diversity.append(diversity)        history.gradient_penalty.append(0.0)  # Not used in baseline                if (epoch + 1) % print_every == 0 or epoch == 0:            print(f"Epoch {epoch+1:03d}/{n_epochs} | "                  f"D loss: {history.d_loss[-1]:.4f} | "                  f"G loss: {history.g_loss[-1]:.4f} | "                  f"D(real): {history.d_real_score[-1]:.3f} | "                  f"D(fake): {history.d_fake_score[-1]:.3f} | "                  f"Diversity: {history.diversity[-1]:.2f}")        return generator, discriminator, historyprint("Baseline training function defined.")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="exercise-1-train-baseline-and-diagnose-issues" class="level2" data-number="20.9">
<h2 data-number="20.9" class="anchored" data-anchor-id="exercise-1-train-baseline-and-diagnose-issues"><span class="header-section-number">20.9</span> Exercise 1: Train Baseline and Diagnose Issues</h2>
<p><strong>Task:</strong> Train the baseline GAN and analyze the results.</p>
<p><strong>Questions to answer:</strong> 1. Does the training appear stable? Look at the loss curves. 2. What is happening with D(real) and D(fake) scores? Are they diverging or collapsing? 3. How does sample diversity evolve over training? 4. Do the generated airfoils look realistic? 5. What problems do you observe?</p>
<div id="cell-15" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train baselineprint("="*80)print("TRAINING BASELINE GAN")print("="*80)latent_dim = 64gen_baseline, disc_baseline, hist_baseline = train_baseline_gan(    X_tensor,    n_epochs=150,    batch_size=64,    latent_dim=latent_dim,    lr_gen=1e-4,      lr_disc=1e-4,    seed=42,    print_every=30)# Visualize resultsplot_training_diagnostics(hist_baseline, " - Baseline")plot_generated_airfoils(gen_baseline, latent_dim, " - Baseline")plot_pca_coverage(gen_baseline, latent_dim, " - Baseline")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="your-observations" class="level3" data-number="20.9.1">
<h3 data-number="20.9.1" class="anchored"><span class="header-section-number">20.9.1</span> Your Observations:</h3>
<p><strong>Write your observations here:</strong></p>
<ol type="1">
<li><h2 id="training-stability" data-number="20.10" class="anchored" data-anchor-id="your-observations"><span class="header-section-number">20.10</span> Training stability:</h2></li>
<li><h2 id="discriminator-scores" data-number="20.11" class="anchored"><span class="header-section-number">20.11</span> Discriminator scores:</h2></li>
<li><h2 id="sample-diversity" data-number="20.12" class="anchored"><span class="header-section-number">20.12</span> Sample diversity:</h2></li>
<li><h2 id="visual-quality" data-number="20.13" class="anchored"><span class="header-section-number">20.13</span> Visual quality:</h2></li>
<li><h2 id="main-problems-identified" data-number="20.14" class="anchored"><span class="header-section-number">20.14</span> Main problems identified:</h2></li>
</ol>
<hr>
</section>
</section>
</section>
<section id="part-2-gan-improvement-word-bank" class="level1" data-number="21">
<h1 data-number="21"><span class="header-section-number">21</span> Part 2: GAN Improvement Word Bank</h1>
<p>Below is a <strong>word bank</strong> of GAN improvements from the literature. Each technique addresses specific training challenges. Your job is to:</p>
<ol type="1">
<li><strong>Select</strong> techniques you think will help with the issues you identified</li>
<li><strong>Hypothesize</strong> what improvement each will provide</li>
<li><strong>Implement</strong> the technique (code templates provided)</li>
<li><strong>Test</strong> and compare against baseline</li>
</ol>
<section id="available-techniques" class="level2" data-number="21.1">
<h2 data-number="21.1" class="anchored" data-anchor-id="available-techniques"><span class="header-section-number">21.1</span> Available Techniques:</h2>
<section id="wasserstein-loss-with-gradient-penalty-wgan-gp" class="level3" data-number="21.1.1">
<h3 data-number="21.1.1" class="anchored" data-anchor-id="wasserstein-loss-with-gradient-penalty-wgan-gp"><span class="header-section-number">21.1.1</span> 1. Wasserstein Loss with Gradient Penalty (WGAN-GP)</h3>
<p><strong>What it does:</strong> Replaces BCE loss with Wasserstein distance. Adds gradient penalty to enforce Lipschitz constraint.<br>
<strong>Paper:</strong> “Improved Training of Wasserstein GANs” (Gulrajani et al., 2017)<br>
<strong>When to use:</strong> Helps with training stability and vanishing gradients<br>
<strong>Conceptual difficulty:</strong> Medium (requires understanding Wasserstein distance)</p>
</section>
<section id="spectral-normalization" class="level3" data-number="21.1.2">
<h3 data-number="21.1.2" class="anchored" data-anchor-id="spectral-normalization"><span class="header-section-number">21.1.2</span> 2. Spectral Normalization</h3>
<p><strong>What it does:</strong> Normalizes weight matrices to have spectral norm ≤ 1 (Lipschitz-1 constraint).<br>
<strong>Paper:</strong> “Spectral Normalization for GANs” (Miyato et al., 2018)<br>
<strong>When to use:</strong> Discriminator becomes too powerful, generator gradients vanish<br>
<strong>Conceptual difficulty:</strong> Easy (just add to layers)</p>
</section>
<section id="minibatch-discrimination-diversity-penalty" class="level3" data-number="21.1.3">
<h3 data-number="21.1.3" class="anchored" data-anchor-id="minibatch-discrimination-diversity-penalty"><span class="header-section-number">21.1.3</span> 3. Minibatch Discrimination / Diversity Penalty</h3>
<p><strong>What it does:</strong> Encourages generator to produce diverse samples by penalizing similarity.<br>
<strong>Paper:</strong> “Improved Techniques for Training GANs” (Salimans et al., 2016)<br>
<strong>When to use:</strong> Mode collapse (generator produces limited variety)<br>
<strong>Conceptual difficulty:</strong> Easy (add diversity term to loss)</p>
</section>
<section id="two-timescale-update-rule-ttur" class="level3" data-number="21.1.4">
<h3 data-number="21.1.4" class="anchored" data-anchor-id="two-timescale-update-rule-ttur"><span class="header-section-number">21.1.4</span> 4. Two-Timescale Update Rule (TTUR)</h3>
<p><strong>What it does:</strong> Uses separate learning rates for G and D, typically lr_D &gt; lr_G.<br>
<strong>Paper:</strong> “GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium” (Heusel et al., 2017)<br>
<strong>When to use:</strong> Loss oscillations, unstable training dynamics<br>
<strong>Conceptual difficulty:</strong> Very easy (just adjust learning rates)</p>
</section>
<section id="label-smoothing" class="level3" data-number="21.1.5">
<h3 data-number="21.1.5" class="anchored" data-anchor-id="label-smoothing"><span class="header-section-number">21.1.5</span> 5. Label Smoothing</h3>
<p><strong>What it does:</strong> Use soft labels (e.g., 0.9 instead of 1.0) for real samples to prevent overconfidence.<br>
<strong>Paper:</strong> “Improved Techniques for Training GANs” (Salimans et al., 2016)<br>
<strong>When to use:</strong> Discriminator becomes overconfident, gradients saturate<br>
<strong>Conceptual difficulty:</strong> Very easy (change target labels)</p>
</section>
<section id="feature-matching" class="level3" data-number="21.1.6">
<h3 data-number="21.1.6" class="anchored" data-anchor-id="feature-matching"><span class="header-section-number">21.1.6</span> 6. Feature Matching</h3>
<p><strong>What it does:</strong> Train generator to match statistics of intermediate discriminator features, not just final output.<br>
<strong>Paper:</strong> “Improved Techniques for Training GANs” (Salimans et al., 2016)<br>
<strong>When to use:</strong> Training instability, helps generator focus on meaningful features<br>
<strong>Conceptual difficulty:</strong> Medium (requires extracting intermediate features)</p>
</section>
</section>
<section id="advanced-topics-dont-recommend-implementing-for-time-unless-interested" class="level2" data-number="21.2">
<h2 data-number="21.2" class="anchored" data-anchor-id="advanced-topics-dont-recommend-implementing-for-time-unless-interested"><span class="header-section-number">21.2</span> Advanced Topics (Don’t Recommend Implementing for Time Unless Interested)</h2>
<section id="a.-progressive-growing-curriculum-learning" class="level3" data-number="21.2.1">
<h3 data-number="21.2.1" class="anchored" data-anchor-id="a.-progressive-growing-curriculum-learning"><span class="header-section-number">21.2.1</span> a. Progressive Growing / Curriculum Learning</h3>
<p><strong>What it does:</strong> Start training with low-resolution/simple outputs, gradually increase complexity.<br>
<strong>Paper:</strong> “Progressive Growing of GANs” (Karras et al., 2018)<br>
<strong>When to use:</strong> Complex output space, difficulty learning fine details<br>
<strong>Conceptual difficulty:</strong> Hard (requires architectural changes)</p>
</section>
<section id="b.-self-attention-mechanism" class="level3" data-number="21.2.2">
<h3 data-number="21.2.2" class="anchored" data-anchor-id="b.-self-attention-mechanism"><span class="header-section-number">21.2.2</span> b. Self-Attention Mechanism</h3>
<p><strong>What it does:</strong> Allows network to model long-range dependencies in the data.<br>
<strong>Paper:</strong> “Self-Attention GANs” (Zhang et al., 2019)<br>
<strong>When to use:</strong> Data has long-range structure (like airfoil smoothness)<br>
<strong>Conceptual difficulty:</strong> Medium (requires attention layer implementation)</p>
<hr>
</section>
</section>
</section>
<section id="part-3-implement-your-chosen-improvements" class="level1" data-number="22">
<h1 data-number="22"><span class="header-section-number">22</span> Part 3: Implement Your Chosen Improvements</h1>
<section id="exercise-2-select-and-hypothesize" class="level2" data-number="22.1">
<h2 data-number="22.1" class="anchored" data-anchor-id="exercise-2-select-and-hypothesize"><span class="header-section-number">22.1</span> Exercise 2: Select and Hypothesize</h2>
<p><strong>Before implementing anything, answer these questions:</strong></p>
<ol type="1">
<li>Which <strong>TWO</strong> techniques do you think will help most with the baseline issues you identified?
<ul>
<li>Technique 1: _______________</li>
<li>Technique 2: _______________</li>
</ul></li>
<li>For each technique, <strong>hypothesize</strong> what specific improvement you expect:
<ul>
<li>Technique 1 hypothesis:
<ul>
<li>What metric will improve? (loss stability / diversity / visual quality / etc.)</li>
<li>Why do you think this will help?</li>
</ul></li>
<li>Technique 2 hypothesis:
<ul>
<li>What metric will improve?</li>
<li>Why do you think this will help?</li>
</ul></li>
</ul></li>
<li>Do you expect these techniques to work well <strong>together</strong> or could they conflict?</li>
</ol>
</section>
<section id="implementation-templates" class="level2" data-number="22.2">
<h2 data-number="22.2" class="anchored" data-anchor-id="implementation-templates"><span class="header-section-number">22.2</span> Implementation Templates</h2>
<p>Below are code templates for implementing each technique. <strong>Choose 2-3</strong> to implement and test.</p>
<section id="example-template-wasserstein-loss-with-gradient-penalty-wgan-gp" class="level3" data-number="22.2.1">
<h3 data-number="22.2.1" class="anchored" data-anchor-id="example-template-wasserstein-loss-with-gradient-penalty-wgan-gp"><span class="header-section-number">22.2.1</span> Example Template: Wasserstein Loss with Gradient Penalty (WGAN-GP)</h3>
<div id="cell-21" class="cell" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_gradient_penalty(discriminator, real_samples, fake_samples):</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute gradient penalty for WGAN-GP.</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The gradient penalty enforces the Lipschitz constraint by penalizing</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co">    gradients that deviate from norm 1.</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> real_samples.size(<span class="dv">0</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Random interpolation coefficient</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> th.rand(batch_size, <span class="dv">1</span>, device<span class="op">=</span>real_samples.device)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Interpolate between real and fake samples</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    interpolates <span class="op">=</span> (alpha <span class="op">*</span> real_samples <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alpha) <span class="op">*</span> fake_samples).requires_grad_(<span class="va">True</span>)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get discriminator output for interpolated samples</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    d_interpolates <span class="op">=</span> discriminator(interpolates)</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute gradients</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    gradients <span class="op">=</span> th.autograd.grad(</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>        outputs<span class="op">=</span>d_interpolates,</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>        inputs<span class="op">=</span>interpolates,</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>        grad_outputs<span class="op">=</span>th.ones_like(d_interpolates),</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>        create_graph<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>        retain_graph<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    )[<span class="dv">0</span>]</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    gradients <span class="op">=</span> gradients.view(batch_size, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    gradient_norm <span class="op">=</span> gradients.norm(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Penalty: (||gradient|| - 1)^2</span></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>    penalty <span class="op">=</span> ((gradient_norm <span class="op">-</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).mean()</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> penalty</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Modified Discriminator for WGAN (no sigmoid!)</span></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WGANDiscriminator(nn.Module):</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""WGAN-GP discriminator (critic) - no sigmoid output!"""</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim: <span class="bu">int</span>):</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> nn.Sequential(</span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_dim, <span class="dv">512</span>),</span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">256</span>),</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.2</span>, inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, <span class="dv">1</span>),</span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>            <span class="co"># NO SIGMOID! - WGAN uses raw scores</span></span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, design: th.Tensor) <span class="op">-&gt;</span> th.Tensor:</span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model(design)</span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Implement WGAN-GP training function</span></span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a><span class="co"># IMPLEMENTATION HINTS:</span></span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Start by copying the train_baseline_gan function as a template</span></span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Replace BaselineDiscriminator with WGANDiscriminator (already defined above)</span></span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Remove the BCE criterion - WGAN doesn't use it!</span></span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. In the discriminator training loop:</span></span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Add a for loop to train the critic n_critic times per batch</span></span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Wasserstein loss: critic_loss = -real_pred.mean() + fake_pred.mean() + lambda_gp * gp</span></span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Use compute_gradient_penalty(critic, designs, gen_designs) to get gp</span></span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Store gp values in a list for tracking: gp_values.append(gp.item())</span></span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. In generator training (happens once per n_critic discriminator updates):</span></span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Generator loss: gen_loss = -gen_pred.mean()</span></span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. IMPORTANT: For visualization, normalize critic scores to [0,1] range using running min/max</span></span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Before the epoch loop, create: real_score_history = [], fake_score_history = []</span></span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a><span class="co">#    - In the batch loop, extend these lists: real_score_history.extend(d_real_scores)</span></span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a><span class="co">#    - After each epoch, compute: score_min = min(real_score_history + fake_score_history)</span></span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a><span class="co">#    - score_max = max(real_score_history + fake_score_history)</span></span>
<span id="cb36-75"><a href="#cb36-75" aria-hidden="true" tabindex="-1"></a><span class="co">#    - Normalize for storage: normalized_real = (np.mean(d_real_scores) - score_min) / (score_max - score_min)</span></span>
<span id="cb36-76"><a href="#cb36-76" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Use Adam optimizer with betas=(0.5, 0.9) for both G and C (different from baseline's (0.5, 0.999))</span></span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Store gradient penalty in history: history.gradient_penalty.append(np.mean(gp_values))</span></span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. Typical hyperparameters: lambda_gp=10, n_critic=5, lr_gen=1e-4, lr_disc=1e-4</span></span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-80"><a href="#cb36-80" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_wgan_gp(X_data, n_epochs<span class="op">=</span><span class="dv">100</span>, batch_size<span class="op">=</span><span class="dv">32</span>, latent_dim<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb36-81"><a href="#cb36-81" aria-hidden="true" tabindex="-1"></a>                  lr_gen<span class="op">=</span><span class="fl">1e-4</span>, lr_disc<span class="op">=</span><span class="fl">1e-4</span>, lambda_gp<span class="op">=</span><span class="dv">10</span>, n_critic<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a>                  seed<span class="op">=</span><span class="dv">42</span>, print_every<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a><span class="co">    Train WGAN with gradient penalty.</span></span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a><span class="co">        lambda_gp: Gradient penalty weight (typically 10)</span></span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a><span class="co">        n_critic: Train discriminator n_critic times per generator update</span></span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Implement this!</span></span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start by copying train_baseline_gan and modifying the loss computation</span></span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"WGAN-GP template defined."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>WGAN-GP template defined.</code></pre>
</div>
</div>
</section>
<section id="example-template-spectral-normalization" class="level3" data-number="22.2.2">
<h3 data-number="22.2.2" class="anchored" data-anchor-id="example-template-spectral-normalization"><span class="header-section-number">22.2.2</span> Example Template: Spectral Normalization</h3>
<div id="cell-23" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SpectralNormDiscriminator(nn.Module):    <span class="st">"""Discriminator with spectral normalization on all linear layers."""</span>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim: <span class="bu">int</span>):        <span class="bu">super</span>().<span class="fu">__init__</span>()                <span class="co"># Apply spectral norm to linear layers        model_layers = [            nn.utils.spectral_norm(nn.Linear(input_dim, 512)),            nn.LeakyReLU(0.2, inplace=True),            nn.utils.spectral_norm(nn.Linear(512, 512)),            nn.LeakyReLU(0.2, inplace=True),            nn.utils.spectral_norm(nn.Linear(512, 256)),            nn.LeakyReLU(0.2, inplace=True),            nn.utils.spectral_norm(nn.Linear(256, 1)),            nn.Sigmoid(),        ]                self.model = nn.Sequential(*model_layers)        def forward(self, design: th.Tensor) -&gt; th.Tensor:        return self.model(design)# </span><span class="al">TODO</span><span class="co">: Implement training with spectral norm discriminator# IMPLEMENTATION HINTS:# 1. Copy the train_baseline_gan function# 2. Replace: discriminator = BaselineDiscriminator(output_dim).to(device)#    With: discriminator = SpectralNormDiscriminator(output_dim).to(device)# 3. Everything else stays exactly the same! That's the beauty of spectral normalization.# 4. Use the same BCE loss and training loop as baseline# 5. Recommended hyperparameters: lr_gen=1e-4, lr_disc=1e-4 (can try lr_disc slightly higher like 4e-4)print("Spectral normalization template defined.")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="example-template-diversity-penalty" class="level3" data-number="22.2.3">
<h3 data-number="22.2.3" class="anchored" data-anchor-id="example-template-diversity-penalty"><span class="header-section-number">22.2.3</span> Example Template: Diversity Penalty</h3>
<div id="cell-25" class="cell" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> diversity_penalty(generated_samples, lambda_div<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute diversity penalty to encourage varied outputs.</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Penalizes the generator if generated samples are too similar.</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co">    We want HIGH diversity, so we add NEGATIVE diversity to the loss.</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">        generated_samples: Batch of generated samples (B, D)</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">        lambda_div: Weight for diversity penalty</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Penalty term (lower diversity = higher penalty)</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> generated_samples.size(<span class="dv">0</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> batch_size <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> th.tensor(<span class="fl">0.0</span>, device<span class="op">=</span>generated_samples.device)</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute pairwise distances</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    samples_flat <span class="op">=</span> generated_samples.view(batch_size, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>    dists <span class="op">=</span> th.cdist(samples_flat, samples_flat, p<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Average pairwise distance (higher = more diverse)</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    avg_dist <span class="op">=</span> dists.<span class="bu">sum</span>() <span class="op">/</span> (batch_size <span class="op">*</span> (batch_size <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We want to MAXIMIZE diversity, so MINIMIZE negative diversity</span></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>    penalty <span class="op">=</span> <span class="op">-</span>lambda_div <span class="op">*</span> avg_dist</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> penalty</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Modify generator training to include diversity penalty</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a><span class="co"># IMPLEMENTATION HINTS:</span></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Copy the train_baseline_gan function</span></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. In the generator training section, modify the loss calculation:</span></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="co">#    OLD: g_loss = criterion(gen_pred, valid)</span></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a><span class="co">#    NEW: adversarial_loss = criterion(gen_pred, valid)</span></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a><span class="co">#         div_penalty = diversity_penalty(gen_designs, lambda_div)</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a><span class="co">#         g_loss = adversarial_loss + div_penalty</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Add lambda_div as a parameter to your training function (typical value: 0.1)</span></span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Note: diversity_penalty returns NEGATIVE diversity, so adding it encourages diversity</span></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Experiment with lambda_div values: 0.01 (subtle), 0.1 (moderate), 0.5 (strong)</span></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Recommended: lr_gen=1e-4, lr_disc=1e-4, lambda_div=0.1</span></span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Diversity penalty template defined."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Diversity penalty template defined.</code></pre>
</div>
</div>
</section>
<section id="example-template-label-smoothing" class="level3" data-number="22.2.4">
<h3 data-number="22.2.4" class="anchored" data-anchor-id="example-template-label-smoothing"><span class="header-section-number">22.2.4</span> Example Template: Label Smoothing</h3>
<div id="cell-27" class="cell" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Implement label smoothing</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># IMPLEMENTATION HINTS:</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Copy the train_baseline_gan function</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. In the discriminator training section, replace the label creation:</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    OLD: valid = th.ones(batch_size_actual, device=device)</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         fake = th.zeros(batch_size_actual, device=device)</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co">#    NEW: valid = th.ones(batch_size_actual, device=device) * smooth_real  # e.g., 0.9</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co">#         fake = th.ones(batch_size_actual, device=device) * smooth_fake   # e.g., 0.1</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. In the generator training section, keep using hard labels:</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co">#    valid_gen = th.ones(batch_size_actual, device=device)  # Still 1.0 for generator</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Add smooth_real and smooth_fake as parameters (typical: smooth_real=0.9, smooth_fake=0.1)</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Alternative (one-sided smoothing): smooth_real=0.9, smooth_fake=0.0</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. This prevents the discriminator from becoming overconfident</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Recommended: lr_gen=1e-4, lr_disc=1e-4, smooth_real=0.9, smooth_fake=0.1</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Label smoothing hint provided."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label smoothing hint provided.</code></pre>
</div>
</div>
</section>
<section id="example-template-feature-matching" class="level3" data-number="22.2.5">
<h3 data-number="22.2.5" class="anchored" data-anchor-id="example-template-feature-matching"><span class="header-section-number">22.2.5</span> Example Template: Feature Matching</h3>
<div id="cell-29" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FeatureMatchingDiscriminator(nn.Module):    <span class="st">"""Discriminator that exposes intermediate features for feature matching."""</span>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim: <span class="bu">int</span>):        <span class="bu">super</span>().<span class="fu">__init__</span>()                <span class="co"># Separate intermediate layers for feature extraction        self.hidden1 = nn.Sequential(            nn.Linear(input_dim, 512),            nn.LeakyReLU(0.2, inplace=True),            nn.Linear(512, 512),            nn.LeakyReLU(0.2, inplace=True),        )                self.hidden2 = nn.Sequential(            nn.Linear(512, 256),            nn.LeakyReLU(0.2, inplace=True),        )                self.output = nn.Sequential(            nn.Linear(256, 1),            nn.Sigmoid(),        )        def forward(self, design: th.Tensor, return_features=False):        # Extract intermediate features        h1 = self.hidden1(design)        h2 = self.hidden2(h1)        out = self.output(h2)                if return_features:            return out, h2  # Return final layer features        return out# </span><span class="al">TODO</span><span class="co">: Implement feature matching loss# IMPLEMENTATION HINTS:# 1. Copy the train_baseline_gan function# 2. Replace: discriminator = BaselineDiscriminator(output_dim).to(device)#    With: discriminator = FeatureMatchingDiscriminator(output_dim).to(device)# 3. In the discriminator training section (no changes needed here):#    - Keep using: real_pred = discriminator(designs).squeeze()#    - Keep using: fake_pred = discriminator(gen_designs.detach()).squeeze()# 4. In the generator training section, modify to use feature matching:#    # Get features from both real and fake samples#    gen_pred, fake_features = discriminator(gen_designs, return_features=True)#    with th.no_grad():  # Don't backprop through real features#        _, real_features = discriminator(designs, return_features=True)#    #    # Feature matching loss: match mean statistics#    fm_loss = th.mean((real_features.mean(0) - fake_features.mean(0)) ** 2)#    #    # Total generator loss#    adversarial_loss = criterion(gen_pred.squeeze(), valid)#    g_loss = adversarial_loss + lambda_fm * fm_loss# 5. Add lambda_fm as a parameter (typical value: 1.0 to 10.0)# 6. Recommended: lr_gen=1e-4, lr_disc=1e-4, lambda_fm=10.0print("Feature matching template defined.")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
</section>
</section>
<section id="exercise-3-implement-and-test-your-chosen-techniques" class="level2" data-number="22.3">
<h2 data-number="22.3" class="anchored" data-anchor-id="exercise-3-implement-and-test-your-chosen-techniques"><span class="header-section-number">22.3</span> Exercise 3: Implement and Test Your Chosen Techniques</h2>
<p><strong>Instructions:</strong> 1. Choose 2-3 techniques from the word bank above 2. Complete the TODO sections in the templates 3. Train models with your improvements 4. Compare results to baseline</p>
<p>Use the cells below to implement your experiments.</p>
<div id="cell-31" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR IMPLEMENTATION HERE - Technique 1</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Copy relevant template and complete the TODOs</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-32" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train and evaluate Technique 1</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-33" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR IMPLEMENTATION HERE - Technique 2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-34" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train and evaluate Technique 2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-36" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># (Optional) Combine techniques</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<hr>
</section>
</section>
<section id="part-4-analysis-and-comparison" class="level1" data-number="23">
<h1 data-number="23"><span class="header-section-number">23</span> Part 4: Analysis and Comparison</h1>
<section id="exercise-4-compare-results" class="level2" data-number="23.1">
<h2 data-number="23.1" class="anchored" data-anchor-id="exercise-4-compare-results"><span class="header-section-number">23.1</span> Exercise 4: Compare Results</h2>
<p>Create comparison plots and fill in the analysis table below.</p>
<div id="cell-38" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Plot loss curves for all experiments</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Create comparison plots</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># fig, axes = plt.subplots(1, 3, figsize=(18, 5))</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="co"># # Compare losses</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[0].plot(hist_baseline.d_loss, label='Baseline', alpha=0.7)</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[0].plot(hist_technique1.d_loss, label='Technique 1', alpha=0.7)</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[0].plot(hist_technique2.d_loss, label='Technique 2', alpha=0.7)</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[0].set_title('Discriminator Loss Comparison')</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[0].legend()</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="co"># # Compare diversity</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[1].plot(hist_baseline.diversity, label='Baseline', alpha=0.7)</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[1].plot(hist_technique1.diversity, label='Technique 1', alpha=0.7)</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[1].plot(hist_technique2.diversity, label='Technique 2', alpha=0.7)</span></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[1].set_title('Diversity Comparison')</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a><span class="co"># axes[1].legend()</span></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a><span class="co"># # Compare score gap</span></span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a><span class="co"># # ...</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="results-table" class="level3" data-number="23.1.1">
<h3 data-number="23.1.1" class="anchored" data-anchor-id="results-table"><span class="header-section-number">23.1.1</span> Results Table</h3>
<p>Fill in this table with your results:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Baseline</th>
<th>Technique 1</th>
<th>Technique 2</th>
<th>Combined</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Final D Loss</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Final G Loss</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Final Diversity</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Training Stability (1-5)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Visual Quality (1-5)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="analysis-questions" class="level3" data-number="23.1.2">
<h3 data-number="23.1.2" class="anchored"><span class="header-section-number">23.1.2</span> Analysis Questions</h3>
<ol type="1">
<li><h2 id="were-your-hypotheses-correct-did-the-techniques-improve-the-metrics-you-expected" data-number="23.2" class="anchored" data-anchor-id="analysis-questions"><span class="header-section-number">23.2</span> <strong>Were your hypotheses correct?</strong> Did the techniques improve the metrics you expected?</h2></li>
<li><h2 id="which-technique-was-most-effective-why-do-you-think-this-is" data-number="23.3" class="anchored"><span class="header-section-number">23.3</span> <strong>Which technique was most effective?</strong> Why do you think this is?</h2></li>
<li><h2 id="did-any-techniques-make-things-worse-what-do-you-think-went-wrong" data-number="23.4" class="anchored"><span class="header-section-number">23.4</span> <strong>Did any techniques make things worse?</strong> What do you think went wrong?</h2></li>
<li><h2 id="how-did-the-techniques-interact-when-combined-were-they-complementary-or-did-they-conflict" data-number="23.5" class="anchored"><span class="header-section-number">23.5</span> <strong>How did the techniques interact when combined?</strong> Were they complementary or did they conflict?</h2></li>
<li><h2 id="what-other-techniques-from-the-word-bank-might-help-with-remaining-issues" data-number="23.6" class="anchored"><span class="header-section-number">23.6</span> <strong>What other techniques from the word bank might help with remaining issues?</strong></h2></li>
</ol>
<hr>
</section>
</section>
</section>
<section id="part-5-reflection-and-extensions" class="level1" data-number="24">
<h1 data-number="24"><span class="header-section-number">24</span> Part 5: Reflection and Extensions</h1>
<section id="exercise-5-critical-thinking" class="level2" data-number="24.1">
<h2 data-number="24.1" class="anchored" data-anchor-id="exercise-5-critical-thinking"><span class="header-section-number">24.1</span> Exercise 5: Critical Thinking</h2>
<p>Answer the following questions:</p>
<ol type="1">
<li><p><strong>Computational Cost:</strong> Which techniques added significant computational overhead? Was the improvement worth the cost?</p></li>
<li><p><strong>Hyperparameter Sensitivity:</strong> Which techniques required careful hyperparameter tuning? Which were more robust?</p></li>
<li><p><strong>Theoretical Understanding:</strong> For each technique you implemented, explain in 2-3 sentences WHY it helps with GAN training from a theoretical perspective.</p></li>
<li><p><strong>Engineering Constraints:</strong> If you were deploying this GAN in production, which technique would you choose and why?</p></li>
<li><p><strong>Future Improvements:</strong> What other techniques (from the word bank or elsewhere) would you like to try? Why?</p></li>
</ol>
<hr>
</section>
<section id="summary" class="level2" data-number="24.2">
<h2 data-number="24.2" class="anchored" data-anchor-id="summary"><span class="header-section-number">24.2</span> Summary</h2>
<p>In this problem set, you: - Trained a baseline GAN and diagnosed its issues - Learned about modern GAN training techniques from the literature - Formed hypotheses about which techniques would help - Implemented and tested your chosen techniques - Analyzed results and understood trade-offs</p>
<p><strong>Key Takeaway:</strong> GAN training is challenging, but systematic application of well-understood techniques can significantly improve stability and output quality. Different problems may benefit from different techniques - there’s no one-size-fits-all solution!</p>
<hr>
<section id="references" class="level3" data-number="24.2.1">
<h3 data-number="24.2.1" class="anchored" data-anchor-id="references"><span class="header-section-number">24.2.1</span> References</h3>
<ol type="1">
<li>Goodfellow et al.&nbsp;(2014) - “Generative Adversarial Networks”</li>
<li>Mirza &amp; Osindero (2014) - “Conditional Generative Adversarial Nets”</li>
<li>Salimans et al.&nbsp;(2016) - “Improved Techniques for Training GANs”</li>
<li>Gulrajani et al.&nbsp;(2017) - “Improved Training of Wasserstein GANs”</li>
<li>Heusel et al.&nbsp;(2017) - “GANs Trained by a Two Time-Scale Update Rule”</li>
<li>Miyato et al.&nbsp;(2018) - “Spectral Normalization for GANs”</li>
<li>Karras et al.&nbsp;(2018) - “Progressive Growing of GANs”</li>
<li>Zhang et al.&nbsp;(2019) - “Self-Attention GANs”</li>
</ol>
</section>
</section>
</section>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../problems/ps1.html" class="pagination-link" aria-label="Problem Set 1">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Problem Set 1</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notebooks/notebooks.html" class="pagination-link" aria-label="In-Class Notebooks">
        <span class="nav-page-text">In-Class Notebooks</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Machine Learning for Mechanical Engineers © 2025 by <a href="./index.qmd#sec-contributors">Mark Fuge and IDEAL Lab Contributors</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>